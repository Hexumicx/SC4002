{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3T3QwMxwPhv",
    "outputId": "84061c71-066a-45cf-ac64-2851f6ef9643"
   },
   "outputs": [],
   "source": [
    "# %pip install datasets\n",
    "# %pip install nltk\n",
    "# %pip install tensorflow\n",
    "# %pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6McSeWSrwI43"
   },
   "source": [
    "# Part 0. Data Prepraration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc6eHQ8IwI45",
    "outputId": "b4da5896-49dc-45f9-d143-100dc35c6f0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alan Wong\\Desktop\\SC4002\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset ['train']\n",
    "validation_dataset = dataset ['validation']\n",
    "test_dataset = dataset ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Alan\n",
      "[nltk_data]     Wong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "Map: 100%|██████████| 8530/8530 [00:00<00:00, 20887.54 examples/s]\n",
      "Map: 100%|██████████| 1066/1066 [00:00<00:00, 9706.38 examples/s]\n",
      "Map: 100%|██████████| 1066/1066 [00:00<00:00, 15952.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock destined 21st century's new \" conan \" he's going make splash even greater arnold schwarzenegger , jean-claud van damme steven segal .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# removing stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(example):\n",
    "    example['text'] = ' '.join(\n",
    "        [word for word in example['text'].split() if word.lower() not in stop_words]\n",
    "    )\n",
    "    return example\n",
    "\n",
    "# Apply the function to each split\n",
    "train_dataset = train_dataset.map(remove_stopwords)\n",
    "validation_dataset = validation_dataset.map(remove_stopwords)\n",
    "test_dataset = test_dataset.map(remove_stopwords)\n",
    "print(train_dataset[0]['text'])  # Should display text without stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhTvsb7swI46"
   },
   "source": [
    "# Part 1. Preparing Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BfyWI60wI47"
   },
   "source": [
    "#### (a) What is the size of the vocabulary formed from your training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffYmg5t5wI47",
    "outputId": "eedb6b74-1d27-4c90-b5cd-0184cfb0b70b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Alan\n",
      "[nltk_data]     Wong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "# In case nltk.download('punkt') does not work.\n",
    "# nltk.download('punkt_tab')\n",
    "vocab = set()\n",
    "for text in train_dataset['text']:\n",
    "    ls = nltk.word_tokenize(text)\n",
    "    for word in ls:\n",
    "        if word.isalpha(): vocab.add(word)\n",
    "#Size of the vocabulary: 15812\n",
    "#New Size of the vocabulary: 15725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEaufFA1wI47",
    "outputId": "9c58e5ef-a3c7-4103-a665-cb946d93d8da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary: 15725\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the vocabulary:\", len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OUr03AqwI48"
   },
   "source": [
    "#### (b) We use OOV (out-of-vocabulary) to refer to those words appeared in the training data but not in the Word2vec (or Glove) dictionary. How many OOV words exist in your training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_MnWtslwI48",
    "outputId": "7633267e-8f95-48f0-87a1-987c734b35cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext-wiki-news-subwords-300\n",
      "conceptnet-numberbatch-17-06-300\n",
      "word2vec-ruscorpora-300\n",
      "word2vec-google-news-300\n",
      "glove-wiki-gigaword-50\n",
      "glove-wiki-gigaword-100\n",
      "glove-wiki-gigaword-200\n",
      "glove-wiki-gigaword-300\n",
      "glove-twitter-25\n",
      "glove-twitter-50\n",
      "glove-twitter-100\n",
      "glove-twitter-200\n",
      "__testing_word2vec-matrix-synopsis\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "for key in api.info()['models'].keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7ZEvG2TawI48"
   },
   "outputs": [],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ujb7pnArwI49",
    "outputId": "58e8d33a-d52b-4c0a-be6f-7962c8427b65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OOV words: 550\n"
     ]
    }
   ],
   "source": [
    "oov_words = set()\n",
    "for word in vocab:\n",
    "    if word not in model:\n",
    "        oov_words.add(word)\n",
    "\n",
    "print(\"Number of OOV words:\", len(oov_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSy_BD90wI49"
   },
   "source": [
    "#### (c) The existence of the OOV words is one of the well-known limitations of Word2vec (or Glove). Without using any transformer-based language models (e.g., BERT, GPT, T5), what do you think is the best strategy to mitigate such limitation? Implement your solution in your source code. Show the corresponding code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bO_10iKqwI49"
   },
   "outputs": [],
   "source": [
    "# Group any words that are not in the model into a single token\n",
    "def wordtovec(word):\n",
    "    if word in model:\n",
    "        return model[word]\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQ6rLQa-wI49"
   },
   "source": [
    "# Part 2. Model Training & Evaluation - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aJZRcXbpwI49"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yTMLPug0wI49"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(model.index_to_key) + 1\n",
    "embedding_dim = model.vector_size\n",
    "word_index = {word: index+1 for index, word in enumerate(model.index_to_key)} # index 0 is reserved for padding\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "biNlG_4VwI4-"
   },
   "outputs": [],
   "source": [
    "for word, idx in word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[idx] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fTACwi_SwI4-"
   },
   "outputs": [],
   "source": [
    "def tokenize(text, word_index):\n",
    "    ls = nltk.word_tokenize(text)\n",
    "    return [word_index[word] for word in ls if word in word_index]\n",
    "\n",
    "X_train = [tokenize(text, word_index) for text in train_dataset['text']]\n",
    "X_val = [tokenize(text, word_index) for text in validation_dataset['text']]\n",
    "X_test = [tokenize(text, word_index) for text in test_dataset['text']]\n",
    "max_length = max(len(seq) for seq in X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2deriXYKwI4-"
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n",
    "X_val = pad_sequences(X_val, maxlen=max_length, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ia8WYob7z0qP"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(train_dataset['label'])\n",
    "y_val = np.array(validation_dataset['label'])\n",
    "y_test = np.array(test_dataset['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJT5G8794ZXC"
   },
   "source": [
    "Model Training - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "best_accuracy = {}\n",
    "class CustomCallback(Callback):\n",
    "    accuracy = 0\n",
    "    cur_key = \"\"\n",
    "    epochs = 0\n",
    "    optimizer = \"\"\n",
    "    batch_size = 0\n",
    "    best_model = None\n",
    "    lr = 0\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.accuracy = 0\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        global best_accuracy\n",
    "        if self.accuracy > best_accuracy.get(\"accuracy\", 0):\n",
    "            best_accuracy = {\n",
    "                \"accuracy\": self.accuracy,\n",
    "                \"epoch\": self.epochs,\n",
    "                \"optimizer\": self.optimizer,\n",
    "                \"batch_size\": self.batch_size,\n",
    "                \"lr\": self.lr\n",
    "            }\n",
    "            print(\"Saved best accuracy for current run:\", self.accuracy, \"at epoch\", self.epochs)\n",
    "            self.best_model.save(filepath=\"best_model.keras\")\n",
    "        print(\"Run completed on:\")\n",
    "        print(self.cur_key)\n",
    "        print(\"Best accuracy for current run:\", self.accuracy, \"at epoch\", self.epochs)\n",
    "        print(\"Training ended\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_accuracy = logs['val_accuracy']\n",
    "        if val_accuracy > self.accuracy:\n",
    "            self.accuracy = val_accuracy\n",
    "            self.epochs = epoch\n",
    "            self.best_model = self.model\n",
    "\n",
    "    def set_key(self, optimizer, batch_size, lr):\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.cur_key = f\"optimizer: {optimizer}, batch_size: {batch_size}, lr: {lr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pvFnR88r6XZJ"
   },
   "outputs": [],
   "source": [
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    custom_callback = CustomCallback()\n",
    "    custom_callback.set_key(optimizer, batch_size, lr)\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False),  # Embedding layer is frozen\n",
    "        SimpleRNN(16, return_sequences=False),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[custom_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEFnPNmg7N-Z",
    "outputId": "2545a360-7231-482f-9598-81a616752eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5137 - loss: 0.6954 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5042 - loss: 0.6939 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4946 - loss: 0.6937 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5003 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4957 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
      "Epoch 6/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4964 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Saved best accuracy for current run: 0.5 at epoch 0\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 16, lr: 0.005\n",
      "Best accuracy for current run: 0.5 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4972 - loss: 0.6975 - val_accuracy: 0.5394 - val_loss: 0.6894\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5292 - loss: 0.6899 - val_accuracy: 0.5347 - val_loss: 0.6956\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5631 - loss: 0.6837 - val_accuracy: 0.5553 - val_loss: 0.6878\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5865 - loss: 0.6761 - val_accuracy: 0.5797 - val_loss: 0.6755\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.6695 - val_accuracy: 0.6032 - val_loss: 0.6651\n",
      "Epoch 6/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6146 - loss: 0.6605 - val_accuracy: 0.6079 - val_loss: 0.6570\n",
      "Epoch 7/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6219 - loss: 0.6554 - val_accuracy: 0.6266 - val_loss: 0.6431\n",
      "Epoch 8/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6380 - loss: 0.6438 - val_accuracy: 0.6295 - val_loss: 0.6390\n",
      "Epoch 9/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6453 - loss: 0.6453 - val_accuracy: 0.6370 - val_loss: 0.6316\n",
      "Epoch 10/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6472 - loss: 0.6402 - val_accuracy: 0.6276 - val_loss: 0.6527\n",
      "Epoch 11/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6545 - loss: 0.6352 - val_accuracy: 0.6538 - val_loss: 0.6394\n",
      "Epoch 12/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6485 - loss: 0.6387 - val_accuracy: 0.4972 - val_loss: 0.7540\n",
      "Saved best accuracy for current run: 0.6538461446762085 at epoch 10\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 16, lr: 0.005\n",
      "Best accuracy for current run: 0.6538461446762085 at epoch 10\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4944 - loss: 0.6984 - val_accuracy: 0.5084 - val_loss: 0.6926\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5016 - loss: 0.6948 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4982 - loss: 0.6938 - val_accuracy: 0.4878 - val_loss: 0.6931\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4945 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 16, lr: 0.005\n",
      "Best accuracy for current run: 0.508442759513855 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5133 - loss: 0.6931 - val_accuracy: 0.6051 - val_loss: 0.6718\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5975 - loss: 0.6713 - val_accuracy: 0.6238 - val_loss: 0.6558\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6193 - loss: 0.6582 - val_accuracy: 0.6220 - val_loss: 0.6471\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6316 - loss: 0.6487 - val_accuracy: 0.6313 - val_loss: 0.6420\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6417 - loss: 0.6407 - val_accuracy: 0.6323 - val_loss: 0.6378\n",
      "Epoch 6/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6502 - loss: 0.6337 - val_accuracy: 0.6463 - val_loss: 0.6340\n",
      "Epoch 7/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6605 - loss: 0.6279 - val_accuracy: 0.6614 - val_loss: 0.6307\n",
      "Epoch 8/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6661 - loss: 0.6231 - val_accuracy: 0.6670 - val_loss: 0.6275\n",
      "Epoch 9/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6699 - loss: 0.6191 - val_accuracy: 0.6660 - val_loss: 0.6246\n",
      "Epoch 10/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6800 - loss: 0.6154 - val_accuracy: 0.6670 - val_loss: 0.6222\n",
      "Epoch 11/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6831 - loss: 0.6121 - val_accuracy: 0.6670 - val_loss: 0.6205\n",
      "Epoch 12/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.6089 - val_accuracy: 0.6651 - val_loss: 0.6190\n",
      "Epoch 13/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6908 - loss: 0.6060 - val_accuracy: 0.6689 - val_loss: 0.6178\n",
      "Epoch 14/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6916 - loss: 0.6033 - val_accuracy: 0.6726 - val_loss: 0.6169\n",
      "Epoch 15/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6945 - loss: 0.6007 - val_accuracy: 0.6745 - val_loss: 0.6162\n",
      "Epoch 16/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6964 - loss: 0.5982 - val_accuracy: 0.6735 - val_loss: 0.6156\n",
      "Epoch 17/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7003 - loss: 0.5957 - val_accuracy: 0.6735 - val_loss: 0.6148\n",
      "Epoch 18/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7036 - loss: 0.5933 - val_accuracy: 0.6764 - val_loss: 0.6144\n",
      "Epoch 19/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7051 - loss: 0.5910 - val_accuracy: 0.6754 - val_loss: 0.6141\n",
      "Epoch 20/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7078 - loss: 0.5890 - val_accuracy: 0.6782 - val_loss: 0.6139\n",
      "Epoch 21/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7090 - loss: 0.5872 - val_accuracy: 0.6754 - val_loss: 0.6138\n",
      "Epoch 22/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7093 - loss: 0.5855 - val_accuracy: 0.6754 - val_loss: 0.6137\n",
      "Epoch 23/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7098 - loss: 0.5840 - val_accuracy: 0.6782 - val_loss: 0.6137\n",
      "Epoch 24/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 0.5825 - val_accuracy: 0.6782 - val_loss: 0.6137\n",
      "Epoch 25/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7143 - loss: 0.5811 - val_accuracy: 0.6801 - val_loss: 0.6137\n",
      "Epoch 26/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7139 - loss: 0.5796 - val_accuracy: 0.6792 - val_loss: 0.6137\n",
      "Epoch 27/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.5781 - val_accuracy: 0.6792 - val_loss: 0.6136\n",
      "Epoch 28/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7172 - loss: 0.5766 - val_accuracy: 0.6811 - val_loss: 0.6136\n",
      "Epoch 29/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7194 - loss: 0.5750 - val_accuracy: 0.6801 - val_loss: 0.6135\n",
      "Epoch 30/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7195 - loss: 0.5735 - val_accuracy: 0.6811 - val_loss: 0.6133\n",
      "Epoch 31/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7214 - loss: 0.5721 - val_accuracy: 0.6820 - val_loss: 0.6131\n",
      "Epoch 32/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7226 - loss: 0.5706 - val_accuracy: 0.6829 - val_loss: 0.6127\n",
      "Epoch 33/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7232 - loss: 0.5693 - val_accuracy: 0.6839 - val_loss: 0.6122\n",
      "Epoch 34/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7239 - loss: 0.5680 - val_accuracy: 0.6848 - val_loss: 0.6115\n",
      "Epoch 35/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.5668 - val_accuracy: 0.6857 - val_loss: 0.6107\n",
      "Epoch 36/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.5658 - val_accuracy: 0.6782 - val_loss: 0.6104\n",
      "Epoch 37/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7277 - loss: 0.5648 - val_accuracy: 0.6773 - val_loss: 0.6103\n",
      "Epoch 38/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5636 - val_accuracy: 0.6782 - val_loss: 0.6103\n",
      "Epoch 39/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.5625 - val_accuracy: 0.6764 - val_loss: 0.6104\n",
      "Epoch 40/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.5615 - val_accuracy: 0.6764 - val_loss: 0.6105\n",
      "Saved best accuracy for current run: 0.6857410669326782 at epoch 34\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 16, lr: 0.005\n",
      "Best accuracy for current run: 0.6857410669326782 at epoch 34\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4945 - loss: 0.6999 - val_accuracy: 0.4991 - val_loss: 0.7065\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5046 - loss: 0.6980 - val_accuracy: 0.4972 - val_loss: 0.6951\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4957 - loss: 0.6965 - val_accuracy: 0.5009 - val_loss: 0.6956\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4904 - loss: 0.6949 - val_accuracy: 0.5009 - val_loss: 0.6964\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5011 - loss: 0.6947 - val_accuracy: 0.5000 - val_loss: 0.6970\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 16, lr: 0.01\n",
      "Best accuracy for current run: 0.5009380578994751 at epoch 2\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5003 - loss: 0.6978 - val_accuracy: 0.5122 - val_loss: 0.6925\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5289 - loss: 0.6906 - val_accuracy: 0.5263 - val_loss: 0.7000\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5480 - loss: 0.6884 - val_accuracy: 0.5797 - val_loss: 0.6718\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5469 - loss: 0.6859 - val_accuracy: 0.4991 - val_loss: 0.6934\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5102 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 6/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5103 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 16, lr: 0.01\n",
      "Best accuracy for current run: 0.5797373652458191 at epoch 2\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4869 - loss: 0.7017 - val_accuracy: 0.5413 - val_loss: 0.6935\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4865 - loss: 0.6995 - val_accuracy: 0.5066 - val_loss: 0.7097\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5062 - loss: 0.6971 - val_accuracy: 0.5019 - val_loss: 0.6971\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5061 - loss: 0.6960 - val_accuracy: 0.4916 - val_loss: 0.7018\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 16, lr: 0.01\n",
      "Best accuracy for current run: 0.5412757992744446 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5156 - loss: 0.6930 - val_accuracy: 0.5816 - val_loss: 0.6778\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6129 - loss: 0.6620 - val_accuracy: 0.6332 - val_loss: 0.6466\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6456 - loss: 0.6408 - val_accuracy: 0.6463 - val_loss: 0.6315\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6607 - loss: 0.6251 - val_accuracy: 0.6585 - val_loss: 0.6212\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6736 - loss: 0.6132 - val_accuracy: 0.6670 - val_loss: 0.6162\n",
      "Epoch 6/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6822 - loss: 0.6044 - val_accuracy: 0.6717 - val_loss: 0.6121\n",
      "Epoch 7/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6910 - loss: 0.5952 - val_accuracy: 0.6651 - val_loss: 0.6104\n",
      "Epoch 8/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6994 - loss: 0.5880 - val_accuracy: 0.6717 - val_loss: 0.6110\n",
      "Epoch 9/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6999 - loss: 0.5840 - val_accuracy: 0.6717 - val_loss: 0.6067\n",
      "Epoch 10/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7090 - loss: 0.5782 - val_accuracy: 0.6632 - val_loss: 0.6064\n",
      "Epoch 11/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7120 - loss: 0.5750 - val_accuracy: 0.6614 - val_loss: 0.6041\n",
      "Epoch 12/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7189 - loss: 0.5686 - val_accuracy: 0.6604 - val_loss: 0.6067\n",
      "Epoch 13/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7197 - loss: 0.5659 - val_accuracy: 0.6538 - val_loss: 0.6074\n",
      "Epoch 14/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7207 - loss: 0.5622 - val_accuracy: 0.6538 - val_loss: 0.6083\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 16, lr: 0.01\n",
      "Best accuracy for current run: 0.6716697812080383 at epoch 5\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5046 - loss: 0.7169 - val_accuracy: 0.4972 - val_loss: 0.7295\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5026 - loss: 0.7231 - val_accuracy: 0.5000 - val_loss: 0.8057\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4950 - loss: 0.7379 - val_accuracy: 0.5028 - val_loss: 0.7926\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5101 - loss: 0.7323 - val_accuracy: 0.5000 - val_loss: 0.7893\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 16, lr: 0.05\n",
      "Best accuracy for current run: 0.5028142333030701 at epoch 2\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4976 - loss: 0.6984 - val_accuracy: 0.5028 - val_loss: 0.6954\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5096 - loss: 0.6944 - val_accuracy: 0.5066 - val_loss: 0.6947\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5125 - loss: 0.6940 - val_accuracy: 0.4869 - val_loss: 0.6946\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6939 - val_accuracy: 0.4728 - val_loss: 0.6952\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5123 - loss: 0.6937 - val_accuracy: 0.4559 - val_loss: 0.6958\n",
      "Epoch 6/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5106 - loss: 0.6936 - val_accuracy: 0.4522 - val_loss: 0.6960\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 16, lr: 0.05\n",
      "Best accuracy for current run: 0.50656658411026 at epoch 1\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4976 - loss: 0.7289 - val_accuracy: 0.5000 - val_loss: 1.3517\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5033 - loss: 0.7316 - val_accuracy: 0.4887 - val_loss: 0.7770\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4997 - loss: 0.7231 - val_accuracy: 0.5000 - val_loss: 0.7848\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5003 - loss: 0.7275 - val_accuracy: 0.5000 - val_loss: 1.3457\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5034 - loss: 0.7333 - val_accuracy: 0.5000 - val_loss: 1.3291\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 16, lr: 0.05\n",
      "Best accuracy for current run: 0.5 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4923 - loss: 0.6978 - val_accuracy: 0.4615 - val_loss: 0.6946\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4970 - loss: 0.6936 - val_accuracy: 0.4934 - val_loss: 0.6934\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5029 - loss: 0.6933 - val_accuracy: 0.4794 - val_loss: 0.6943\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4994 - loss: 0.6935 - val_accuracy: 0.4709 - val_loss: 0.6942\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5044 - loss: 0.6935 - val_accuracy: 0.4747 - val_loss: 0.6943\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 16, lr: 0.05\n",
      "Best accuracy for current run: 0.4934333860874176 at epoch 1\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4843 - loss: 0.7608 - val_accuracy: 0.4962 - val_loss: 0.6981\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4975 - loss: 0.7415 - val_accuracy: 0.5150 - val_loss: 0.6975\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4978 - loss: 0.7443 - val_accuracy: 0.5000 - val_loss: 0.8169\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5098 - loss: 0.7613 - val_accuracy: 0.4841 - val_loss: 0.7061\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5008 - loss: 0.7375 - val_accuracy: 0.5028 - val_loss: 0.7452\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 16, lr: 0.1\n",
      "Best accuracy for current run: 0.5150094032287598 at epoch 1\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4983 - loss: 0.6989 - val_accuracy: 0.5000 - val_loss: 0.6987\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5062 - loss: 0.6946 - val_accuracy: 0.4559 - val_loss: 0.6995\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5087 - loss: 0.6943 - val_accuracy: 0.4831 - val_loss: 0.6953\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 0.6938 - val_accuracy: 0.4812 - val_loss: 0.6952\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5126 - loss: 0.6937 - val_accuracy: 0.4709 - val_loss: 0.6952\n",
      "Epoch 6/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5083 - loss: 0.6936 - val_accuracy: 0.4756 - val_loss: 0.6953\n",
      "Epoch 7/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5092 - loss: 0.6936 - val_accuracy: 0.4803 - val_loss: 0.6954\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 16, lr: 0.1\n",
      "Best accuracy for current run: 0.5 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4994 - loss: 0.7922 - val_accuracy: 0.5000 - val_loss: 1.7164\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5022 - loss: 0.7741 - val_accuracy: 0.5131 - val_loss: 0.8321\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4981 - loss: 0.7666 - val_accuracy: 0.5019 - val_loss: 0.7933\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4926 - loss: 0.7620 - val_accuracy: 0.5028 - val_loss: 1.1132\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4917 - loss: 0.7792 - val_accuracy: 0.5009 - val_loss: 1.1217\n",
      "Epoch 6/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4909 - loss: 0.7694 - val_accuracy: 0.4897 - val_loss: 1.0750\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 16, lr: 0.1\n",
      "Best accuracy for current run: 0.5131332278251648 at epoch 1\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4992 - loss: 0.6994 - val_accuracy: 0.5038 - val_loss: 0.6933\n",
      "Epoch 2/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5084 - loss: 0.6942 - val_accuracy: 0.5009 - val_loss: 0.6931\n",
      "Epoch 3/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5022 - loss: 0.6934 - val_accuracy: 0.4550 - val_loss: 0.7084\n",
      "Epoch 4/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5039 - loss: 0.6939 - val_accuracy: 0.4972 - val_loss: 0.6934\n",
      "Epoch 5/100\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5035 - loss: 0.6933 - val_accuracy: 0.4934 - val_loss: 0.6934\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 16, lr: 0.1\n",
      "Best accuracy for current run: 0.5037523508071899 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4962 - loss: 0.6965 - val_accuracy: 0.4981 - val_loss: 0.6933\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4953 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4990 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4997 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 32, lr: 0.005\n",
      "Best accuracy for current run: 0.5 at epoch 1\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5030 - loss: 0.6976 - val_accuracy: 0.5544 - val_loss: 0.6868\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5202 - loss: 0.6919 - val_accuracy: 0.5685 - val_loss: 0.6839\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5439 - loss: 0.6870 - val_accuracy: 0.5713 - val_loss: 0.6830\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5681 - loss: 0.6825 - val_accuracy: 0.5797 - val_loss: 0.6792\n",
      "Epoch 5/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5741 - loss: 0.6780 - val_accuracy: 0.5835 - val_loss: 0.6754\n",
      "Epoch 6/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5865 - loss: 0.6735 - val_accuracy: 0.5976 - val_loss: 0.6704\n",
      "Epoch 7/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5933 - loss: 0.6691 - val_accuracy: 0.6126 - val_loss: 0.6638\n",
      "Epoch 8/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6086 - loss: 0.6649 - val_accuracy: 0.6266 - val_loss: 0.6586\n",
      "Epoch 9/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6187 - loss: 0.6607 - val_accuracy: 0.6285 - val_loss: 0.6545\n",
      "Epoch 10/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6258 - loss: 0.6556 - val_accuracy: 0.6323 - val_loss: 0.6498\n",
      "Epoch 11/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6303 - loss: 0.6503 - val_accuracy: 0.6379 - val_loss: 0.6439\n",
      "Epoch 12/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6369 - loss: 0.6452 - val_accuracy: 0.6332 - val_loss: 0.6401\n",
      "Epoch 13/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6454 - loss: 0.6418 - val_accuracy: 0.6398 - val_loss: 0.6373\n",
      "Epoch 14/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6526 - loss: 0.6363 - val_accuracy: 0.6341 - val_loss: 0.6331\n",
      "Epoch 15/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6559 - loss: 0.6335 - val_accuracy: 0.6257 - val_loss: 0.6365\n",
      "Epoch 16/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6503 - loss: 0.6348 - val_accuracy: 0.6370 - val_loss: 0.6327\n",
      "Epoch 17/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6664 - loss: 0.6279 - val_accuracy: 0.6454 - val_loss: 0.6275\n",
      "Epoch 18/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6643 - loss: 0.6270 - val_accuracy: 0.6426 - val_loss: 0.6270\n",
      "Epoch 19/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6742 - loss: 0.6215 - val_accuracy: 0.6417 - val_loss: 0.6346\n",
      "Epoch 20/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6720 - loss: 0.6161 - val_accuracy: 0.6360 - val_loss: 0.6294\n",
      "Epoch 21/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6868 - loss: 0.6088 - val_accuracy: 0.6426 - val_loss: 0.6188\n",
      "Epoch 22/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6819 - loss: 0.6148 - val_accuracy: 0.6426 - val_loss: 0.6273\n",
      "Epoch 23/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6790 - loss: 0.6143 - val_accuracy: 0.6379 - val_loss: 0.6325\n",
      "Epoch 24/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6809 - loss: 0.6118 - val_accuracy: 0.6623 - val_loss: 0.6201\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 32, lr: 0.005\n",
      "Best accuracy for current run: 0.6622889041900635 at epoch 23\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5009 - loss: 0.6965 - val_accuracy: 0.5028 - val_loss: 0.6931\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4835 - loss: 0.6941 - val_accuracy: 0.4634 - val_loss: 0.6951\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4968 - loss: 0.6939 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4926 - loss: 0.6936 - val_accuracy: 0.4653 - val_loss: 0.6948\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 32, lr: 0.005\n",
      "Best accuracy for current run: 0.5028142333030701 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5073 - loss: 0.6951 - val_accuracy: 0.5872 - val_loss: 0.6777\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5679 - loss: 0.6810 - val_accuracy: 0.6116 - val_loss: 0.6658\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5984 - loss: 0.6700 - val_accuracy: 0.6163 - val_loss: 0.6568\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6123 - loss: 0.6617 - val_accuracy: 0.6276 - val_loss: 0.6506\n",
      "Epoch 5/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6240 - loss: 0.6548 - val_accuracy: 0.6370 - val_loss: 0.6462\n",
      "Epoch 6/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6316 - loss: 0.6485 - val_accuracy: 0.6332 - val_loss: 0.6428\n",
      "Epoch 7/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6389 - loss: 0.6426 - val_accuracy: 0.6360 - val_loss: 0.6398\n",
      "Epoch 8/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6479 - loss: 0.6370 - val_accuracy: 0.6426 - val_loss: 0.6369\n",
      "Epoch 9/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6531 - loss: 0.6320 - val_accuracy: 0.6463 - val_loss: 0.6340\n",
      "Epoch 10/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6597 - loss: 0.6275 - val_accuracy: 0.6548 - val_loss: 0.6313\n",
      "Epoch 11/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6625 - loss: 0.6236 - val_accuracy: 0.6595 - val_loss: 0.6285\n",
      "Epoch 12/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6685 - loss: 0.6201 - val_accuracy: 0.6632 - val_loss: 0.6258\n",
      "Epoch 13/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6747 - loss: 0.6169 - val_accuracy: 0.6651 - val_loss: 0.6234\n",
      "Epoch 14/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6807 - loss: 0.6139 - val_accuracy: 0.6679 - val_loss: 0.6213\n",
      "Epoch 15/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6824 - loss: 0.6111 - val_accuracy: 0.6670 - val_loss: 0.6194\n",
      "Epoch 16/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6871 - loss: 0.6085 - val_accuracy: 0.6698 - val_loss: 0.6176\n",
      "Epoch 17/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6887 - loss: 0.6060 - val_accuracy: 0.6707 - val_loss: 0.6160\n",
      "Epoch 18/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6917 - loss: 0.6035 - val_accuracy: 0.6707 - val_loss: 0.6147\n",
      "Epoch 19/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6962 - loss: 0.6011 - val_accuracy: 0.6689 - val_loss: 0.6137\n",
      "Epoch 20/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6989 - loss: 0.5988 - val_accuracy: 0.6726 - val_loss: 0.6128\n",
      "Epoch 21/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7011 - loss: 0.5967 - val_accuracy: 0.6735 - val_loss: 0.6122\n",
      "Epoch 22/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7028 - loss: 0.5948 - val_accuracy: 0.6735 - val_loss: 0.6117\n",
      "Epoch 23/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7044 - loss: 0.5930 - val_accuracy: 0.6754 - val_loss: 0.6114\n",
      "Epoch 24/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7049 - loss: 0.5913 - val_accuracy: 0.6735 - val_loss: 0.6111\n",
      "Epoch 25/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.5898 - val_accuracy: 0.6745 - val_loss: 0.6108\n",
      "Epoch 26/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7079 - loss: 0.5883 - val_accuracy: 0.6754 - val_loss: 0.6105\n",
      "Epoch 27/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7077 - loss: 0.5868 - val_accuracy: 0.6801 - val_loss: 0.6102\n",
      "Epoch 28/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7085 - loss: 0.5853 - val_accuracy: 0.6801 - val_loss: 0.6100\n",
      "Epoch 29/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7079 - loss: 0.5837 - val_accuracy: 0.6829 - val_loss: 0.6097\n",
      "Epoch 30/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7081 - loss: 0.5822 - val_accuracy: 0.6820 - val_loss: 0.6094\n",
      "Epoch 31/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7104 - loss: 0.5806 - val_accuracy: 0.6829 - val_loss: 0.6091\n",
      "Epoch 32/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7114 - loss: 0.5792 - val_accuracy: 0.6839 - val_loss: 0.6088\n",
      "Epoch 33/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7127 - loss: 0.5777 - val_accuracy: 0.6857 - val_loss: 0.6084\n",
      "Epoch 34/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7136 - loss: 0.5762 - val_accuracy: 0.6848 - val_loss: 0.6081\n",
      "Epoch 35/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7151 - loss: 0.5748 - val_accuracy: 0.6848 - val_loss: 0.6078\n",
      "Epoch 36/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7167 - loss: 0.5735 - val_accuracy: 0.6876 - val_loss: 0.6075\n",
      "Epoch 37/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7184 - loss: 0.5722 - val_accuracy: 0.6886 - val_loss: 0.6073\n",
      "Epoch 38/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7212 - loss: 0.5709 - val_accuracy: 0.6886 - val_loss: 0.6071\n",
      "Epoch 39/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7222 - loss: 0.5700 - val_accuracy: 0.6867 - val_loss: 0.6069\n",
      "Epoch 40/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7241 - loss: 0.5685 - val_accuracy: 0.6867 - val_loss: 0.6067\n",
      "Epoch 41/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7242 - loss: 0.5679 - val_accuracy: 0.6886 - val_loss: 0.6066\n",
      "Epoch 42/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7249 - loss: 0.5663 - val_accuracy: 0.6876 - val_loss: 0.6065\n",
      "Epoch 43/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7260 - loss: 0.5654 - val_accuracy: 0.6886 - val_loss: 0.6063\n",
      "Epoch 44/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7277 - loss: 0.5645 - val_accuracy: 0.6923 - val_loss: 0.6062\n",
      "Epoch 45/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7290 - loss: 0.5635 - val_accuracy: 0.6932 - val_loss: 0.6060\n",
      "Epoch 46/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.5627 - val_accuracy: 0.6942 - val_loss: 0.6057\n",
      "Epoch 47/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7301 - loss: 0.5617 - val_accuracy: 0.6942 - val_loss: 0.6054\n",
      "Epoch 48/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7296 - loss: 0.5609 - val_accuracy: 0.6932 - val_loss: 0.6052\n",
      "Epoch 49/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7305 - loss: 0.5600 - val_accuracy: 0.6914 - val_loss: 0.6049\n",
      "Epoch 50/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7315 - loss: 0.5592 - val_accuracy: 0.6923 - val_loss: 0.6047\n",
      "Epoch 51/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7315 - loss: 0.5583 - val_accuracy: 0.6904 - val_loss: 0.6045\n",
      "Epoch 52/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7323 - loss: 0.5576 - val_accuracy: 0.6895 - val_loss: 0.6044\n",
      "Epoch 53/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7332 - loss: 0.5567 - val_accuracy: 0.6867 - val_loss: 0.6042\n",
      "Epoch 54/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7335 - loss: 0.5560 - val_accuracy: 0.6867 - val_loss: 0.6041\n",
      "Epoch 55/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.5552 - val_accuracy: 0.6867 - val_loss: 0.6040\n",
      "Epoch 56/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7348 - loss: 0.5545 - val_accuracy: 0.6857 - val_loss: 0.6039\n",
      "Epoch 57/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7358 - loss: 0.5536 - val_accuracy: 0.6876 - val_loss: 0.6038\n",
      "Epoch 58/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.5530 - val_accuracy: 0.6876 - val_loss: 0.6038\n",
      "Epoch 59/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.5521 - val_accuracy: 0.6886 - val_loss: 0.6038\n",
      "Epoch 60/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.5513 - val_accuracy: 0.6895 - val_loss: 0.6039\n",
      "Saved best accuracy for current run: 0.694183886051178 at epoch 45\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 32, lr: 0.005\n",
      "Best accuracy for current run: 0.694183886051178 at epoch 45\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5004 - loss: 0.7019 - val_accuracy: 0.5000 - val_loss: 0.6928\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4878 - loss: 0.6964 - val_accuracy: 0.5009 - val_loss: 0.6991\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5051 - loss: 0.6957 - val_accuracy: 0.4972 - val_loss: 0.6992\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4944 - loss: 0.6966 - val_accuracy: 0.5000 - val_loss: 0.6992\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 32, lr: 0.01\n",
      "Best accuracy for current run: 0.5009380578994751 at epoch 1\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4990 - loss: 0.6975 - val_accuracy: 0.5516 - val_loss: 0.6873\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5223 - loss: 0.6907 - val_accuracy: 0.5432 - val_loss: 0.6937\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5575 - loss: 0.6851 - val_accuracy: 0.5469 - val_loss: 0.6884\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5771 - loss: 0.6787 - val_accuracy: 0.5872 - val_loss: 0.6733\n",
      "Epoch 5/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5958 - loss: 0.6702 - val_accuracy: 0.6182 - val_loss: 0.6613\n",
      "Epoch 6/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6136 - loss: 0.6625 - val_accuracy: 0.6013 - val_loss: 0.6651\n",
      "Epoch 7/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6237 - loss: 0.6564 - val_accuracy: 0.6238 - val_loss: 0.6438\n",
      "Epoch 8/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6429 - loss: 0.6443 - val_accuracy: 0.4841 - val_loss: 0.7300\n",
      "Epoch 9/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6368 - loss: 0.6498 - val_accuracy: 0.6313 - val_loss: 0.6427\n",
      "Epoch 10/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6262 - loss: 0.6536 - val_accuracy: 0.4962 - val_loss: 0.6936\n",
      "Epoch 11/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4989 - loss: 0.6938 - val_accuracy: 0.4887 - val_loss: 0.6932\n",
      "Epoch 12/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4997 - loss: 0.6937 - val_accuracy: 0.4944 - val_loss: 0.6931\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 32, lr: 0.01\n",
      "Best accuracy for current run: 0.6313320994377136 at epoch 8\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5090 - loss: 0.6975 - val_accuracy: 0.4981 - val_loss: 0.7192\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4945 - loss: 0.6970 - val_accuracy: 0.4934 - val_loss: 0.6957\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5011 - loss: 0.6966 - val_accuracy: 0.5188 - val_loss: 0.6957\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5126 - loss: 0.6950 - val_accuracy: 0.4981 - val_loss: 0.6972\n",
      "Epoch 5/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4934 - loss: 0.6967 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 6/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4926 - loss: 0.6961 - val_accuracy: 0.4672 - val_loss: 0.6970\n",
      "Epoch 7/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5028 - loss: 0.6953 - val_accuracy: 0.5122 - val_loss: 0.6956\n",
      "Epoch 8/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5058 - loss: 0.6948 - val_accuracy: 0.4625 - val_loss: 0.7140\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 32, lr: 0.01\n",
      "Best accuracy for current run: 0.5187617540359497 at epoch 2\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5103 - loss: 0.6947 - val_accuracy: 0.5619 - val_loss: 0.6853\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5899 - loss: 0.6737 - val_accuracy: 0.6295 - val_loss: 0.6551\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6245 - loss: 0.6559 - val_accuracy: 0.6304 - val_loss: 0.6417\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6408 - loss: 0.6419 - val_accuracy: 0.6398 - val_loss: 0.6324\n",
      "Epoch 5/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6561 - loss: 0.6285 - val_accuracy: 0.6426 - val_loss: 0.6245\n",
      "Epoch 6/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6695 - loss: 0.6190 - val_accuracy: 0.6445 - val_loss: 0.6203\n",
      "Epoch 7/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6751 - loss: 0.6098 - val_accuracy: 0.6567 - val_loss: 0.6154\n",
      "Epoch 8/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6855 - loss: 0.6026 - val_accuracy: 0.6660 - val_loss: 0.6132\n",
      "Epoch 9/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6889 - loss: 0.5961 - val_accuracy: 0.6689 - val_loss: 0.6116\n",
      "Epoch 10/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6939 - loss: 0.5890 - val_accuracy: 0.6782 - val_loss: 0.6121\n",
      "Epoch 11/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7035 - loss: 0.5836 - val_accuracy: 0.6754 - val_loss: 0.6091\n",
      "Epoch 12/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7053 - loss: 0.5799 - val_accuracy: 0.6717 - val_loss: 0.6094\n",
      "Epoch 13/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7062 - loss: 0.5760 - val_accuracy: 0.6773 - val_loss: 0.6073\n",
      "Epoch 14/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7089 - loss: 0.5732 - val_accuracy: 0.6754 - val_loss: 0.6052\n",
      "Epoch 15/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7081 - loss: 0.5686 - val_accuracy: 0.6735 - val_loss: 0.6054\n",
      "Epoch 16/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7139 - loss: 0.5665 - val_accuracy: 0.6773 - val_loss: 0.6033\n",
      "Epoch 17/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7132 - loss: 0.5619 - val_accuracy: 0.6839 - val_loss: 0.6037\n",
      "Epoch 18/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7153 - loss: 0.5598 - val_accuracy: 0.6782 - val_loss: 0.6029\n",
      "Epoch 19/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7178 - loss: 0.5570 - val_accuracy: 0.6745 - val_loss: 0.6020\n",
      "Epoch 20/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7199 - loss: 0.5541 - val_accuracy: 0.6754 - val_loss: 0.6031\n",
      "Epoch 21/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7198 - loss: 0.5528 - val_accuracy: 0.6745 - val_loss: 0.6012\n",
      "Epoch 22/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7243 - loss: 0.5494 - val_accuracy: 0.6726 - val_loss: 0.6017\n",
      "Epoch 23/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7224 - loss: 0.5482 - val_accuracy: 0.6660 - val_loss: 0.6026\n",
      "Epoch 24/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7244 - loss: 0.5487 - val_accuracy: 0.6735 - val_loss: 0.5986\n",
      "Epoch 25/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7242 - loss: 0.5458 - val_accuracy: 0.6735 - val_loss: 0.6006\n",
      "Epoch 26/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.5443 - val_accuracy: 0.6698 - val_loss: 0.6055\n",
      "Epoch 27/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7273 - loss: 0.5469 - val_accuracy: 0.6689 - val_loss: 0.5988\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 32, lr: 0.01\n",
      "Best accuracy for current run: 0.6838648915290833 at epoch 16\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4979 - loss: 0.7090 - val_accuracy: 0.5131 - val_loss: 0.7044\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4958 - loss: 0.7056 - val_accuracy: 0.4719 - val_loss: 0.7333\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5008 - loss: 0.7067 - val_accuracy: 0.4878 - val_loss: 0.7841\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5067 - loss: 0.7110 - val_accuracy: 0.4859 - val_loss: 0.7915\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 32, lr: 0.05\n",
      "Best accuracy for current run: 0.5131332278251648 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4995 - loss: 0.6987 - val_accuracy: 0.5009 - val_loss: 0.6937\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5136 - loss: 0.6940 - val_accuracy: 0.5019 - val_loss: 0.6935\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5183 - loss: 0.6934 - val_accuracy: 0.5103 - val_loss: 0.6938\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5130 - loss: 0.6929 - val_accuracy: 0.5019 - val_loss: 0.6937\n",
      "Epoch 5/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5147 - loss: 0.6926 - val_accuracy: 0.4991 - val_loss: 0.6944\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 32, lr: 0.05\n",
      "Best accuracy for current run: 0.51031893491745 at epoch 2\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4882 - loss: 0.7334 - val_accuracy: 0.5000 - val_loss: 0.8161\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4953 - loss: 0.7185 - val_accuracy: 0.5000 - val_loss: 0.9049\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4957 - loss: 0.7224 - val_accuracy: 0.5000 - val_loss: 0.9405\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5018 - loss: 0.7243 - val_accuracy: 0.5000 - val_loss: 0.9238\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 32, lr: 0.05\n",
      "Best accuracy for current run: 0.5 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4961 - loss: 0.6983 - val_accuracy: 0.4606 - val_loss: 0.7088\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4965 - loss: 0.6949 - val_accuracy: 0.4812 - val_loss: 0.6942\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4884 - loss: 0.6937 - val_accuracy: 0.4794 - val_loss: 0.6947\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4886 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6956\n",
      "Epoch 5/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4981 - loss: 0.6935 - val_accuracy: 0.4887 - val_loss: 0.6953\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 32, lr: 0.05\n",
      "Best accuracy for current run: 0.48874297738075256 at epoch 4\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4976 - loss: 0.7303 - val_accuracy: 0.4906 - val_loss: 0.7266\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5004 - loss: 0.7155 - val_accuracy: 0.4775 - val_loss: 0.7090\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5145 - loss: 0.7103 - val_accuracy: 0.4944 - val_loss: 0.7038\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5140 - loss: 0.7092 - val_accuracy: 0.5038 - val_loss: 0.7014\n",
      "Epoch 5/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5082 - loss: 0.7100 - val_accuracy: 0.4925 - val_loss: 0.7068\n",
      "Epoch 6/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5141 - loss: 0.7103 - val_accuracy: 0.4916 - val_loss: 0.7051\n",
      "Epoch 7/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5098 - loss: 0.7116 - val_accuracy: 0.4934 - val_loss: 0.7056\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 32, lr: 0.1\n",
      "Best accuracy for current run: 0.5037523508071899 at epoch 3\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4987 - loss: 0.6988 - val_accuracy: 0.4944 - val_loss: 0.6938\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5089 - loss: 0.6945 - val_accuracy: 0.4916 - val_loss: 0.6942\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5103 - loss: 0.6940 - val_accuracy: 0.4681 - val_loss: 0.6946\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5063 - loss: 0.6938 - val_accuracy: 0.4822 - val_loss: 0.6950\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 32, lr: 0.1\n",
      "Best accuracy for current run: 0.4943714737892151 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5129 - loss: 0.7625 - val_accuracy: 0.5000 - val_loss: 0.7290\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5095 - loss: 0.7867 - val_accuracy: 0.5000 - val_loss: 0.7243\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5153 - loss: 0.7547 - val_accuracy: 0.5000 - val_loss: 1.0214\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5009 - loss: 0.7453 - val_accuracy: 0.5000 - val_loss: 0.7611\n",
      "Epoch 5/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4994 - loss: 0.7495 - val_accuracy: 0.4859 - val_loss: 0.7731\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 32, lr: 0.1\n",
      "Best accuracy for current run: 0.5 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4926 - loss: 0.6995 - val_accuracy: 0.4597 - val_loss: 0.6939\n",
      "Epoch 2/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5110 - loss: 0.6937 - val_accuracy: 0.4775 - val_loss: 0.6941\n",
      "Epoch 3/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5085 - loss: 0.6934 - val_accuracy: 0.4822 - val_loss: 0.6938\n",
      "Epoch 4/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4985 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
      "Epoch 5/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4971 - loss: 0.6933 - val_accuracy: 0.4897 - val_loss: 0.6936\n",
      "Epoch 6/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4931 - loss: 0.6934 - val_accuracy: 0.4972 - val_loss: 0.6937\n",
      "Epoch 7/100\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4958 - loss: 0.6933 - val_accuracy: 0.4925 - val_loss: 0.6937\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 32, lr: 0.1\n",
      "Best accuracy for current run: 0.5 at epoch 3\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5014 - loss: 0.6961 - val_accuracy: 0.5038 - val_loss: 0.6933\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5032 - loss: 0.6936 - val_accuracy: 0.4953 - val_loss: 0.6934\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5048 - loss: 0.6935 - val_accuracy: 0.5038 - val_loss: 0.6927\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4984 - loss: 0.6933 - val_accuracy: 0.4991 - val_loss: 0.6933\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4979 - loss: 0.6933 - val_accuracy: 0.5197 - val_loss: 0.6922\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4950 - loss: 0.6932 - val_accuracy: 0.4709 - val_loss: 0.6993\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5086 - loss: 0.6939 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4952 - loss: 0.6935 - val_accuracy: 0.5009 - val_loss: 0.6935\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 64, lr: 0.005\n",
      "Best accuracy for current run: 0.5196998119354248 at epoch 4\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4957 - loss: 0.6982 - val_accuracy: 0.5507 - val_loss: 0.6884\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5115 - loss: 0.6937 - val_accuracy: 0.5469 - val_loss: 0.6864\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5208 - loss: 0.6912 - val_accuracy: 0.5657 - val_loss: 0.6845\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5438 - loss: 0.6880 - val_accuracy: 0.5685 - val_loss: 0.6841\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5620 - loss: 0.6848 - val_accuracy: 0.5797 - val_loss: 0.6833\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5721 - loss: 0.6821 - val_accuracy: 0.5760 - val_loss: 0.6814\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5741 - loss: 0.6796 - val_accuracy: 0.5807 - val_loss: 0.6799\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5806 - loss: 0.6771 - val_accuracy: 0.5816 - val_loss: 0.6785\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 0.6747 - val_accuracy: 0.5835 - val_loss: 0.6767\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5930 - loss: 0.6724 - val_accuracy: 0.5863 - val_loss: 0.6742\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5985 - loss: 0.6700 - val_accuracy: 0.5901 - val_loss: 0.6713\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6004 - loss: 0.6676 - val_accuracy: 0.6004 - val_loss: 0.6681\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6056 - loss: 0.6652 - val_accuracy: 0.6098 - val_loss: 0.6647\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6081 - loss: 0.6628 - val_accuracy: 0.6135 - val_loss: 0.6614\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6161 - loss: 0.6604 - val_accuracy: 0.6229 - val_loss: 0.6583\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: 0.6580 - val_accuracy: 0.6304 - val_loss: 0.6554\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6261 - loss: 0.6556 - val_accuracy: 0.6332 - val_loss: 0.6529\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6274 - loss: 0.6531 - val_accuracy: 0.6360 - val_loss: 0.6506\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6320 - loss: 0.6505 - val_accuracy: 0.6351 - val_loss: 0.6484\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6317 - loss: 0.6478 - val_accuracy: 0.6379 - val_loss: 0.6466\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6355 - loss: 0.6452 - val_accuracy: 0.6379 - val_loss: 0.6452\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6402 - loss: 0.6427 - val_accuracy: 0.6445 - val_loss: 0.6442\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6427 - loss: 0.6400 - val_accuracy: 0.6445 - val_loss: 0.6419\n",
      "Epoch 24/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6457 - loss: 0.6377 - val_accuracy: 0.6398 - val_loss: 0.6390\n",
      "Epoch 25/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6470 - loss: 0.6353 - val_accuracy: 0.6407 - val_loss: 0.6373\n",
      "Epoch 26/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6521 - loss: 0.6329 - val_accuracy: 0.6332 - val_loss: 0.6340\n",
      "Epoch 27/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6538 - loss: 0.6299 - val_accuracy: 0.6332 - val_loss: 0.6319\n",
      "Epoch 28/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6548 - loss: 0.6274 - val_accuracy: 0.6398 - val_loss: 0.6306\n",
      "Epoch 29/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6616 - loss: 0.6239 - val_accuracy: 0.6435 - val_loss: 0.6291\n",
      "Epoch 30/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6619 - loss: 0.6217 - val_accuracy: 0.6370 - val_loss: 0.6342\n",
      "Epoch 31/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6712 - loss: 0.6214 - val_accuracy: 0.6473 - val_loss: 0.6290\n",
      "Epoch 32/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6745 - loss: 0.6183 - val_accuracy: 0.6332 - val_loss: 0.6322\n",
      "Epoch 33/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6738 - loss: 0.6199 - val_accuracy: 0.6426 - val_loss: 0.6335\n",
      "Epoch 34/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6789 - loss: 0.6175 - val_accuracy: 0.6510 - val_loss: 0.6286\n",
      "Epoch 35/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6753 - loss: 0.6105 - val_accuracy: 0.6463 - val_loss: 0.6339\n",
      "Epoch 36/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6800 - loss: 0.6144 - val_accuracy: 0.6492 - val_loss: 0.6284\n",
      "Epoch 37/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6835 - loss: 0.6085 - val_accuracy: 0.6529 - val_loss: 0.6261\n",
      "Epoch 38/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6827 - loss: 0.6059 - val_accuracy: 0.6482 - val_loss: 0.6256\n",
      "Epoch 39/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6861 - loss: 0.6077 - val_accuracy: 0.6576 - val_loss: 0.6266\n",
      "Epoch 40/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6885 - loss: 0.6055 - val_accuracy: 0.6426 - val_loss: 0.6256\n",
      "Epoch 41/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6831 - loss: 0.6025 - val_accuracy: 0.6360 - val_loss: 0.6332\n",
      "Epoch 42/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.6025 - val_accuracy: 0.6407 - val_loss: 0.6206\n",
      "Epoch 43/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6910 - loss: 0.6017 - val_accuracy: 0.6463 - val_loss: 0.6240\n",
      "Epoch 44/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.6030 - val_accuracy: 0.6557 - val_loss: 0.6192\n",
      "Epoch 45/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.5990 - val_accuracy: 0.6717 - val_loss: 0.6174\n",
      "Epoch 46/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6943 - loss: 0.5978 - val_accuracy: 0.6567 - val_loss: 0.6205\n",
      "Epoch 47/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6976 - loss: 0.5963 - val_accuracy: 0.6660 - val_loss: 0.6130\n",
      "Epoch 48/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6996 - loss: 0.5931 - val_accuracy: 0.6473 - val_loss: 0.6190\n",
      "Epoch 49/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6952 - loss: 0.5937 - val_accuracy: 0.6679 - val_loss: 0.6137\n",
      "Epoch 50/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7018 - loss: 0.5876 - val_accuracy: 0.6614 - val_loss: 0.6138\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 64, lr: 0.005\n",
      "Best accuracy for current run: 0.6716697812080383 at epoch 44\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5062 - loss: 0.6960 - val_accuracy: 0.5206 - val_loss: 0.6927\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4964 - loss: 0.6942 - val_accuracy: 0.4972 - val_loss: 0.6932\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4990 - loss: 0.6937 - val_accuracy: 0.4841 - val_loss: 0.6934\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4995 - loss: 0.6936 - val_accuracy: 0.4906 - val_loss: 0.6936\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 64, lr: 0.005\n",
      "Best accuracy for current run: 0.5206378698348999 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5025 - loss: 0.6964 - val_accuracy: 0.5732 - val_loss: 0.6842\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5430 - loss: 0.6879 - val_accuracy: 0.5835 - val_loss: 0.6773\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5737 - loss: 0.6802 - val_accuracy: 0.5976 - val_loss: 0.6709\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5873 - loss: 0.6735 - val_accuracy: 0.6060 - val_loss: 0.6651\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6003 - loss: 0.6679 - val_accuracy: 0.6135 - val_loss: 0.6596\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6086 - loss: 0.6629 - val_accuracy: 0.6163 - val_loss: 0.6552\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6148 - loss: 0.6584 - val_accuracy: 0.6238 - val_loss: 0.6515\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6238 - loss: 0.6541 - val_accuracy: 0.6285 - val_loss: 0.6484\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6285 - loss: 0.6501 - val_accuracy: 0.6285 - val_loss: 0.6458\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6341 - loss: 0.6461 - val_accuracy: 0.6285 - val_loss: 0.6434\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6383 - loss: 0.6421 - val_accuracy: 0.6313 - val_loss: 0.6411\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6440 - loss: 0.6383 - val_accuracy: 0.6323 - val_loss: 0.6389\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6492 - loss: 0.6346 - val_accuracy: 0.6426 - val_loss: 0.6367\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6550 - loss: 0.6312 - val_accuracy: 0.6435 - val_loss: 0.6345\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6582 - loss: 0.6280 - val_accuracy: 0.6463 - val_loss: 0.6323\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6604 - loss: 0.6251 - val_accuracy: 0.6529 - val_loss: 0.6302\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6645 - loss: 0.6223 - val_accuracy: 0.6548 - val_loss: 0.6281\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6700 - loss: 0.6197 - val_accuracy: 0.6623 - val_loss: 0.6260\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6727 - loss: 0.6172 - val_accuracy: 0.6614 - val_loss: 0.6242\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6764 - loss: 0.6149 - val_accuracy: 0.6642 - val_loss: 0.6225\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6793 - loss: 0.6126 - val_accuracy: 0.6642 - val_loss: 0.6210\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6817 - loss: 0.6105 - val_accuracy: 0.6651 - val_loss: 0.6197\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6842 - loss: 0.6084 - val_accuracy: 0.6679 - val_loss: 0.6184\n",
      "Epoch 24/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6867 - loss: 0.6064 - val_accuracy: 0.6689 - val_loss: 0.6173\n",
      "Epoch 25/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6897 - loss: 0.6045 - val_accuracy: 0.6660 - val_loss: 0.6162\n",
      "Epoch 26/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6915 - loss: 0.6026 - val_accuracy: 0.6651 - val_loss: 0.6153\n",
      "Epoch 27/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6934 - loss: 0.6008 - val_accuracy: 0.6651 - val_loss: 0.6145\n",
      "Epoch 28/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6955 - loss: 0.5991 - val_accuracy: 0.6679 - val_loss: 0.6137\n",
      "Epoch 29/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6965 - loss: 0.5975 - val_accuracy: 0.6698 - val_loss: 0.6131\n",
      "Epoch 30/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6979 - loss: 0.5959 - val_accuracy: 0.6707 - val_loss: 0.6126\n",
      "Epoch 31/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6989 - loss: 0.5944 - val_accuracy: 0.6735 - val_loss: 0.6121\n",
      "Epoch 32/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7034 - loss: 0.5929 - val_accuracy: 0.6754 - val_loss: 0.6117\n",
      "Epoch 33/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7032 - loss: 0.5916 - val_accuracy: 0.6764 - val_loss: 0.6113\n",
      "Epoch 34/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7056 - loss: 0.5902 - val_accuracy: 0.6801 - val_loss: 0.6109\n",
      "Epoch 35/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7077 - loss: 0.5889 - val_accuracy: 0.6839 - val_loss: 0.6106\n",
      "Epoch 36/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7087 - loss: 0.5876 - val_accuracy: 0.6839 - val_loss: 0.6102\n",
      "Epoch 37/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7093 - loss: 0.5863 - val_accuracy: 0.6829 - val_loss: 0.6100\n",
      "Epoch 38/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7087 - loss: 0.5850 - val_accuracy: 0.6857 - val_loss: 0.6097\n",
      "Epoch 39/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7095 - loss: 0.5837 - val_accuracy: 0.6867 - val_loss: 0.6095\n",
      "Epoch 40/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7096 - loss: 0.5824 - val_accuracy: 0.6857 - val_loss: 0.6093\n",
      "Epoch 41/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7118 - loss: 0.5812 - val_accuracy: 0.6848 - val_loss: 0.6091\n",
      "Epoch 42/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7139 - loss: 0.5800 - val_accuracy: 0.6857 - val_loss: 0.6090\n",
      "Epoch 43/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7142 - loss: 0.5787 - val_accuracy: 0.6867 - val_loss: 0.6088\n",
      "Epoch 44/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.5775 - val_accuracy: 0.6867 - val_loss: 0.6087\n",
      "Epoch 45/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7148 - loss: 0.5763 - val_accuracy: 0.6876 - val_loss: 0.6085\n",
      "Epoch 46/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7148 - loss: 0.5753 - val_accuracy: 0.6895 - val_loss: 0.6083\n",
      "Epoch 47/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7159 - loss: 0.5743 - val_accuracy: 0.6895 - val_loss: 0.6081\n",
      "Epoch 48/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7170 - loss: 0.5733 - val_accuracy: 0.6904 - val_loss: 0.6080\n",
      "Epoch 49/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7175 - loss: 0.5723 - val_accuracy: 0.6923 - val_loss: 0.6078\n",
      "Epoch 50/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7201 - loss: 0.5714 - val_accuracy: 0.6923 - val_loss: 0.6076\n",
      "Epoch 51/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7200 - loss: 0.5705 - val_accuracy: 0.6904 - val_loss: 0.6074\n",
      "Epoch 52/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7214 - loss: 0.5696 - val_accuracy: 0.6904 - val_loss: 0.6072\n",
      "Epoch 53/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7214 - loss: 0.5688 - val_accuracy: 0.6904 - val_loss: 0.6070\n",
      "Epoch 54/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7230 - loss: 0.5680 - val_accuracy: 0.6895 - val_loss: 0.6068\n",
      "Epoch 55/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7238 - loss: 0.5672 - val_accuracy: 0.6895 - val_loss: 0.6067\n",
      "Epoch 56/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7244 - loss: 0.5665 - val_accuracy: 0.6914 - val_loss: 0.6065\n",
      "Epoch 57/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7254 - loss: 0.5657 - val_accuracy: 0.6904 - val_loss: 0.6063\n",
      "Epoch 58/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7260 - loss: 0.5650 - val_accuracy: 0.6914 - val_loss: 0.6062\n",
      "Epoch 59/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7256 - loss: 0.5642 - val_accuracy: 0.6932 - val_loss: 0.6061\n",
      "Epoch 60/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7269 - loss: 0.5635 - val_accuracy: 0.6932 - val_loss: 0.6060\n",
      "Epoch 61/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7262 - loss: 0.5628 - val_accuracy: 0.6914 - val_loss: 0.6059\n",
      "Epoch 62/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7277 - loss: 0.5621 - val_accuracy: 0.6914 - val_loss: 0.6058\n",
      "Epoch 63/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7297 - loss: 0.5615 - val_accuracy: 0.6886 - val_loss: 0.6057\n",
      "Epoch 64/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7307 - loss: 0.5608 - val_accuracy: 0.6886 - val_loss: 0.6056\n",
      "Epoch 65/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7308 - loss: 0.5602 - val_accuracy: 0.6895 - val_loss: 0.6055\n",
      "Epoch 66/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7317 - loss: 0.5595 - val_accuracy: 0.6904 - val_loss: 0.6054\n",
      "Epoch 67/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7317 - loss: 0.5589 - val_accuracy: 0.6886 - val_loss: 0.6053\n",
      "Epoch 68/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7335 - loss: 0.5582 - val_accuracy: 0.6886 - val_loss: 0.6052\n",
      "Epoch 69/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.5576 - val_accuracy: 0.6895 - val_loss: 0.6051\n",
      "Epoch 70/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7344 - loss: 0.5569 - val_accuracy: 0.6904 - val_loss: 0.6050\n",
      "Epoch 71/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7343 - loss: 0.5563 - val_accuracy: 0.6886 - val_loss: 0.6049\n",
      "Epoch 72/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7352 - loss: 0.5557 - val_accuracy: 0.6886 - val_loss: 0.6048\n",
      "Epoch 73/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7354 - loss: 0.5551 - val_accuracy: 0.6876 - val_loss: 0.6047\n",
      "Epoch 74/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 0.5545 - val_accuracy: 0.6867 - val_loss: 0.6045\n",
      "Epoch 75/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.5539 - val_accuracy: 0.6848 - val_loss: 0.6044\n",
      "Epoch 76/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7350 - loss: 0.5532 - val_accuracy: 0.6848 - val_loss: 0.6042\n",
      "Epoch 77/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7361 - loss: 0.5526 - val_accuracy: 0.6857 - val_loss: 0.6040\n",
      "Epoch 78/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.5519 - val_accuracy: 0.6876 - val_loss: 0.6038\n",
      "Epoch 79/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7384 - loss: 0.5513 - val_accuracy: 0.6857 - val_loss: 0.6037\n",
      "Epoch 80/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7388 - loss: 0.5506 - val_accuracy: 0.6867 - val_loss: 0.6034\n",
      "Epoch 81/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.5499 - val_accuracy: 0.6876 - val_loss: 0.6033\n",
      "Epoch 82/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7376 - loss: 0.5493 - val_accuracy: 0.6876 - val_loss: 0.6031\n",
      "Epoch 83/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7381 - loss: 0.5486 - val_accuracy: 0.6867 - val_loss: 0.6029\n",
      "Epoch 84/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7389 - loss: 0.5480 - val_accuracy: 0.6857 - val_loss: 0.6027\n",
      "Epoch 85/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 0.5474 - val_accuracy: 0.6857 - val_loss: 0.6025\n",
      "Epoch 86/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 0.5467 - val_accuracy: 0.6867 - val_loss: 0.6024\n",
      "Epoch 87/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.5461 - val_accuracy: 0.6876 - val_loss: 0.6022\n",
      "Epoch 88/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.5455 - val_accuracy: 0.6886 - val_loss: 0.6021\n",
      "Epoch 89/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7392 - loss: 0.5449 - val_accuracy: 0.6895 - val_loss: 0.6020\n",
      "Epoch 90/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7394 - loss: 0.5443 - val_accuracy: 0.6895 - val_loss: 0.6019\n",
      "Epoch 91/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7400 - loss: 0.5436 - val_accuracy: 0.6895 - val_loss: 0.6019\n",
      "Epoch 92/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7406 - loss: 0.5430 - val_accuracy: 0.6914 - val_loss: 0.6018\n",
      "Epoch 93/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7405 - loss: 0.5424 - val_accuracy: 0.6914 - val_loss: 0.6019\n",
      "Epoch 94/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7409 - loss: 0.5418 - val_accuracy: 0.6914 - val_loss: 0.6019\n",
      "Epoch 95/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7412 - loss: 0.5412 - val_accuracy: 0.6914 - val_loss: 0.6019\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 64, lr: 0.005\n",
      "Best accuracy for current run: 0.6932457685470581 at epoch 58\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5097 - loss: 0.6971 - val_accuracy: 0.5066 - val_loss: 0.6931\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5080 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5007 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5044 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 64, lr: 0.01\n",
      "Best accuracy for current run: 0.50656658411026 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4979 - loss: 0.6977 - val_accuracy: 0.5356 - val_loss: 0.6888\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5182 - loss: 0.6924 - val_accuracy: 0.5338 - val_loss: 0.6905\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5394 - loss: 0.6882 - val_accuracy: 0.5338 - val_loss: 0.6976\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5633 - loss: 0.6843 - val_accuracy: 0.5432 - val_loss: 0.6953\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 64, lr: 0.01\n",
      "Best accuracy for current run: 0.5431519746780396 at epoch 3\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5055 - loss: 0.7014 - val_accuracy: 0.5000 - val_loss: 0.6949\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5091 - loss: 0.6940 - val_accuracy: 0.4925 - val_loss: 0.6932\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4990 - loss: 0.6937 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5074 - loss: 0.6934 - val_accuracy: 0.4934 - val_loss: 0.6933\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5079 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 64, lr: 0.01\n",
      "Best accuracy for current run: 0.5 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5036 - loss: 0.6959 - val_accuracy: 0.5338 - val_loss: 0.6941\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5619 - loss: 0.6842 - val_accuracy: 0.5694 - val_loss: 0.6839\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5959 - loss: 0.6715 - val_accuracy: 0.6088 - val_loss: 0.6651\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 0.6607 - val_accuracy: 0.6351 - val_loss: 0.6517\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6293 - loss: 0.6513 - val_accuracy: 0.6313 - val_loss: 0.6430\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6421 - loss: 0.6423 - val_accuracy: 0.6332 - val_loss: 0.6367\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6500 - loss: 0.6339 - val_accuracy: 0.6388 - val_loss: 0.6310\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6603 - loss: 0.6264 - val_accuracy: 0.6473 - val_loss: 0.6255\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6699 - loss: 0.6195 - val_accuracy: 0.6538 - val_loss: 0.6219\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.6131 - val_accuracy: 0.6651 - val_loss: 0.6194\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6862 - loss: 0.6070 - val_accuracy: 0.6717 - val_loss: 0.6165\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6941 - loss: 0.6016 - val_accuracy: 0.6745 - val_loss: 0.6140\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.5964 - val_accuracy: 0.6801 - val_loss: 0.6119\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7001 - loss: 0.5918 - val_accuracy: 0.6782 - val_loss: 0.6108\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.5891 - val_accuracy: 0.6754 - val_loss: 0.6096\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7066 - loss: 0.5849 - val_accuracy: 0.6735 - val_loss: 0.6090\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7087 - loss: 0.5811 - val_accuracy: 0.6773 - val_loss: 0.6079\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7108 - loss: 0.5784 - val_accuracy: 0.6745 - val_loss: 0.6075\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7140 - loss: 0.5757 - val_accuracy: 0.6754 - val_loss: 0.6067\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 0.5748 - val_accuracy: 0.6792 - val_loss: 0.6066\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 0.5699 - val_accuracy: 0.6792 - val_loss: 0.6068\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7224 - loss: 0.5670 - val_accuracy: 0.6857 - val_loss: 0.6069\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.5652 - val_accuracy: 0.6811 - val_loss: 0.6062\n",
      "Epoch 24/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7208 - loss: 0.5672 - val_accuracy: 0.6801 - val_loss: 0.6064\n",
      "Epoch 25/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7280 - loss: 0.5617 - val_accuracy: 0.6820 - val_loss: 0.6068\n",
      "Epoch 26/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7291 - loss: 0.5581 - val_accuracy: 0.6801 - val_loss: 0.6056\n",
      "Epoch 27/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7301 - loss: 0.5572 - val_accuracy: 0.6829 - val_loss: 0.6072\n",
      "Epoch 28/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7311 - loss: 0.5545 - val_accuracy: 0.6839 - val_loss: 0.6068\n",
      "Epoch 29/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.5526 - val_accuracy: 0.6820 - val_loss: 0.6061\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 64, lr: 0.01\n",
      "Best accuracy for current run: 0.6857410669326782 at epoch 21\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5178 - loss: 0.7065 - val_accuracy: 0.5000 - val_loss: 0.7174\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4973 - loss: 0.7034 - val_accuracy: 0.5000 - val_loss: 0.7238\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4997 - loss: 0.7069 - val_accuracy: 0.5000 - val_loss: 0.7128\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5079 - loss: 0.7054 - val_accuracy: 0.5000 - val_loss: 0.7109\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5110 - loss: 0.7052 - val_accuracy: 0.5122 - val_loss: 0.7157\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5096 - loss: 0.6999 - val_accuracy: 0.5000 - val_loss: 0.7209\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4944 - loss: 0.7072 - val_accuracy: 0.5000 - val_loss: 0.7176\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 64, lr: 0.05\n",
      "Best accuracy for current run: 0.5121951103210449 at epoch 4\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4983 - loss: 0.6980 - val_accuracy: 0.5084 - val_loss: 0.6933\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5133 - loss: 0.6936 - val_accuracy: 0.5178 - val_loss: 0.6932\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5222 - loss: 0.6925 - val_accuracy: 0.4972 - val_loss: 0.7052\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5259 - loss: 0.6920 - val_accuracy: 0.5169 - val_loss: 0.6978\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5481 - loss: 0.6873 - val_accuracy: 0.5216 - val_loss: 0.6987\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 64, lr: 0.05\n",
      "Best accuracy for current run: 0.5215759873390198 at epoch 4\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5074 - loss: 0.7242 - val_accuracy: 0.4981 - val_loss: 0.7042\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4907 - loss: 0.7128 - val_accuracy: 0.5075 - val_loss: 0.7146\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5058 - loss: 0.7097 - val_accuracy: 0.5000 - val_loss: 0.9271\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5047 - loss: 0.7205 - val_accuracy: 0.4681 - val_loss: 0.7157\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 64, lr: 0.05\n",
      "Best accuracy for current run: 0.5075047016143799 at epoch 1\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4999 - loss: 0.6979 - val_accuracy: 0.5094 - val_loss: 0.6934\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5077 - loss: 0.6937 - val_accuracy: 0.4859 - val_loss: 0.6943\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5047 - loss: 0.6935 - val_accuracy: 0.4869 - val_loss: 0.6942\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5149 - loss: 0.6930 - val_accuracy: 0.4906 - val_loss: 0.6943\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 64, lr: 0.05\n",
      "Best accuracy for current run: 0.5093808770179749 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5055 - loss: 0.7349 - val_accuracy: 0.4887 - val_loss: 0.7242\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5161 - loss: 0.7083 - val_accuracy: 0.4887 - val_loss: 0.7193\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5140 - loss: 0.7075 - val_accuracy: 0.4887 - val_loss: 0.7227\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5040 - loss: 0.7116 - val_accuracy: 0.4991 - val_loss: 0.7525\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4972 - loss: 0.7166 - val_accuracy: 0.4784 - val_loss: 0.7347\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 64, lr: 0.1\n",
      "Best accuracy for current run: 0.4990619122982025 at epoch 3\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5027 - loss: 0.6984 - val_accuracy: 0.5094 - val_loss: 0.6940\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5112 - loss: 0.6942 - val_accuracy: 0.4897 - val_loss: 0.6948\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5050 - loss: 0.6936 - val_accuracy: 0.4841 - val_loss: 0.6942\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5101 - loss: 0.6930 - val_accuracy: 0.4869 - val_loss: 0.6940\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5107 - loss: 0.6927 - val_accuracy: 0.4859 - val_loss: 0.6941\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5147 - loss: 0.6924 - val_accuracy: 0.4925 - val_loss: 0.6945\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5185 - loss: 0.6921 - val_accuracy: 0.4972 - val_loss: 0.6948\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 64, lr: 0.1\n",
      "Best accuracy for current run: 0.5093808770179749 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5008 - loss: 0.7664 - val_accuracy: 0.5131 - val_loss: 0.8338\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5037 - loss: 0.7387 - val_accuracy: 0.5225 - val_loss: 0.7636\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4972 - loss: 0.7375 - val_accuracy: 0.4934 - val_loss: 0.7714\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5074 - loss: 0.7705 - val_accuracy: 0.5009 - val_loss: 1.0652\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5087 - loss: 0.7795 - val_accuracy: 0.4981 - val_loss: 1.0027\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 64, lr: 0.1\n",
      "Best accuracy for current run: 0.5225140452384949 at epoch 1\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4984 - loss: 0.6986 - val_accuracy: 0.5038 - val_loss: 0.6943\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5096 - loss: 0.6938 - val_accuracy: 0.4822 - val_loss: 0.6942\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5106 - loss: 0.6937 - val_accuracy: 0.4662 - val_loss: 0.6948\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5108 - loss: 0.6935 - val_accuracy: 0.4615 - val_loss: 0.6953\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5059 - loss: 0.6935 - val_accuracy: 0.4550 - val_loss: 0.6956\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 64, lr: 0.1\n",
      "Best accuracy for current run: 0.5037523508071899 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5025 - loss: 0.6962 - val_accuracy: 0.5028 - val_loss: 0.6947\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5096 - loss: 0.6938 - val_accuracy: 0.4944 - val_loss: 0.6955\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5055 - loss: 0.6941 - val_accuracy: 0.4944 - val_loss: 0.6942\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4972 - loss: 0.6935 - val_accuracy: 0.4906 - val_loss: 0.6949\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5102 - loss: 0.6936 - val_accuracy: 0.5009 - val_loss: 0.6929\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4955 - loss: 0.6936 - val_accuracy: 0.4737 - val_loss: 0.6967\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4978 - loss: 0.6938 - val_accuracy: 0.5009 - val_loss: 0.6937\n",
      "Epoch 8/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4941 - loss: 0.6936 - val_accuracy: 0.4981 - val_loss: 0.6939\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 128, lr: 0.005\n",
      "Best accuracy for current run: 0.5028142333030701 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4962 - loss: 0.6988 - val_accuracy: 0.5159 - val_loss: 0.6896\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5048 - loss: 0.6955 - val_accuracy: 0.5310 - val_loss: 0.6880\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5124 - loss: 0.6938 - val_accuracy: 0.5629 - val_loss: 0.6866\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5194 - loss: 0.6922 - val_accuracy: 0.5704 - val_loss: 0.6848\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5292 - loss: 0.6905 - val_accuracy: 0.5797 - val_loss: 0.6826\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5367 - loss: 0.6885 - val_accuracy: 0.5872 - val_loss: 0.6800\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5482 - loss: 0.6863 - val_accuracy: 0.5994 - val_loss: 0.6777\n",
      "Epoch 8/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5615 - loss: 0.6845 - val_accuracy: 0.6013 - val_loss: 0.6759\n",
      "Epoch 9/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5679 - loss: 0.6828 - val_accuracy: 0.6023 - val_loss: 0.6743\n",
      "Epoch 10/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5717 - loss: 0.6814 - val_accuracy: 0.6023 - val_loss: 0.6729\n",
      "Epoch 11/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5750 - loss: 0.6799 - val_accuracy: 0.6060 - val_loss: 0.6716\n",
      "Epoch 12/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5774 - loss: 0.6785 - val_accuracy: 0.6079 - val_loss: 0.6705\n",
      "Epoch 13/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5806 - loss: 0.6771 - val_accuracy: 0.6088 - val_loss: 0.6694\n",
      "Epoch 14/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5826 - loss: 0.6758 - val_accuracy: 0.6060 - val_loss: 0.6685\n",
      "Epoch 15/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5872 - loss: 0.6745 - val_accuracy: 0.6079 - val_loss: 0.6676\n",
      "Epoch 16/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5874 - loss: 0.6732 - val_accuracy: 0.6098 - val_loss: 0.6667\n",
      "Epoch 17/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5909 - loss: 0.6720 - val_accuracy: 0.6116 - val_loss: 0.6659\n",
      "Epoch 18/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5930 - loss: 0.6707 - val_accuracy: 0.6088 - val_loss: 0.6650\n",
      "Epoch 19/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5950 - loss: 0.6695 - val_accuracy: 0.6116 - val_loss: 0.6641\n",
      "Epoch 20/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5976 - loss: 0.6683 - val_accuracy: 0.6191 - val_loss: 0.6632\n",
      "Epoch 21/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6021 - loss: 0.6671 - val_accuracy: 0.6238 - val_loss: 0.6623\n",
      "Epoch 22/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6037 - loss: 0.6659 - val_accuracy: 0.6248 - val_loss: 0.6613\n",
      "Epoch 23/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6084 - loss: 0.6647 - val_accuracy: 0.6266 - val_loss: 0.6604\n",
      "Epoch 24/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6109 - loss: 0.6635 - val_accuracy: 0.6257 - val_loss: 0.6594\n",
      "Epoch 25/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6127 - loss: 0.6624 - val_accuracy: 0.6266 - val_loss: 0.6585\n",
      "Epoch 26/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6143 - loss: 0.6613 - val_accuracy: 0.6276 - val_loss: 0.6576\n",
      "Epoch 27/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6165 - loss: 0.6601 - val_accuracy: 0.6229 - val_loss: 0.6567\n",
      "Epoch 28/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6172 - loss: 0.6590 - val_accuracy: 0.6266 - val_loss: 0.6558\n",
      "Epoch 29/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6197 - loss: 0.6579 - val_accuracy: 0.6248 - val_loss: 0.6549\n",
      "Epoch 30/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6218 - loss: 0.6568 - val_accuracy: 0.6238 - val_loss: 0.6540\n",
      "Epoch 31/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6220 - loss: 0.6556 - val_accuracy: 0.6210 - val_loss: 0.6530\n",
      "Epoch 32/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6224 - loss: 0.6544 - val_accuracy: 0.6182 - val_loss: 0.6520\n",
      "Epoch 33/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6232 - loss: 0.6532 - val_accuracy: 0.6173 - val_loss: 0.6510\n",
      "Epoch 34/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6238 - loss: 0.6520 - val_accuracy: 0.6201 - val_loss: 0.6499\n",
      "Epoch 35/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6247 - loss: 0.6507 - val_accuracy: 0.6201 - val_loss: 0.6489\n",
      "Epoch 36/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6269 - loss: 0.6493 - val_accuracy: 0.6220 - val_loss: 0.6477\n",
      "Epoch 37/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6291 - loss: 0.6480 - val_accuracy: 0.6257 - val_loss: 0.6466\n",
      "Epoch 38/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6304 - loss: 0.6466 - val_accuracy: 0.6276 - val_loss: 0.6455\n",
      "Epoch 39/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6341 - loss: 0.6451 - val_accuracy: 0.6304 - val_loss: 0.6445\n",
      "Epoch 40/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6348 - loss: 0.6437 - val_accuracy: 0.6313 - val_loss: 0.6435\n",
      "Epoch 41/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6382 - loss: 0.6424 - val_accuracy: 0.6285 - val_loss: 0.6426\n",
      "Epoch 42/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6387 - loss: 0.6411 - val_accuracy: 0.6304 - val_loss: 0.6418\n",
      "Epoch 43/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6400 - loss: 0.6398 - val_accuracy: 0.6295 - val_loss: 0.6410\n",
      "Epoch 44/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6409 - loss: 0.6386 - val_accuracy: 0.6304 - val_loss: 0.6403\n",
      "Epoch 45/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6427 - loss: 0.6374 - val_accuracy: 0.6323 - val_loss: 0.6395\n",
      "Epoch 46/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6458 - loss: 0.6361 - val_accuracy: 0.6360 - val_loss: 0.6387\n",
      "Epoch 47/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6459 - loss: 0.6348 - val_accuracy: 0.6388 - val_loss: 0.6378\n",
      "Epoch 48/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6474 - loss: 0.6336 - val_accuracy: 0.6398 - val_loss: 0.6369\n",
      "Epoch 49/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6478 - loss: 0.6322 - val_accuracy: 0.6398 - val_loss: 0.6361\n",
      "Epoch 50/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6490 - loss: 0.6309 - val_accuracy: 0.6407 - val_loss: 0.6353\n",
      "Epoch 51/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6526 - loss: 0.6295 - val_accuracy: 0.6379 - val_loss: 0.6344\n",
      "Epoch 52/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6541 - loss: 0.6282 - val_accuracy: 0.6407 - val_loss: 0.6335\n",
      "Epoch 53/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6568 - loss: 0.6270 - val_accuracy: 0.6492 - val_loss: 0.6326\n",
      "Epoch 54/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6579 - loss: 0.6259 - val_accuracy: 0.6557 - val_loss: 0.6318\n",
      "Epoch 55/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6601 - loss: 0.6247 - val_accuracy: 0.6557 - val_loss: 0.6311\n",
      "Epoch 56/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6606 - loss: 0.6233 - val_accuracy: 0.6548 - val_loss: 0.6305\n",
      "Epoch 57/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6632 - loss: 0.6216 - val_accuracy: 0.6520 - val_loss: 0.6292\n",
      "Epoch 58/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6669 - loss: 0.6199 - val_accuracy: 0.6510 - val_loss: 0.6281\n",
      "Epoch 59/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6716 - loss: 0.6183 - val_accuracy: 0.6501 - val_loss: 0.6276\n",
      "Epoch 60/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6721 - loss: 0.6172 - val_accuracy: 0.6529 - val_loss: 0.6268\n",
      "Epoch 61/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6745 - loss: 0.6157 - val_accuracy: 0.6529 - val_loss: 0.6266\n",
      "Epoch 62/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6757 - loss: 0.6144 - val_accuracy: 0.6538 - val_loss: 0.6258\n",
      "Epoch 63/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6763 - loss: 0.6135 - val_accuracy: 0.6538 - val_loss: 0.6252\n",
      "Epoch 64/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6809 - loss: 0.6118 - val_accuracy: 0.6529 - val_loss: 0.6253\n",
      "Epoch 65/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6805 - loss: 0.6113 - val_accuracy: 0.6567 - val_loss: 0.6239\n",
      "Epoch 66/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6802 - loss: 0.6101 - val_accuracy: 0.6595 - val_loss: 0.6232\n",
      "Epoch 67/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6821 - loss: 0.6089 - val_accuracy: 0.6614 - val_loss: 0.6223\n",
      "Epoch 68/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6839 - loss: 0.6074 - val_accuracy: 0.6604 - val_loss: 0.6216\n",
      "Epoch 69/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6827 - loss: 0.6061 - val_accuracy: 0.6623 - val_loss: 0.6221\n",
      "Epoch 70/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6847 - loss: 0.6044 - val_accuracy: 0.6614 - val_loss: 0.6229\n",
      "Epoch 71/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6854 - loss: 0.6034 - val_accuracy: 0.6651 - val_loss: 0.6220\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 128, lr: 0.005\n",
      "Best accuracy for current run: 0.6651031970977783 at epoch 70\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4944 - loss: 0.6966 - val_accuracy: 0.4747 - val_loss: 0.6955\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4953 - loss: 0.6940 - val_accuracy: 0.4756 - val_loss: 0.6944\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4941 - loss: 0.6957 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4981 - loss: 0.6944 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4936 - loss: 0.6940 - val_accuracy: 0.4991 - val_loss: 0.6941\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4988 - loss: 0.6936 - val_accuracy: 0.5028 - val_loss: 0.6935\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5075 - loss: 0.6934 - val_accuracy: 0.4916 - val_loss: 0.6940\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 128, lr: 0.005\n",
      "Best accuracy for current run: 0.5028142333030701 at epoch 5\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5006 - loss: 0.6975 - val_accuracy: 0.5460 - val_loss: 0.6868\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5220 - loss: 0.6918 - val_accuracy: 0.5863 - val_loss: 0.6813\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5433 - loss: 0.6870 - val_accuracy: 0.5994 - val_loss: 0.6758\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5698 - loss: 0.6824 - val_accuracy: 0.6098 - val_loss: 0.6720\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5756 - loss: 0.6784 - val_accuracy: 0.6182 - val_loss: 0.6688\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5833 - loss: 0.6748 - val_accuracy: 0.6182 - val_loss: 0.6660\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5920 - loss: 0.6714 - val_accuracy: 0.6182 - val_loss: 0.6634\n",
      "Epoch 8/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5978 - loss: 0.6683 - val_accuracy: 0.6116 - val_loss: 0.6609\n",
      "Epoch 9/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6050 - loss: 0.6654 - val_accuracy: 0.6107 - val_loss: 0.6586\n",
      "Epoch 10/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6061 - loss: 0.6626 - val_accuracy: 0.6088 - val_loss: 0.6565\n",
      "Epoch 11/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6088 - loss: 0.6600 - val_accuracy: 0.6154 - val_loss: 0.6544\n",
      "Epoch 12/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6148 - loss: 0.6573 - val_accuracy: 0.6210 - val_loss: 0.6526\n",
      "Epoch 13/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6215 - loss: 0.6547 - val_accuracy: 0.6201 - val_loss: 0.6508\n",
      "Epoch 14/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6274 - loss: 0.6522 - val_accuracy: 0.6201 - val_loss: 0.6492\n",
      "Epoch 15/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6298 - loss: 0.6496 - val_accuracy: 0.6229 - val_loss: 0.6476\n",
      "Epoch 16/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6321 - loss: 0.6471 - val_accuracy: 0.6266 - val_loss: 0.6461\n",
      "Epoch 17/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6354 - loss: 0.6445 - val_accuracy: 0.6276 - val_loss: 0.6445\n",
      "Epoch 18/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6419 - loss: 0.6420 - val_accuracy: 0.6276 - val_loss: 0.6429\n",
      "Epoch 19/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6436 - loss: 0.6394 - val_accuracy: 0.6351 - val_loss: 0.6412\n",
      "Epoch 20/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6478 - loss: 0.6369 - val_accuracy: 0.6351 - val_loss: 0.6395\n",
      "Epoch 21/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6496 - loss: 0.6345 - val_accuracy: 0.6370 - val_loss: 0.6378\n",
      "Epoch 22/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6540 - loss: 0.6322 - val_accuracy: 0.6379 - val_loss: 0.6361\n",
      "Epoch 23/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6571 - loss: 0.6300 - val_accuracy: 0.6388 - val_loss: 0.6344\n",
      "Epoch 24/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6580 - loss: 0.6278 - val_accuracy: 0.6407 - val_loss: 0.6328\n",
      "Epoch 25/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6591 - loss: 0.6258 - val_accuracy: 0.6417 - val_loss: 0.6311\n",
      "Epoch 26/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6619 - loss: 0.6237 - val_accuracy: 0.6463 - val_loss: 0.6296\n",
      "Epoch 27/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6649 - loss: 0.6218 - val_accuracy: 0.6473 - val_loss: 0.6281\n",
      "Epoch 28/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6669 - loss: 0.6199 - val_accuracy: 0.6492 - val_loss: 0.6266\n",
      "Epoch 29/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6709 - loss: 0.6180 - val_accuracy: 0.6492 - val_loss: 0.6252\n",
      "Epoch 30/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6719 - loss: 0.6162 - val_accuracy: 0.6510 - val_loss: 0.6238\n",
      "Epoch 31/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6729 - loss: 0.6145 - val_accuracy: 0.6576 - val_loss: 0.6225\n",
      "Epoch 32/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6756 - loss: 0.6128 - val_accuracy: 0.6604 - val_loss: 0.6212\n",
      "Epoch 33/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6780 - loss: 0.6112 - val_accuracy: 0.6632 - val_loss: 0.6200\n",
      "Epoch 34/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6796 - loss: 0.6096 - val_accuracy: 0.6642 - val_loss: 0.6189\n",
      "Epoch 35/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6821 - loss: 0.6081 - val_accuracy: 0.6670 - val_loss: 0.6178\n",
      "Epoch 36/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6844 - loss: 0.6066 - val_accuracy: 0.6670 - val_loss: 0.6168\n",
      "Epoch 37/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6859 - loss: 0.6051 - val_accuracy: 0.6679 - val_loss: 0.6159\n",
      "Epoch 38/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6874 - loss: 0.6037 - val_accuracy: 0.6679 - val_loss: 0.6150\n",
      "Epoch 39/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6895 - loss: 0.6023 - val_accuracy: 0.6707 - val_loss: 0.6142\n",
      "Epoch 40/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6892 - loss: 0.6009 - val_accuracy: 0.6717 - val_loss: 0.6135\n",
      "Epoch 41/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6908 - loss: 0.5995 - val_accuracy: 0.6754 - val_loss: 0.6128\n",
      "Epoch 42/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6916 - loss: 0.5982 - val_accuracy: 0.6773 - val_loss: 0.6122\n",
      "Epoch 43/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 0.5970 - val_accuracy: 0.6792 - val_loss: 0.6117\n",
      "Epoch 44/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6949 - loss: 0.5957 - val_accuracy: 0.6801 - val_loss: 0.6112\n",
      "Epoch 45/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6968 - loss: 0.5945 - val_accuracy: 0.6811 - val_loss: 0.6107\n",
      "Epoch 46/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6993 - loss: 0.5933 - val_accuracy: 0.6829 - val_loss: 0.6102\n",
      "Epoch 47/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6992 - loss: 0.5922 - val_accuracy: 0.6857 - val_loss: 0.6098\n",
      "Epoch 48/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7005 - loss: 0.5910 - val_accuracy: 0.6867 - val_loss: 0.6094\n",
      "Epoch 49/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7024 - loss: 0.5899 - val_accuracy: 0.6876 - val_loss: 0.6091\n",
      "Epoch 50/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7037 - loss: 0.5888 - val_accuracy: 0.6914 - val_loss: 0.6088\n",
      "Epoch 51/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7051 - loss: 0.5877 - val_accuracy: 0.6904 - val_loss: 0.6085\n",
      "Epoch 52/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7062 - loss: 0.5866 - val_accuracy: 0.6914 - val_loss: 0.6082\n",
      "Epoch 53/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.5856 - val_accuracy: 0.6923 - val_loss: 0.6079\n",
      "Epoch 54/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.5846 - val_accuracy: 0.6895 - val_loss: 0.6077\n",
      "Epoch 55/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7079 - loss: 0.5836 - val_accuracy: 0.6886 - val_loss: 0.6074\n",
      "Epoch 56/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7069 - loss: 0.5826 - val_accuracy: 0.6904 - val_loss: 0.6071\n",
      "Epoch 57/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7079 - loss: 0.5816 - val_accuracy: 0.6904 - val_loss: 0.6068\n",
      "Epoch 58/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.5807 - val_accuracy: 0.6904 - val_loss: 0.6065\n",
      "Epoch 59/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7122 - loss: 0.5797 - val_accuracy: 0.6895 - val_loss: 0.6062\n",
      "Epoch 60/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7129 - loss: 0.5787 - val_accuracy: 0.6914 - val_loss: 0.6059\n",
      "Epoch 61/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7130 - loss: 0.5778 - val_accuracy: 0.6914 - val_loss: 0.6055\n",
      "Epoch 62/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7126 - loss: 0.5768 - val_accuracy: 0.6904 - val_loss: 0.6052\n",
      "Epoch 63/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7144 - loss: 0.5759 - val_accuracy: 0.6923 - val_loss: 0.6048\n",
      "Epoch 64/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7144 - loss: 0.5750 - val_accuracy: 0.6904 - val_loss: 0.6044\n",
      "Epoch 65/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7164 - loss: 0.5741 - val_accuracy: 0.6914 - val_loss: 0.6040\n",
      "Epoch 66/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7173 - loss: 0.5732 - val_accuracy: 0.6932 - val_loss: 0.6037\n",
      "Epoch 67/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7183 - loss: 0.5723 - val_accuracy: 0.6932 - val_loss: 0.6033\n",
      "Epoch 68/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7193 - loss: 0.5715 - val_accuracy: 0.6923 - val_loss: 0.6030\n",
      "Epoch 69/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.5706 - val_accuracy: 0.6923 - val_loss: 0.6027\n",
      "Epoch 70/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7205 - loss: 0.5698 - val_accuracy: 0.6932 - val_loss: 0.6024\n",
      "Epoch 71/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7205 - loss: 0.5690 - val_accuracy: 0.6942 - val_loss: 0.6021\n",
      "Epoch 72/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.5682 - val_accuracy: 0.6951 - val_loss: 0.6018\n",
      "Epoch 73/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7218 - loss: 0.5674 - val_accuracy: 0.6923 - val_loss: 0.6015\n",
      "Epoch 74/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7226 - loss: 0.5666 - val_accuracy: 0.6932 - val_loss: 0.6012\n",
      "Epoch 75/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7230 - loss: 0.5658 - val_accuracy: 0.6942 - val_loss: 0.6009\n",
      "Epoch 76/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.5649 - val_accuracy: 0.6951 - val_loss: 0.6005\n",
      "Epoch 77/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.5641 - val_accuracy: 0.6932 - val_loss: 0.6001\n",
      "Epoch 78/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7233 - loss: 0.5633 - val_accuracy: 0.6961 - val_loss: 0.5997\n",
      "Epoch 79/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7239 - loss: 0.5624 - val_accuracy: 0.6951 - val_loss: 0.5994\n",
      "Epoch 80/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7238 - loss: 0.5616 - val_accuracy: 0.6951 - val_loss: 0.5991\n",
      "Epoch 81/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.5607 - val_accuracy: 0.6951 - val_loss: 0.5989\n",
      "Epoch 82/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7255 - loss: 0.5598 - val_accuracy: 0.6951 - val_loss: 0.5987\n",
      "Epoch 83/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7260 - loss: 0.5589 - val_accuracy: 0.6961 - val_loss: 0.5985\n",
      "Epoch 84/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7268 - loss: 0.5580 - val_accuracy: 0.6951 - val_loss: 0.5983\n",
      "Epoch 85/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7256 - loss: 0.5572 - val_accuracy: 0.6951 - val_loss: 0.5981\n",
      "Epoch 86/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7266 - loss: 0.5564 - val_accuracy: 0.6961 - val_loss: 0.5979\n",
      "Epoch 87/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7267 - loss: 0.5557 - val_accuracy: 0.6942 - val_loss: 0.5977\n",
      "Epoch 88/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7277 - loss: 0.5549 - val_accuracy: 0.6951 - val_loss: 0.5976\n",
      "Epoch 89/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7276 - loss: 0.5542 - val_accuracy: 0.6932 - val_loss: 0.5974\n",
      "Epoch 90/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7282 - loss: 0.5535 - val_accuracy: 0.6942 - val_loss: 0.5973\n",
      "Epoch 91/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7293 - loss: 0.5529 - val_accuracy: 0.6932 - val_loss: 0.5972\n",
      "Epoch 92/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7292 - loss: 0.5523 - val_accuracy: 0.6932 - val_loss: 0.5971\n",
      "Epoch 93/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7285 - loss: 0.5516 - val_accuracy: 0.6932 - val_loss: 0.5970\n",
      "Epoch 94/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7283 - loss: 0.5510 - val_accuracy: 0.6932 - val_loss: 0.5970\n",
      "Epoch 95/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7290 - loss: 0.5504 - val_accuracy: 0.6923 - val_loss: 0.5969\n",
      "Epoch 96/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7300 - loss: 0.5498 - val_accuracy: 0.6923 - val_loss: 0.5969\n",
      "Epoch 97/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7305 - loss: 0.5492 - val_accuracy: 0.6932 - val_loss: 0.5969\n",
      "Epoch 98/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7310 - loss: 0.5487 - val_accuracy: 0.6923 - val_loss: 0.5969\n",
      "Epoch 99/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7314 - loss: 0.5481 - val_accuracy: 0.6923 - val_loss: 0.5969\n",
      "Epoch 100/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7313 - loss: 0.5475 - val_accuracy: 0.6904 - val_loss: 0.5970\n",
      "Saved best accuracy for current run: 0.696060061454773 at epoch 77\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 128, lr: 0.005\n",
      "Best accuracy for current run: 0.696060061454773 at epoch 77\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5080 - loss: 0.6965 - val_accuracy: 0.4925 - val_loss: 0.6936\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6935 - val_accuracy: 0.4934 - val_loss: 0.6941\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4963 - loss: 0.6935 - val_accuracy: 0.4962 - val_loss: 0.6937\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4984 - loss: 0.6934 - val_accuracy: 0.4953 - val_loss: 0.6937\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 128, lr: 0.01\n",
      "Best accuracy for current run: 0.49624764919281006 at epoch 2\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4940 - loss: 0.6982 - val_accuracy: 0.5338 - val_loss: 0.6881\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5054 - loss: 0.6938 - val_accuracy: 0.5629 - val_loss: 0.6857\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5225 - loss: 0.6912 - val_accuracy: 0.5807 - val_loss: 0.6823\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5396 - loss: 0.6878 - val_accuracy: 0.5816 - val_loss: 0.6794\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5654 - loss: 0.6845 - val_accuracy: 0.5816 - val_loss: 0.6777\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5710 - loss: 0.6817 - val_accuracy: 0.5863 - val_loss: 0.6761\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5723 - loss: 0.6791 - val_accuracy: 0.5835 - val_loss: 0.6749\n",
      "Epoch 8/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5818 - loss: 0.6768 - val_accuracy: 0.5816 - val_loss: 0.6740\n",
      "Epoch 9/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5847 - loss: 0.6745 - val_accuracy: 0.5854 - val_loss: 0.6731\n",
      "Epoch 10/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5893 - loss: 0.6724 - val_accuracy: 0.5882 - val_loss: 0.6720\n",
      "Epoch 11/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5946 - loss: 0.6703 - val_accuracy: 0.5910 - val_loss: 0.6709\n",
      "Epoch 12/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5997 - loss: 0.6680 - val_accuracy: 0.5910 - val_loss: 0.6695\n",
      "Epoch 13/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6042 - loss: 0.6656 - val_accuracy: 0.5994 - val_loss: 0.6672\n",
      "Epoch 14/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6085 - loss: 0.6631 - val_accuracy: 0.6107 - val_loss: 0.6636\n",
      "Epoch 15/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6137 - loss: 0.6607 - val_accuracy: 0.6191 - val_loss: 0.6598\n",
      "Epoch 16/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6187 - loss: 0.6584 - val_accuracy: 0.6238 - val_loss: 0.6562\n",
      "Epoch 17/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6241 - loss: 0.6561 - val_accuracy: 0.6313 - val_loss: 0.6531\n",
      "Epoch 18/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6266 - loss: 0.6536 - val_accuracy: 0.6304 - val_loss: 0.6504\n",
      "Epoch 19/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6305 - loss: 0.6509 - val_accuracy: 0.6266 - val_loss: 0.6474\n",
      "Epoch 20/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6294 - loss: 0.6482 - val_accuracy: 0.6341 - val_loss: 0.6448\n",
      "Epoch 21/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6315 - loss: 0.6457 - val_accuracy: 0.6313 - val_loss: 0.6431\n",
      "Epoch 22/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6362 - loss: 0.6434 - val_accuracy: 0.6285 - val_loss: 0.6412\n",
      "Epoch 23/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6373 - loss: 0.6410 - val_accuracy: 0.6285 - val_loss: 0.6410\n",
      "Epoch 24/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6409 - loss: 0.6387 - val_accuracy: 0.6313 - val_loss: 0.6386\n",
      "Epoch 25/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6429 - loss: 0.6358 - val_accuracy: 0.6351 - val_loss: 0.6335\n",
      "Epoch 26/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6437 - loss: 0.6336 - val_accuracy: 0.6332 - val_loss: 0.6337\n",
      "Epoch 27/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6499 - loss: 0.6304 - val_accuracy: 0.6341 - val_loss: 0.6317\n",
      "Epoch 28/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6513 - loss: 0.6282 - val_accuracy: 0.6435 - val_loss: 0.6332\n",
      "Epoch 29/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6525 - loss: 0.6275 - val_accuracy: 0.6341 - val_loss: 0.6311\n",
      "Epoch 30/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6540 - loss: 0.6232 - val_accuracy: 0.6473 - val_loss: 0.6286\n",
      "Epoch 31/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6590 - loss: 0.6213 - val_accuracy: 0.6482 - val_loss: 0.6271\n",
      "Epoch 32/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6716 - loss: 0.6175 - val_accuracy: 0.6426 - val_loss: 0.6269\n",
      "Epoch 33/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6748 - loss: 0.6170 - val_accuracy: 0.6445 - val_loss: 0.6275\n",
      "Epoch 34/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6680 - loss: 0.6151 - val_accuracy: 0.6388 - val_loss: 0.6249\n",
      "Epoch 35/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6741 - loss: 0.6144 - val_accuracy: 0.6529 - val_loss: 0.6264\n",
      "Epoch 36/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6793 - loss: 0.6130 - val_accuracy: 0.6417 - val_loss: 0.6273\n",
      "Epoch 37/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6803 - loss: 0.6074 - val_accuracy: 0.6388 - val_loss: 0.6231\n",
      "Epoch 38/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.6083 - val_accuracy: 0.6473 - val_loss: 0.6238\n",
      "Epoch 39/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6778 - loss: 0.6142 - val_accuracy: 0.6407 - val_loss: 0.6303\n",
      "Epoch 40/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6876 - loss: 0.6057 - val_accuracy: 0.6341 - val_loss: 0.6282\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 128, lr: 0.01\n",
      "Best accuracy for current run: 0.6529080867767334 at epoch 34\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5005 - loss: 0.6972 - val_accuracy: 0.5028 - val_loss: 0.6934\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5019 - loss: 0.6947 - val_accuracy: 0.4962 - val_loss: 0.6932\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4963 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4955 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4929 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 128, lr: 0.01\n",
      "Best accuracy for current run: 0.5028142333030701 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.5042 - loss: 0.6968 - val_accuracy: 0.5694 - val_loss: 0.6846\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5374 - loss: 0.6887 - val_accuracy: 0.5760 - val_loss: 0.6800\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5725 - loss: 0.6807 - val_accuracy: 0.5844 - val_loss: 0.6741\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5869 - loss: 0.6739 - val_accuracy: 0.5966 - val_loss: 0.6684\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5973 - loss: 0.6676 - val_accuracy: 0.6107 - val_loss: 0.6618\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6119 - loss: 0.6617 - val_accuracy: 0.6276 - val_loss: 0.6554\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6171 - loss: 0.6562 - val_accuracy: 0.6210 - val_loss: 0.6498\n",
      "Epoch 8/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6242 - loss: 0.6507 - val_accuracy: 0.6276 - val_loss: 0.6451\n",
      "Epoch 9/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6334 - loss: 0.6449 - val_accuracy: 0.6295 - val_loss: 0.6411\n",
      "Epoch 10/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6420 - loss: 0.6390 - val_accuracy: 0.6407 - val_loss: 0.6368\n",
      "Epoch 11/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6505 - loss: 0.6333 - val_accuracy: 0.6435 - val_loss: 0.6326\n",
      "Epoch 12/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6568 - loss: 0.6282 - val_accuracy: 0.6492 - val_loss: 0.6288\n",
      "Epoch 13/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 0.6232 - val_accuracy: 0.6492 - val_loss: 0.6255\n",
      "Epoch 14/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6694 - loss: 0.6187 - val_accuracy: 0.6529 - val_loss: 0.6229\n",
      "Epoch 15/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6760 - loss: 0.6145 - val_accuracy: 0.6501 - val_loss: 0.6218\n",
      "Epoch 16/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6790 - loss: 0.6103 - val_accuracy: 0.6548 - val_loss: 0.6193\n",
      "Epoch 17/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6848 - loss: 0.6060 - val_accuracy: 0.6623 - val_loss: 0.6170\n",
      "Epoch 18/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6878 - loss: 0.6023 - val_accuracy: 0.6660 - val_loss: 0.6154\n",
      "Epoch 19/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6922 - loss: 0.5988 - val_accuracy: 0.6651 - val_loss: 0.6133\n",
      "Epoch 20/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6968 - loss: 0.5953 - val_accuracy: 0.6689 - val_loss: 0.6122\n",
      "Epoch 21/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6975 - loss: 0.5927 - val_accuracy: 0.6698 - val_loss: 0.6108\n",
      "Epoch 22/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7016 - loss: 0.5898 - val_accuracy: 0.6735 - val_loss: 0.6094\n",
      "Epoch 23/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7028 - loss: 0.5874 - val_accuracy: 0.6754 - val_loss: 0.6093\n",
      "Epoch 24/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7043 - loss: 0.5854 - val_accuracy: 0.6754 - val_loss: 0.6087\n",
      "Epoch 25/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7051 - loss: 0.5830 - val_accuracy: 0.6829 - val_loss: 0.6074\n",
      "Epoch 26/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7087 - loss: 0.5804 - val_accuracy: 0.6829 - val_loss: 0.6077\n",
      "Epoch 27/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7093 - loss: 0.5780 - val_accuracy: 0.6839 - val_loss: 0.6080\n",
      "Epoch 28/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7071 - loss: 0.5757 - val_accuracy: 0.6867 - val_loss: 0.6071\n",
      "Epoch 29/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7094 - loss: 0.5754 - val_accuracy: 0.6857 - val_loss: 0.6058\n",
      "Epoch 30/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7139 - loss: 0.5722 - val_accuracy: 0.6886 - val_loss: 0.6049\n",
      "Epoch 31/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7224 - loss: 0.5681 - val_accuracy: 0.6764 - val_loss: 0.6047\n",
      "Epoch 32/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.5658 - val_accuracy: 0.6801 - val_loss: 0.6031\n",
      "Epoch 33/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7208 - loss: 0.5654 - val_accuracy: 0.6782 - val_loss: 0.6023\n",
      "Epoch 34/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7201 - loss: 0.5633 - val_accuracy: 0.6811 - val_loss: 0.6015\n",
      "Epoch 35/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7234 - loss: 0.5627 - val_accuracy: 0.6773 - val_loss: 0.6009\n",
      "Epoch 36/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7239 - loss: 0.5615 - val_accuracy: 0.6848 - val_loss: 0.5999\n",
      "Epoch 37/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7287 - loss: 0.5590 - val_accuracy: 0.6867 - val_loss: 0.6009\n",
      "Epoch 38/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7266 - loss: 0.5595 - val_accuracy: 0.6764 - val_loss: 0.6011\n",
      "Epoch 39/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7274 - loss: 0.5567 - val_accuracy: 0.6717 - val_loss: 0.6013\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 128, lr: 0.01\n",
      "Best accuracy for current run: 0.6885553598403931 at epoch 29\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5110 - loss: 0.7058 - val_accuracy: 0.5028 - val_loss: 0.6998\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5076 - loss: 0.7078 - val_accuracy: 0.4887 - val_loss: 0.6987\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4999 - loss: 0.7023 - val_accuracy: 0.5000 - val_loss: 0.6971\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4996 - loss: 0.7013 - val_accuracy: 0.5000 - val_loss: 0.6972\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4978 - loss: 0.7018 - val_accuracy: 0.5113 - val_loss: 0.6974\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4966 - loss: 0.7022 - val_accuracy: 0.5113 - val_loss: 0.6972\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 128, lr: 0.05\n",
      "Best accuracy for current run: 0.5112570524215698 at epoch 4\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4974 - loss: 0.6981 - val_accuracy: 0.5291 - val_loss: 0.6892\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5128 - loss: 0.6926 - val_accuracy: 0.5197 - val_loss: 0.6950\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5281 - loss: 0.6907 - val_accuracy: 0.5300 - val_loss: 0.6951\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5536 - loss: 0.6871 - val_accuracy: 0.5038 - val_loss: 0.7073\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 128, lr: 0.05\n",
      "Best accuracy for current run: 0.5300187468528748 at epoch 2\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5036 - loss: 0.7291 - val_accuracy: 0.4991 - val_loss: 0.6977\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4949 - loss: 0.7049 - val_accuracy: 0.5122 - val_loss: 0.6957\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4984 - loss: 0.7045 - val_accuracy: 0.4962 - val_loss: 0.6953\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5137 - loss: 0.7013 - val_accuracy: 0.5206 - val_loss: 0.6944\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5052 - loss: 0.7056 - val_accuracy: 0.4944 - val_loss: 0.7043\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5008 - loss: 0.7051 - val_accuracy: 0.5000 - val_loss: 0.7030\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4986 - loss: 0.7065 - val_accuracy: 0.5000 - val_loss: 0.7540\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 128, lr: 0.05\n",
      "Best accuracy for current run: 0.5206378698348999 at epoch 3\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4943 - loss: 0.6985 - val_accuracy: 0.5038 - val_loss: 0.6944\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4935 - loss: 0.6942 - val_accuracy: 0.4906 - val_loss: 0.6939\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5060 - loss: 0.6935 - val_accuracy: 0.5075 - val_loss: 0.6931\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5113 - loss: 0.6926 - val_accuracy: 0.4991 - val_loss: 0.6931\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5168 - loss: 0.6916 - val_accuracy: 0.5047 - val_loss: 0.6931\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5204 - loss: 0.6919 - val_accuracy: 0.5356 - val_loss: 0.6903\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5560 - loss: 0.6862 - val_accuracy: 0.4981 - val_loss: 0.6933\n",
      "Epoch 8/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5021 - loss: 0.6939 - val_accuracy: 0.4925 - val_loss: 0.6931\n",
      "Epoch 9/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 0.6936 - val_accuracy: 0.4972 - val_loss: 0.6932\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 128, lr: 0.05\n",
      "Best accuracy for current run: 0.5356472730636597 at epoch 5\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4868 - loss: 0.7282 - val_accuracy: 0.5150 - val_loss: 0.6987\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5130 - loss: 0.7047 - val_accuracy: 0.4916 - val_loss: 0.6998\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5152 - loss: 0.7046 - val_accuracy: 0.4916 - val_loss: 0.6995\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5137 - loss: 0.7043 - val_accuracy: 0.5159 - val_loss: 0.6977\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5119 - loss: 0.7030 - val_accuracy: 0.4831 - val_loss: 0.6980\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5167 - loss: 0.7029 - val_accuracy: 0.4756 - val_loss: 0.7070\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5085 - loss: 0.7014 - val_accuracy: 0.4897 - val_loss: 0.7000\n",
      "Run completed on:\n",
      "optimizer: adam, batch_size: 128, lr: 0.1\n",
      "Best accuracy for current run: 0.5159474611282349 at epoch 3\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4944 - loss: 0.6988 - val_accuracy: 0.5047 - val_loss: 0.6929\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5063 - loss: 0.6937 - val_accuracy: 0.5094 - val_loss: 0.6922\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5109 - loss: 0.6928 - val_accuracy: 0.5084 - val_loss: 0.6920\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5246 - loss: 0.6920 - val_accuracy: 0.5281 - val_loss: 0.6911\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5298 - loss: 0.6916 - val_accuracy: 0.4991 - val_loss: 0.6934\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5049 - loss: 0.6937 - val_accuracy: 0.4878 - val_loss: 0.6933\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5047 - loss: 0.6936 - val_accuracy: 0.4953 - val_loss: 0.6933\n",
      "Run completed on:\n",
      "optimizer: sgd, batch_size: 128, lr: 0.1\n",
      "Best accuracy for current run: 0.5281425714492798 at epoch 3\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5101 - loss: 0.7905 - val_accuracy: 0.5159 - val_loss: 0.7127\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5039 - loss: 0.7222 - val_accuracy: 0.5000 - val_loss: 0.7126\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5109 - loss: 0.7159 - val_accuracy: 0.4925 - val_loss: 0.6994\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5047 - loss: 0.7160 - val_accuracy: 0.5000 - val_loss: 0.7039\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5039 - loss: 0.7522 - val_accuracy: 0.5000 - val_loss: 0.7164\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4951 - loss: 0.7338 - val_accuracy: 0.5000 - val_loss: 0.7242\n",
      "Run completed on:\n",
      "optimizer: rmsprop, batch_size: 128, lr: 0.1\n",
      "Best accuracy for current run: 0.5159474611282349 at epoch 0\n",
      "Training ended\n",
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4918 - loss: 0.6993 - val_accuracy: 0.5038 - val_loss: 0.6929\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5048 - loss: 0.6939 - val_accuracy: 0.4859 - val_loss: 0.6943\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5089 - loss: 0.6937 - val_accuracy: 0.4784 - val_loss: 0.6947\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5034 - loss: 0.6935 - val_accuracy: 0.4784 - val_loss: 0.6952\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 128, lr: 0.1\n",
      "Best accuracy for current run: 0.5037523508071899 at epoch 0\n",
      "Training ended\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [16, 32, 64, 128]:\n",
    "    for lr in [0.005, 0.01, 0.05, 0.1]:\n",
    "        for optimizer in ['adam', 'sgd', 'rmsprop', 'adagrad']:\n",
    "            train_model(optimizer, 100, batch_size, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.696060061454773,\n",
       " 'epoch': 77,\n",
       " 'optimizer': 'adagrad',\n",
       " 'batch_size': 128,\n",
       " 'lr': 0.005}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model is trained with Optimizer: adagrad, Epoch: 35, Batch_size: 64, Learning_rate: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cQjhQD_JwI4-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5036 - loss: 0.6959 - val_accuracy: 0.5338 - val_loss: 0.6941\n",
      "Epoch 2/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5619 - loss: 0.6842 - val_accuracy: 0.5694 - val_loss: 0.6839\n",
      "Epoch 3/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5959 - loss: 0.6715 - val_accuracy: 0.6088 - val_loss: 0.6651\n",
      "Epoch 4/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 0.6607 - val_accuracy: 0.6351 - val_loss: 0.6517\n",
      "Epoch 5/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6293 - loss: 0.6513 - val_accuracy: 0.6313 - val_loss: 0.6430\n",
      "Epoch 6/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6421 - loss: 0.6423 - val_accuracy: 0.6332 - val_loss: 0.6367\n",
      "Epoch 7/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6500 - loss: 0.6339 - val_accuracy: 0.6388 - val_loss: 0.6310\n",
      "Epoch 8/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6603 - loss: 0.6264 - val_accuracy: 0.6473 - val_loss: 0.6255\n",
      "Epoch 9/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6699 - loss: 0.6195 - val_accuracy: 0.6538 - val_loss: 0.6219\n",
      "Epoch 10/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.6131 - val_accuracy: 0.6651 - val_loss: 0.6194\n",
      "Epoch 11/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6862 - loss: 0.6070 - val_accuracy: 0.6717 - val_loss: 0.6165\n",
      "Epoch 12/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6941 - loss: 0.6016 - val_accuracy: 0.6745 - val_loss: 0.6140\n",
      "Epoch 13/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.5964 - val_accuracy: 0.6801 - val_loss: 0.6119\n",
      "Epoch 14/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7001 - loss: 0.5918 - val_accuracy: 0.6782 - val_loss: 0.6108\n",
      "Epoch 15/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.5891 - val_accuracy: 0.6754 - val_loss: 0.6096\n",
      "Epoch 16/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7066 - loss: 0.5849 - val_accuracy: 0.6735 - val_loss: 0.6090\n",
      "Epoch 17/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7087 - loss: 0.5811 - val_accuracy: 0.6773 - val_loss: 0.6079\n",
      "Epoch 18/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7108 - loss: 0.5784 - val_accuracy: 0.6745 - val_loss: 0.6075\n",
      "Epoch 19/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7140 - loss: 0.5757 - val_accuracy: 0.6754 - val_loss: 0.6067\n",
      "Epoch 20/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 0.5748 - val_accuracy: 0.6792 - val_loss: 0.6066\n",
      "Epoch 21/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 0.5699 - val_accuracy: 0.6792 - val_loss: 0.6068\n",
      "Epoch 22/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7224 - loss: 0.5670 - val_accuracy: 0.6857 - val_loss: 0.6069\n",
      "Epoch 23/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.5652 - val_accuracy: 0.6811 - val_loss: 0.6062\n",
      "Epoch 24/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7208 - loss: 0.5672 - val_accuracy: 0.6801 - val_loss: 0.6064\n",
      "Epoch 25/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7280 - loss: 0.5617 - val_accuracy: 0.6820 - val_loss: 0.6068\n",
      "Epoch 26/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7291 - loss: 0.5581 - val_accuracy: 0.6801 - val_loss: 0.6056\n",
      "Epoch 27/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7301 - loss: 0.5572 - val_accuracy: 0.6829 - val_loss: 0.6072\n",
      "Epoch 28/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7311 - loss: 0.5545 - val_accuracy: 0.6839 - val_loss: 0.6068\n",
      "Epoch 29/40\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.5526 - val_accuracy: 0.6820 - val_loss: 0.6061\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 64, lr: 0.01\n",
      "Best accuracy for current run: 0.6857410669326782 at epoch 21\n",
      "Training ended\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 40, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "37gu7KI9_eWG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6564 - loss: 0.6093 \n",
      "Test accuracy: 0.690431535243988\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "accuracy = best_model.evaluate(X_val, y_val)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': {'module': 'keras.optimizers',\n",
       "  'class_name': 'Adagrad',\n",
       "  'config': {'name': 'adagrad',\n",
       "   'learning_rate': 0.004999999888241291,\n",
       "   'weight_decay': None,\n",
       "   'clipnorm': None,\n",
       "   'global_clipnorm': None,\n",
       "   'clipvalue': None,\n",
       "   'use_ema': False,\n",
       "   'ema_momentum': 0.99,\n",
       "   'ema_overwrite_frequency': None,\n",
       "   'loss_scale_factor': None,\n",
       "   'gradient_accumulation_steps': None,\n",
       "   'initial_accumulator_value': 0.1,\n",
       "   'epsilon': 1e-07},\n",
       "  'registered_name': None},\n",
       " 'loss': 'binary_crossentropy',\n",
       " 'loss_weights': None,\n",
       " 'metrics': ['accuracy'],\n",
       " 'weighted_metrics': None,\n",
       " 'run_eagerly': False,\n",
       " 'steps_per_execution': 1,\n",
       " 'jit_compile': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_compile_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import AveragePooling1D, GlobalAveragePooling1D\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_mean.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False),  # Embedding layer is frozen\n",
    "        SimpleRNN(16, return_sequences=True),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4578 - loss: 0.7000\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49531, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4584 - loss: 0.6999 - val_accuracy: 0.4953 - val_loss: 0.6946\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4925 - loss: 0.6950\n",
      "Epoch 2: val_accuracy improved from 0.49531 to 0.51313, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4926 - loss: 0.6950 - val_accuracy: 0.5131 - val_loss: 0.6928\n",
      "Epoch 3/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5066 - loss: 0.6932\n",
      "Epoch 3: val_accuracy improved from 0.51313 to 0.52533, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5069 - loss: 0.6932 - val_accuracy: 0.5253 - val_loss: 0.6914\n",
      "Epoch 4/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5203 - loss: 0.6917\n",
      "Epoch 4: val_accuracy improved from 0.52533 to 0.52908, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5206 - loss: 0.6917 - val_accuracy: 0.5291 - val_loss: 0.6902\n",
      "Epoch 5/100\n",
      "\u001b[1m122/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5345 - loss: 0.6904\n",
      "Epoch 5: val_accuracy improved from 0.52908 to 0.54315, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5353 - loss: 0.6904 - val_accuracy: 0.5432 - val_loss: 0.6890\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5479 - loss: 0.6891\n",
      "Epoch 6: val_accuracy improved from 0.54315 to 0.55066, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5479 - loss: 0.6891 - val_accuracy: 0.5507 - val_loss: 0.6878\n",
      "Epoch 7/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5624 - loss: 0.6877\n",
      "Epoch 7: val_accuracy improved from 0.55066 to 0.56004, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5625 - loss: 0.6877 - val_accuracy: 0.5600 - val_loss: 0.6865\n",
      "Epoch 8/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5753 - loss: 0.6862\n",
      "Epoch 8: val_accuracy improved from 0.56004 to 0.56942, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5757 - loss: 0.6862 - val_accuracy: 0.5694 - val_loss: 0.6850\n",
      "Epoch 9/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5898 - loss: 0.6845\n",
      "Epoch 9: val_accuracy improved from 0.56942 to 0.58068, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5898 - loss: 0.6845 - val_accuracy: 0.5807 - val_loss: 0.6832\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5993 - loss: 0.6821\n",
      "Epoch 10: val_accuracy improved from 0.58068 to 0.60976, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5994 - loss: 0.6821 - val_accuracy: 0.6098 - val_loss: 0.6794\n",
      "Epoch 11/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6110 - loss: 0.6728\n",
      "Epoch 11: val_accuracy did not improve from 0.60976\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6108 - loss: 0.6725 - val_accuracy: 0.6041 - val_loss: 0.6538\n",
      "Epoch 12/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6303 - loss: 0.6437\n",
      "Epoch 12: val_accuracy improved from 0.60976 to 0.61726, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6305 - loss: 0.6436 - val_accuracy: 0.6173 - val_loss: 0.6552\n",
      "Epoch 13/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6560 - loss: 0.6234\n",
      "Epoch 13: val_accuracy improved from 0.61726 to 0.65947, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6560 - loss: 0.6234 - val_accuracy: 0.6595 - val_loss: 0.6243\n",
      "Epoch 14/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6594 - loss: 0.6213\n",
      "Epoch 14: val_accuracy did not improve from 0.65947\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6591 - loss: 0.6215 - val_accuracy: 0.6454 - val_loss: 0.6345\n",
      "Epoch 15/100\n",
      "\u001b[1m120/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6735 - loss: 0.6099\n",
      "Epoch 15: val_accuracy improved from 0.65947 to 0.66323, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6733 - loss: 0.6099 - val_accuracy: 0.6632 - val_loss: 0.6212\n",
      "Epoch 16/100\n",
      "\u001b[1m124/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6777 - loss: 0.6078\n",
      "Epoch 16: val_accuracy did not improve from 0.66323\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6774 - loss: 0.6079 - val_accuracy: 0.6557 - val_loss: 0.6275\n",
      "Epoch 17/100\n",
      "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6850 - loss: 0.6015\n",
      "Epoch 17: val_accuracy did not improve from 0.66323\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6850 - loss: 0.6015 - val_accuracy: 0.6632 - val_loss: 0.6174\n",
      "Epoch 18/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6738 - loss: 0.6096\n",
      "Epoch 18: val_accuracy improved from 0.66323 to 0.67073, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6735 - loss: 0.6097 - val_accuracy: 0.6707 - val_loss: 0.6108\n",
      "Epoch 19/100\n",
      "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6838 - loss: 0.6018\n",
      "Epoch 19: val_accuracy did not improve from 0.67073\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6831 - loss: 0.6025 - val_accuracy: 0.6041 - val_loss: 0.6788\n",
      "Epoch 20/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6504 - loss: 0.6357\n",
      "Epoch 20: val_accuracy did not improve from 0.67073\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6512 - loss: 0.6350 - val_accuracy: 0.6126 - val_loss: 0.6661\n",
      "Epoch 21/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6864 - loss: 0.6037\n",
      "Epoch 21: val_accuracy improved from 0.67073 to 0.67917, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6865 - loss: 0.6037 - val_accuracy: 0.6792 - val_loss: 0.6063\n",
      "Epoch 22/100\n",
      "\u001b[1m124/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6958 - loss: 0.5957\n",
      "Epoch 22: val_accuracy did not improve from 0.67917\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6952 - loss: 0.5962 - val_accuracy: 0.6782 - val_loss: 0.6110\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6954 - loss: 0.5958\n",
      "Epoch 23: val_accuracy improved from 0.67917 to 0.68199, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6953 - loss: 0.5959 - val_accuracy: 0.6820 - val_loss: 0.6102\n",
      "Epoch 24/100\n",
      "\u001b[1m123/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6777 - loss: 0.6117\n",
      "Epoch 24: val_accuracy did not improve from 0.68199\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.6114 - val_accuracy: 0.6811 - val_loss: 0.6076\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7345 - loss: 0.5605 \n",
      "Test accuracy: 0.6848030090332031\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_mean.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPooling1D\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_max.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False),  # Embedding layer is frozen\n",
    "        SimpleRNN(16, return_sequences=True),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5095 - loss: 0.7062\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52439, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5096 - loss: 0.7057 - val_accuracy: 0.5244 - val_loss: 0.6920\n",
      "Epoch 2/100\n",
      "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5311 - loss: 0.6902\n",
      "Epoch 2: val_accuracy improved from 0.52439 to 0.54034, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5311 - loss: 0.6902 - val_accuracy: 0.5403 - val_loss: 0.6882\n",
      "Epoch 3/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5481 - loss: 0.6856\n",
      "Epoch 3: val_accuracy improved from 0.54034 to 0.54597, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5482 - loss: 0.6856 - val_accuracy: 0.5460 - val_loss: 0.6838\n",
      "Epoch 4/100\n",
      "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5686 - loss: 0.6804\n",
      "Epoch 4: val_accuracy improved from 0.54597 to 0.56754, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5685 - loss: 0.6803 - val_accuracy: 0.5675 - val_loss: 0.6778\n",
      "Epoch 5/100\n",
      "\u001b[1m122/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5930 - loss: 0.6733\n",
      "Epoch 5: val_accuracy improved from 0.56754 to 0.57880, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5934 - loss: 0.6731 - val_accuracy: 0.5788 - val_loss: 0.6693\n",
      "Epoch 6/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6178 - loss: 0.6633\n",
      "Epoch 6: val_accuracy improved from 0.57880 to 0.61163, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6182 - loss: 0.6631 - val_accuracy: 0.6116 - val_loss: 0.6590\n",
      "Epoch 7/100\n",
      "\u001b[1m121/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6378 - loss: 0.6520\n",
      "Epoch 7: val_accuracy improved from 0.61163 to 0.63133, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6384 - loss: 0.6516 - val_accuracy: 0.6313 - val_loss: 0.6474\n",
      "Epoch 8/100\n",
      "\u001b[1m121/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6554 - loss: 0.6399\n",
      "Epoch 8: val_accuracy improved from 0.63133 to 0.65572, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6561 - loss: 0.6395 - val_accuracy: 0.6557 - val_loss: 0.6364\n",
      "Epoch 9/100\n",
      "\u001b[1m123/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6716 - loss: 0.6281\n",
      "Epoch 9: val_accuracy improved from 0.65572 to 0.66323, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6720 - loss: 0.6278 - val_accuracy: 0.6632 - val_loss: 0.6257\n",
      "Epoch 10/100\n",
      "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6854 - loss: 0.6172\n",
      "Epoch 10: val_accuracy improved from 0.66323 to 0.67824, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6856 - loss: 0.6170 - val_accuracy: 0.6782 - val_loss: 0.6163\n",
      "Epoch 11/100\n",
      "\u001b[1m124/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6951 - loss: 0.6070\n",
      "Epoch 11: val_accuracy improved from 0.67824 to 0.69043, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6954 - loss: 0.6067 - val_accuracy: 0.6904 - val_loss: 0.6076\n",
      "Epoch 12/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7026 - loss: 0.5969\n",
      "Epoch 12: val_accuracy improved from 0.69043 to 0.70638, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7028 - loss: 0.5968 - val_accuracy: 0.7064 - val_loss: 0.5995\n",
      "Epoch 13/100\n",
      "\u001b[1m121/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7092 - loss: 0.5875\n",
      "Epoch 13: val_accuracy improved from 0.70638 to 0.70732, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7096 - loss: 0.5873 - val_accuracy: 0.7073 - val_loss: 0.5916\n",
      "Epoch 14/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7162 - loss: 0.5787\n",
      "Epoch 14: val_accuracy did not improve from 0.70732\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7163 - loss: 0.5786 - val_accuracy: 0.7036 - val_loss: 0.5844\n",
      "Epoch 15/100\n",
      "\u001b[1m123/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7210 - loss: 0.5707\n",
      "Epoch 15: val_accuracy improved from 0.70732 to 0.71107, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7211 - loss: 0.5706 - val_accuracy: 0.7111 - val_loss: 0.5780\n",
      "Epoch 16/100\n",
      "\u001b[1m122/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7236 - loss: 0.5637\n",
      "Epoch 16: val_accuracy improved from 0.71107 to 0.71388, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7237 - loss: 0.5636 - val_accuracy: 0.7139 - val_loss: 0.5722\n",
      "Epoch 17/100\n",
      "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7249 - loss: 0.5573\n",
      "Epoch 17: val_accuracy did not improve from 0.71388\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7250 - loss: 0.5572 - val_accuracy: 0.7139 - val_loss: 0.5670\n",
      "Epoch 18/100\n",
      "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7287 - loss: 0.5517\n",
      "Epoch 18: val_accuracy improved from 0.71388 to 0.71482, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7288 - loss: 0.5517 - val_accuracy: 0.7148 - val_loss: 0.5624\n",
      "Epoch 19/100\n",
      "\u001b[1m123/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7304 - loss: 0.5470\n",
      "Epoch 19: val_accuracy did not improve from 0.71482\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7305 - loss: 0.5470 - val_accuracy: 0.7139 - val_loss: 0.5582\n",
      "Epoch 20/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7316 - loss: 0.5435\n",
      "Epoch 20: val_accuracy improved from 0.71482 to 0.71951, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7317 - loss: 0.5435 - val_accuracy: 0.7195 - val_loss: 0.5553\n",
      "Epoch 21/100\n",
      "\u001b[1m124/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7341 - loss: 0.5395\n",
      "Epoch 21: val_accuracy improved from 0.71951 to 0.72139, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7343 - loss: 0.5394 - val_accuracy: 0.7214 - val_loss: 0.5519\n",
      "Epoch 22/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7365 - loss: 0.5361\n",
      "Epoch 22: val_accuracy improved from 0.72139 to 0.72608, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7366 - loss: 0.5361 - val_accuracy: 0.7261 - val_loss: 0.5490\n",
      "Epoch 23/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.5333\n",
      "Epoch 23: val_accuracy improved from 0.72608 to 0.72795, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7372 - loss: 0.5333 - val_accuracy: 0.7280 - val_loss: 0.5462\n",
      "Epoch 24/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.5304\n",
      "Epoch 24: val_accuracy did not improve from 0.72795\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7388 - loss: 0.5304 - val_accuracy: 0.7261 - val_loss: 0.5444\n",
      "Epoch 25/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7384 - loss: 0.5282\n",
      "Epoch 25: val_accuracy did not improve from 0.72795\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7384 - loss: 0.5282 - val_accuracy: 0.7261 - val_loss: 0.5467\n",
      "Epoch 26/100\n",
      "\u001b[1m122/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7403 - loss: 0.5270\n",
      "Epoch 26: val_accuracy improved from 0.72795 to 0.72983, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7405 - loss: 0.5271 - val_accuracy: 0.7298 - val_loss: 0.5406\n",
      "Epoch 27/100\n",
      "\u001b[1m123/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7459 - loss: 0.5245\n",
      "Epoch 27: val_accuracy improved from 0.72983 to 0.73358, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7458 - loss: 0.5246 - val_accuracy: 0.7336 - val_loss: 0.5384\n",
      "Epoch 28/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7431 - loss: 0.5216\n",
      "Epoch 28: val_accuracy did not improve from 0.73358\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7431 - loss: 0.5216 - val_accuracy: 0.7336 - val_loss: 0.5381\n",
      "Epoch 29/100\n",
      "\u001b[1m122/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.5196\n",
      "Epoch 29: val_accuracy improved from 0.73358 to 0.73452, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7476 - loss: 0.5196 - val_accuracy: 0.7345 - val_loss: 0.5346\n",
      "Epoch 30/100\n",
      "\u001b[1m124/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7474 - loss: 0.5176\n",
      "Epoch 30: val_accuracy improved from 0.73452 to 0.73827, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7475 - loss: 0.5176 - val_accuracy: 0.7383 - val_loss: 0.5334\n",
      "Epoch 31/100\n",
      "\u001b[1m123/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7480 - loss: 0.5155\n",
      "Epoch 31: val_accuracy did not improve from 0.73827\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7481 - loss: 0.5155 - val_accuracy: 0.7373 - val_loss: 0.5325\n",
      "Epoch 32/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7499 - loss: 0.5144\n",
      "Epoch 32: val_accuracy did not improve from 0.73827\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7500 - loss: 0.5144 - val_accuracy: 0.7364 - val_loss: 0.5319\n",
      "Epoch 33/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7513 - loss: 0.5128\n",
      "Epoch 33: val_accuracy did not improve from 0.73827\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7514 - loss: 0.5128 - val_accuracy: 0.7364 - val_loss: 0.5306\n",
      "Epoch 34/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7536 - loss: 0.5120\n",
      "Epoch 34: val_accuracy did not improve from 0.73827\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.5120 - val_accuracy: 0.7373 - val_loss: 0.5299\n",
      "Epoch 35/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7543 - loss: 0.5112\n",
      "Epoch 35: val_accuracy did not improve from 0.73827\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7543 - loss: 0.5112 - val_accuracy: 0.7345 - val_loss: 0.5309\n",
      "Epoch 36/100\n",
      "\u001b[1m122/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.5089\n",
      "Epoch 36: val_accuracy did not improve from 0.73827\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7549 - loss: 0.5089 - val_accuracy: 0.7364 - val_loss: 0.5283\n",
      "Epoch 37/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7560 - loss: 0.5076\n",
      "Epoch 37: val_accuracy did not improve from 0.73827\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7559 - loss: 0.5076 - val_accuracy: 0.7336 - val_loss: 0.5265\n",
      "Epoch 38/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7566 - loss: 0.5060\n",
      "Epoch 38: val_accuracy improved from 0.73827 to 0.73921, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7565 - loss: 0.5060 - val_accuracy: 0.7392 - val_loss: 0.5259\n",
      "Epoch 39/100\n",
      "\u001b[1m124/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7557 - loss: 0.5054\n",
      "Epoch 39: val_accuracy improved from 0.73921 to 0.74109, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7559 - loss: 0.5054 - val_accuracy: 0.7411 - val_loss: 0.5255\n",
      "Epoch 40/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7567 - loss: 0.5037\n",
      "Epoch 40: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7569 - loss: 0.5037 - val_accuracy: 0.7411 - val_loss: 0.5251\n",
      "Epoch 41/100\n",
      "\u001b[1m124/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.5026\n",
      "Epoch 41: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.5026 - val_accuracy: 0.7402 - val_loss: 0.5244\n",
      "Epoch 42/100\n",
      "\u001b[1m121/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.5017\n",
      "Epoch 42: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7573 - loss: 0.5019 - val_accuracy: 0.7392 - val_loss: 0.5270\n",
      "Epoch 43/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7584 - loss: 0.5022\n",
      "Epoch 43: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7585 - loss: 0.5022 - val_accuracy: 0.7402 - val_loss: 0.5233\n",
      "Epoch 44/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.4999\n",
      "Epoch 44: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7604 - loss: 0.4999 - val_accuracy: 0.7402 - val_loss: 0.5229\n",
      "Epoch 45/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.4983\n",
      "Epoch 45: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.4983 - val_accuracy: 0.7402 - val_loss: 0.5232\n",
      "Epoch 46/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7620 - loss: 0.4971\n",
      "Epoch 46: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7620 - loss: 0.4972 - val_accuracy: 0.6764 - val_loss: 0.6042\n",
      "Epoch 47/100\n",
      "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.5325\n",
      "Epoch 47: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7356 - loss: 0.5311 - val_accuracy: 0.7280 - val_loss: 0.5246\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6999 - loss: 0.5836   \n",
      "Test accuracy: 0.7298311591148376\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_max.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_dense.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=True),  # Embedding layer is frozen\n",
    "        SimpleRNN(16, return_sequences=True),\n",
    "        Flatten(),\n",
    "        Dense(62, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5417 - loss: 0.6986\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58068, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 114ms/step - accuracy: 0.5418 - loss: 0.6985 - val_accuracy: 0.5807 - val_loss: 0.6771\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6285 - loss: 0.6447\n",
      "Epoch 2: val_accuracy improved from 0.58068 to 0.62570, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - accuracy: 0.6286 - loss: 0.6447 - val_accuracy: 0.6257 - val_loss: 0.6579\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6698 - loss: 0.6096\n",
      "Epoch 3: val_accuracy improved from 0.62570 to 0.65666, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - accuracy: 0.6698 - loss: 0.6095 - val_accuracy: 0.6567 - val_loss: 0.6324\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6942 - loss: 0.5847\n",
      "Epoch 4: val_accuracy improved from 0.65666 to 0.67261, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.6942 - loss: 0.5847 - val_accuracy: 0.6726 - val_loss: 0.6189\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7106 - loss: 0.5671\n",
      "Epoch 5: val_accuracy improved from 0.67261 to 0.68574, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.7106 - loss: 0.5671 - val_accuracy: 0.6857 - val_loss: 0.5999\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7205 - loss: 0.5527\n",
      "Epoch 6: val_accuracy improved from 0.68574 to 0.68856, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 113ms/step - accuracy: 0.7205 - loss: 0.5527 - val_accuracy: 0.6886 - val_loss: 0.5936\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7283 - loss: 0.5405\n",
      "Epoch 7: val_accuracy did not improve from 0.68856\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 107ms/step - accuracy: 0.7283 - loss: 0.5405 - val_accuracy: 0.6857 - val_loss: 0.5827\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7354 - loss: 0.5303\n",
      "Epoch 8: val_accuracy did not improve from 0.68856\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 107ms/step - accuracy: 0.7354 - loss: 0.5303 - val_accuracy: 0.6886 - val_loss: 0.5772\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7420 - loss: 0.5215\n",
      "Epoch 9: val_accuracy improved from 0.68856 to 0.69418, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 113ms/step - accuracy: 0.7420 - loss: 0.5215 - val_accuracy: 0.6942 - val_loss: 0.5708\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7469 - loss: 0.5150\n",
      "Epoch 10: val_accuracy improved from 0.69418 to 0.69794, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.7469 - loss: 0.5150 - val_accuracy: 0.6979 - val_loss: 0.5660\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7530 - loss: 0.5074\n",
      "Epoch 11: val_accuracy improved from 0.69794 to 0.70826, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.7530 - loss: 0.5074 - val_accuracy: 0.7083 - val_loss: 0.5629\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7575 - loss: 0.5010\n",
      "Epoch 12: val_accuracy improved from 0.70826 to 0.70919, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - accuracy: 0.7575 - loss: 0.5011 - val_accuracy: 0.7092 - val_loss: 0.5606\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7605 - loss: 0.4953\n",
      "Epoch 13: val_accuracy did not improve from 0.70919\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 102ms/step - accuracy: 0.7604 - loss: 0.4954 - val_accuracy: 0.7083 - val_loss: 0.5566\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7631 - loss: 0.4900\n",
      "Epoch 14: val_accuracy did not improve from 0.70919\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 101ms/step - accuracy: 0.7631 - loss: 0.4901 - val_accuracy: 0.7092 - val_loss: 0.5548\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7668 - loss: 0.4850\n",
      "Epoch 15: val_accuracy improved from 0.70919 to 0.71201, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - accuracy: 0.7668 - loss: 0.4850 - val_accuracy: 0.7120 - val_loss: 0.5534\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7690 - loss: 0.4803\n",
      "Epoch 16: val_accuracy did not improve from 0.71201\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 101ms/step - accuracy: 0.7689 - loss: 0.4803 - val_accuracy: 0.7120 - val_loss: 0.5518\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7724 - loss: 0.4758\n",
      "Epoch 17: val_accuracy improved from 0.71201 to 0.71295, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - accuracy: 0.7724 - loss: 0.4758 - val_accuracy: 0.7129 - val_loss: 0.5501\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7755 - loss: 0.4713\n",
      "Epoch 18: val_accuracy did not improve from 0.71295\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 104ms/step - accuracy: 0.7755 - loss: 0.4713 - val_accuracy: 0.7129 - val_loss: 0.5496\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7784 - loss: 0.4672\n",
      "Epoch 19: val_accuracy improved from 0.71295 to 0.71576, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.7783 - loss: 0.4672 - val_accuracy: 0.7158 - val_loss: 0.5476\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7806 - loss: 0.4631\n",
      "Epoch 20: val_accuracy improved from 0.71576 to 0.71670, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.7806 - loss: 0.4631 - val_accuracy: 0.7167 - val_loss: 0.5474\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7833 - loss: 0.4590\n",
      "Epoch 21: val_accuracy did not improve from 0.71670\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 105ms/step - accuracy: 0.7833 - loss: 0.4590 - val_accuracy: 0.7148 - val_loss: 0.5468\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7855 - loss: 0.4550\n",
      "Epoch 22: val_accuracy did not improve from 0.71670\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 103ms/step - accuracy: 0.7855 - loss: 0.4550 - val_accuracy: 0.7148 - val_loss: 0.5466\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7894 - loss: 0.4510\n",
      "Epoch 23: val_accuracy did not improve from 0.71670\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 102ms/step - accuracy: 0.7894 - loss: 0.4511 - val_accuracy: 0.7167 - val_loss: 0.5470\n",
      "Epoch 24/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7916 - loss: 0.4471\n",
      "Epoch 24: val_accuracy improved from 0.71670 to 0.71857, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.7916 - loss: 0.4471 - val_accuracy: 0.7186 - val_loss: 0.5466\n",
      "Epoch 25/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7946 - loss: 0.4432\n",
      "Epoch 25: val_accuracy did not improve from 0.71857\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - accuracy: 0.7945 - loss: 0.4432 - val_accuracy: 0.7176 - val_loss: 0.5464\n",
      "Epoch 26/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7963 - loss: 0.4392\n",
      "Epoch 26: val_accuracy improved from 0.71857 to 0.71951, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - accuracy: 0.7963 - loss: 0.4392 - val_accuracy: 0.7195 - val_loss: 0.5467\n",
      "Epoch 27/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7989 - loss: 0.4352\n",
      "Epoch 27: val_accuracy did not improve from 0.71951\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 103ms/step - accuracy: 0.7989 - loss: 0.4352 - val_accuracy: 0.7195 - val_loss: 0.5459\n",
      "Epoch 28/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8026 - loss: 0.4313\n",
      "Epoch 28: val_accuracy improved from 0.71951 to 0.72233, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.8026 - loss: 0.4313 - val_accuracy: 0.7223 - val_loss: 0.5454\n",
      "Epoch 29/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8050 - loss: 0.4274\n",
      "Epoch 29: val_accuracy did not improve from 0.72233\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 104ms/step - accuracy: 0.8050 - loss: 0.4274 - val_accuracy: 0.7214 - val_loss: 0.5462\n",
      "Epoch 30/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8074 - loss: 0.4236\n",
      "Epoch 30: val_accuracy improved from 0.72233 to 0.72514, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.8074 - loss: 0.4236 - val_accuracy: 0.7251 - val_loss: 0.5459\n",
      "Epoch 31/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8107 - loss: 0.4196\n",
      "Epoch 31: val_accuracy did not improve from 0.72514\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 104ms/step - accuracy: 0.8107 - loss: 0.4196 - val_accuracy: 0.7251 - val_loss: 0.5459\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6725 - loss: 0.6366 \n",
      "Test accuracy: 0.7204502820968628\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_dense.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mk92r_ZsrSpi"
   },
   "source": [
    "# Part 3. Enhancement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KqKwEpbsrdS"
   },
   "source": [
    "#### 1. Instead of keeping the word embeddings fixed, now update the word embeddings (the same way as model parameters) during the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_K0Do_y_onlw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 247ms/step - accuracy: 0.5068 - loss: 0.6994 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 2/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 250ms/step - accuracy: 0.5133 - loss: 0.6952 - val_accuracy: 0.5000 - val_loss: 0.6955\n",
      "Epoch 3/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 248ms/step - accuracy: 0.5070 - loss: 0.6956 - val_accuracy: 0.5000 - val_loss: 0.6951\n",
      "Epoch 4/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 246ms/step - accuracy: 0.5063 - loss: 0.6955 - val_accuracy: 0.5000 - val_loss: 0.6949\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size,\n",
    "              output_dim=embedding_dim,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=True),\n",
    "    SimpleRNN(16, return_sequences=False),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01) #Static learning rate\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXX18PkzurVx"
   },
   "source": [
    "#### 2. As discussed in Question 1(c), apply your solution in mitigating the influence of OOV words and train your model again.\n",
    "##### (Run cells 6 and 7 first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "QqnGXOHhvkMX"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(model.index_to_key) + 2 # 0 is reserved for padding, 1 is reserved for OOV\n",
    "embedding_dim = model.vector_size\n",
    "word_index = {word: index+2 for index, word in enumerate(model.index_to_key)} # index 0 is reserved for padding\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "QF-3ABACvkMZ"
   },
   "outputs": [],
   "source": [
    "for word, idx in word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[idx] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "43whGTSCvkMZ"
   },
   "outputs": [],
   "source": [
    "def tokenize(text, word_index):\n",
    "    ls = nltk.word_tokenize(text)\n",
    "    return [word_index[word] if word in word_index else 1 for word in ls]\n",
    "\n",
    "X_train = [tokenize(text, word_index) for text in train_dataset['text']]\n",
    "X_val = [tokenize(text, word_index) for text in validation_dataset['text']]\n",
    "X_test = [tokenize(text, word_index) for text in test_dataset['text']]\n",
    "max_length = max(len(seq) for seq in X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "tdWGgBiavkMZ"
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n",
    "X_val = pad_sequences(X_val, maxlen=max_length, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "yUXkRq0gvkMa"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(train_dataset['label'])\n",
    "y_val = np.array(validation_dataset['label'])\n",
    "y_test = np.array(test_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_oov.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False),  # Embedding layer is frozen\n",
    "        SimpleRNN(16, return_sequences=False),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m124/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5135 - loss: 0.6945\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52439, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5132 - loss: 0.6945 - val_accuracy: 0.5244 - val_loss: 0.6933\n",
      "Epoch 2/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5322 - loss: 0.6906\n",
      "Epoch 2: val_accuracy did not improve from 0.52439\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5322 - loss: 0.6906 - val_accuracy: 0.5206 - val_loss: 0.6940\n",
      "Epoch 3/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5592 - loss: 0.6857\n",
      "Epoch 3: val_accuracy improved from 0.52439 to 0.53377, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5589 - loss: 0.6858 - val_accuracy: 0.5338 - val_loss: 0.6915\n",
      "Epoch 4/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5767 - loss: 0.6793\n",
      "Epoch 4: val_accuracy improved from 0.53377 to 0.55253, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5764 - loss: 0.6794 - val_accuracy: 0.5525 - val_loss: 0.6824\n",
      "Epoch 5/100\n",
      "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5939 - loss: 0.6719\n",
      "Epoch 5: val_accuracy improved from 0.55253 to 0.58818, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5934 - loss: 0.6720 - val_accuracy: 0.5882 - val_loss: 0.6698\n",
      "Epoch 6/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 0.6640\n",
      "Epoch 6: val_accuracy improved from 0.58818 to 0.60694, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6109 - loss: 0.6641 - val_accuracy: 0.6069 - val_loss: 0.6609\n",
      "Epoch 7/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6185 - loss: 0.6565\n",
      "Epoch 7: val_accuracy improved from 0.60694 to 0.60882, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6182 - loss: 0.6566 - val_accuracy: 0.6088 - val_loss: 0.6562\n",
      "Epoch 8/100\n",
      "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6295 - loss: 0.6480\n",
      "Epoch 8: val_accuracy improved from 0.60882 to 0.61726, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6291 - loss: 0.6482 - val_accuracy: 0.6173 - val_loss: 0.6514\n",
      "Epoch 9/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6419 - loss: 0.6413\n",
      "Epoch 9: val_accuracy improved from 0.61726 to 0.62383, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6417 - loss: 0.6414 - val_accuracy: 0.6238 - val_loss: 0.6479\n",
      "Epoch 10/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6509 - loss: 0.6353\n",
      "Epoch 10: val_accuracy did not improve from 0.62383\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6506 - loss: 0.6355 - val_accuracy: 0.6210 - val_loss: 0.6461\n",
      "Epoch 11/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6560 - loss: 0.6313\n",
      "Epoch 11: val_accuracy improved from 0.62383 to 0.63790, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6557 - loss: 0.6315 - val_accuracy: 0.6379 - val_loss: 0.6402\n",
      "Epoch 12/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6666 - loss: 0.6244\n",
      "Epoch 12: val_accuracy did not improve from 0.63790\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6664 - loss: 0.6244 - val_accuracy: 0.6295 - val_loss: 0.6460\n",
      "Epoch 13/100\n",
      "\u001b[1m124/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6684 - loss: 0.6199\n",
      "Epoch 13: val_accuracy improved from 0.63790 to 0.63977, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6680 - loss: 0.6201 - val_accuracy: 0.6398 - val_loss: 0.6427\n",
      "Epoch 14/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6755 - loss: 0.6158\n",
      "Epoch 14: val_accuracy improved from 0.63977 to 0.65197, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6750 - loss: 0.6160 - val_accuracy: 0.6520 - val_loss: 0.6400\n",
      "Epoch 15/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6808 - loss: 0.6088\n",
      "Epoch 15: val_accuracy improved from 0.65197 to 0.65291, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6803 - loss: 0.6090 - val_accuracy: 0.6529 - val_loss: 0.6430\n",
      "Epoch 16/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6816 - loss: 0.6048\n",
      "Epoch 16: val_accuracy improved from 0.65291 to 0.65666, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6814 - loss: 0.6049 - val_accuracy: 0.6567 - val_loss: 0.6440\n",
      "Epoch 17/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6907 - loss: 0.6033\n",
      "Epoch 17: val_accuracy improved from 0.65666 to 0.65947, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6901 - loss: 0.6035 - val_accuracy: 0.6595 - val_loss: 0.6381\n",
      "Epoch 18/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6893 - loss: 0.6000\n",
      "Epoch 18: val_accuracy improved from 0.65947 to 0.66229, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6890 - loss: 0.6002 - val_accuracy: 0.6623 - val_loss: 0.6203\n",
      "Epoch 19/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6954 - loss: 0.5934\n",
      "Epoch 19: val_accuracy improved from 0.66229 to 0.66510, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6952 - loss: 0.5936 - val_accuracy: 0.6651 - val_loss: 0.6311\n",
      "Epoch 20/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6986 - loss: 0.5929\n",
      "Epoch 20: val_accuracy did not improve from 0.66510\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6981 - loss: 0.5932 - val_accuracy: 0.6642 - val_loss: 0.6184\n",
      "Epoch 21/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6975 - loss: 0.5905\n",
      "Epoch 21: val_accuracy improved from 0.66510 to 0.67448, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6969 - loss: 0.5910 - val_accuracy: 0.6745 - val_loss: 0.6217\n",
      "Epoch 22/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7042 - loss: 0.5870\n",
      "Epoch 22: val_accuracy improved from 0.67448 to 0.67730, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7037 - loss: 0.5873 - val_accuracy: 0.6773 - val_loss: 0.6204\n",
      "Epoch 23/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7008 - loss: 0.5849\n",
      "Epoch 23: val_accuracy did not improve from 0.67730\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7004 - loss: 0.5852 - val_accuracy: 0.6642 - val_loss: 0.6130\n",
      "Epoch 24/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7086 - loss: 0.5811\n",
      "Epoch 24: val_accuracy did not improve from 0.67730\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7080 - loss: 0.5814 - val_accuracy: 0.6754 - val_loss: 0.6204\n",
      "Epoch 25/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7118 - loss: 0.5805\n",
      "Epoch 25: val_accuracy improved from 0.67730 to 0.67824, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7116 - loss: 0.5806 - val_accuracy: 0.6782 - val_loss: 0.6156\n",
      "Epoch 26/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7155 - loss: 0.5752\n",
      "Epoch 26: val_accuracy did not improve from 0.67824\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7152 - loss: 0.5754 - val_accuracy: 0.6679 - val_loss: 0.6088\n",
      "Epoch 27/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7154 - loss: 0.5717\n",
      "Epoch 27: val_accuracy improved from 0.67824 to 0.68293, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7148 - loss: 0.5722 - val_accuracy: 0.6829 - val_loss: 0.6085\n",
      "Epoch 28/100\n",
      "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7177 - loss: 0.5681\n",
      "Epoch 28: val_accuracy did not improve from 0.68293\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7169 - loss: 0.5688 - val_accuracy: 0.6764 - val_loss: 0.6108\n",
      "Epoch 29/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7162 - loss: 0.5704\n",
      "Epoch 29: val_accuracy did not improve from 0.68293\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7160 - loss: 0.5705 - val_accuracy: 0.6811 - val_loss: 0.6106\n",
      "Epoch 30/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7194 - loss: 0.5682\n",
      "Epoch 30: val_accuracy did not improve from 0.68293\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7185 - loss: 0.5689 - val_accuracy: 0.6820 - val_loss: 0.6030\n",
      "Epoch 31/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.5654\n",
      "Epoch 31: val_accuracy did not improve from 0.68293\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7179 - loss: 0.5662 - val_accuracy: 0.6811 - val_loss: 0.6029\n",
      "Epoch 32/100\n",
      "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7205 - loss: 0.5615\n",
      "Epoch 32: val_accuracy did not improve from 0.68293\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7197 - loss: 0.5623 - val_accuracy: 0.6829 - val_loss: 0.6012\n",
      "Epoch 33/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7202 - loss: 0.5610\n",
      "Epoch 33: val_accuracy improved from 0.68293 to 0.68574, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7197 - loss: 0.5615 - val_accuracy: 0.6857 - val_loss: 0.6001\n",
      "Epoch 34/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7170 - loss: 0.5629\n",
      "Epoch 34: val_accuracy improved from 0.68574 to 0.68762, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7167 - loss: 0.5631 - val_accuracy: 0.6876 - val_loss: 0.5970\n",
      "Epoch 35/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.5602\n",
      "Epoch 35: val_accuracy improved from 0.68762 to 0.69137, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7254 - loss: 0.5605 - val_accuracy: 0.6914 - val_loss: 0.6025\n",
      "Epoch 36/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7245 - loss: 0.5562\n",
      "Epoch 36: val_accuracy did not improve from 0.69137\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7241 - loss: 0.5565 - val_accuracy: 0.6914 - val_loss: 0.5990\n",
      "Epoch 37/100\n",
      "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7257 - loss: 0.5533\n",
      "Epoch 37: val_accuracy did not improve from 0.69137\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7249 - loss: 0.5542 - val_accuracy: 0.6904 - val_loss: 0.6028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Sequential name=sequential_71, built=True>,\n",
       " <keras.src.callbacks.history.History at 0x242b47b0fe0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6786 - loss: 0.5732\n",
      "Test accuracy: 0.6763602495193481\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_oov.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Keeping the above two adjustments, replace your simple RNN model in Part 2 with a biLSTM model and a biGRU model, incorporating recurrent computations in both directions and stacking multiple layers if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_combined.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=True),  # Embedding layer is frozen\n",
    "        Bidirectional(LSTM(16, return_sequences=False)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5296 - loss: 0.6917\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57599, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.5297 - loss: 0.6916 - val_accuracy: 0.5760 - val_loss: 0.6849\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5714 - loss: 0.6818\n",
      "Epoch 2: val_accuracy improved from 0.57599 to 0.60131, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 122ms/step - accuracy: 0.5715 - loss: 0.6818 - val_accuracy: 0.6013 - val_loss: 0.6755\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6036 - loss: 0.6692\n",
      "Epoch 3: val_accuracy improved from 0.60131 to 0.63415, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - accuracy: 0.6036 - loss: 0.6692 - val_accuracy: 0.6341 - val_loss: 0.6607\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6412 - loss: 0.6492\n",
      "Epoch 4: val_accuracy improved from 0.63415 to 0.67167, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 115ms/step - accuracy: 0.6412 - loss: 0.6492 - val_accuracy: 0.6717 - val_loss: 0.6377\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.6676 - loss: 0.6243\n",
      "Epoch 5: val_accuracy improved from 0.67167 to 0.67824, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.6676 - loss: 0.6243 - val_accuracy: 0.6782 - val_loss: 0.6181\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6974 - loss: 0.6020\n",
      "Epoch 6: val_accuracy did not improve from 0.67824\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 117ms/step - accuracy: 0.6974 - loss: 0.6020 - val_accuracy: 0.6726 - val_loss: 0.6184\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7078 - loss: 0.5857\n",
      "Epoch 7: val_accuracy improved from 0.67824 to 0.68199, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 122ms/step - accuracy: 0.7078 - loss: 0.5857 - val_accuracy: 0.6820 - val_loss: 0.6067\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7158 - loss: 0.5738\n",
      "Epoch 8: val_accuracy improved from 0.68199 to 0.69418, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 121ms/step - accuracy: 0.7158 - loss: 0.5738 - val_accuracy: 0.6942 - val_loss: 0.5948\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7243 - loss: 0.5621\n",
      "Epoch 9: val_accuracy improved from 0.69418 to 0.70075, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 116ms/step - accuracy: 0.7243 - loss: 0.5621 - val_accuracy: 0.7008 - val_loss: 0.5865\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7336 - loss: 0.5525\n",
      "Epoch 10: val_accuracy improved from 0.70075 to 0.70450, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 119ms/step - accuracy: 0.7336 - loss: 0.5525 - val_accuracy: 0.7045 - val_loss: 0.5793\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7378 - loss: 0.5444\n",
      "Epoch 11: val_accuracy improved from 0.70450 to 0.70826, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 121ms/step - accuracy: 0.7377 - loss: 0.5445 - val_accuracy: 0.7083 - val_loss: 0.5724\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7422 - loss: 0.5376\n",
      "Epoch 12: val_accuracy improved from 0.70826 to 0.71576, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.7422 - loss: 0.5376 - val_accuracy: 0.7158 - val_loss: 0.5665\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7467 - loss: 0.5315\n",
      "Epoch 13: val_accuracy improved from 0.71576 to 0.71857, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.7466 - loss: 0.5315 - val_accuracy: 0.7186 - val_loss: 0.5612\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7507 - loss: 0.5260\n",
      "Epoch 14: val_accuracy improved from 0.71857 to 0.72139, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.7507 - loss: 0.5261 - val_accuracy: 0.7214 - val_loss: 0.5562\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7520 - loss: 0.5211\n",
      "Epoch 15: val_accuracy improved from 0.72139 to 0.73077, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - accuracy: 0.7520 - loss: 0.5211 - val_accuracy: 0.7308 - val_loss: 0.5517\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7525 - loss: 0.5165\n",
      "Epoch 16: val_accuracy improved from 0.73077 to 0.73921, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 119ms/step - accuracy: 0.7525 - loss: 0.5165 - val_accuracy: 0.7392 - val_loss: 0.5474\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7578 - loss: 0.5122\n",
      "Epoch 17: val_accuracy did not improve from 0.73921\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 115ms/step - accuracy: 0.7578 - loss: 0.5122 - val_accuracy: 0.7383 - val_loss: 0.5433\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7614 - loss: 0.5082\n",
      "Epoch 18: val_accuracy did not improve from 0.73921\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 114ms/step - accuracy: 0.7613 - loss: 0.5082 - val_accuracy: 0.7355 - val_loss: 0.5394\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7626 - loss: 0.5044\n",
      "Epoch 19: val_accuracy did not improve from 0.73921\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 114ms/step - accuracy: 0.7626 - loss: 0.5044 - val_accuracy: 0.7326 - val_loss: 0.5357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Sequential name=sequential_72, built=True>,\n",
       " <keras.src.callbacks.history.History at 0x2419d7d1f40>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6495 - loss: 0.6274 \n",
      "Test accuracy: 0.7260788083076477\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_combined.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, GRU\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_combined.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=True),  # Embedding layer is frozen\n",
    "        Bidirectional(GRU(16, return_sequences=False)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5007 - loss: 0.7018\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50750, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.5007 - loss: 0.7017 - val_accuracy: 0.5075 - val_loss: 0.6927\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5439 - loss: 0.6876\n",
      "Epoch 2: val_accuracy improved from 0.50750 to 0.55159, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 115ms/step - accuracy: 0.5440 - loss: 0.6876 - val_accuracy: 0.5516 - val_loss: 0.6857\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5801 - loss: 0.6800\n",
      "Epoch 3: val_accuracy improved from 0.55159 to 0.55910, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 116ms/step - accuracy: 0.5801 - loss: 0.6800 - val_accuracy: 0.5591 - val_loss: 0.6803\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5972 - loss: 0.6738\n",
      "Epoch 4: val_accuracy improved from 0.55910 to 0.57317, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.5971 - loss: 0.6738 - val_accuracy: 0.5732 - val_loss: 0.6753\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.6081 - loss: 0.6678\n",
      "Epoch 5: val_accuracy improved from 0.57317 to 0.57786, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 122ms/step - accuracy: 0.6081 - loss: 0.6678 - val_accuracy: 0.5779 - val_loss: 0.6699\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6204 - loss: 0.6615\n",
      "Epoch 6: val_accuracy improved from 0.57786 to 0.59099, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - accuracy: 0.6204 - loss: 0.6615 - val_accuracy: 0.5910 - val_loss: 0.6640\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.6267 - loss: 0.6543\n",
      "Epoch 7: val_accuracy improved from 0.59099 to 0.61257, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.6266 - loss: 0.6543 - val_accuracy: 0.6126 - val_loss: 0.6571\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6416 - loss: 0.6461\n",
      "Epoch 8: val_accuracy improved from 0.61257 to 0.61820, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.6416 - loss: 0.6461 - val_accuracy: 0.6182 - val_loss: 0.6491\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6579 - loss: 0.6363\n",
      "Epoch 9: val_accuracy improved from 0.61820 to 0.63415, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - accuracy: 0.6578 - loss: 0.6363 - val_accuracy: 0.6341 - val_loss: 0.6397\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6688 - loss: 0.6248\n",
      "Epoch 10: val_accuracy improved from 0.63415 to 0.65197, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.6688 - loss: 0.6247 - val_accuracy: 0.6520 - val_loss: 0.6289\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6781 - loss: 0.6111\n",
      "Epoch 11: val_accuracy improved from 0.65197 to 0.67261, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - accuracy: 0.6781 - loss: 0.6111 - val_accuracy: 0.6726 - val_loss: 0.6167\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6844 - loss: 0.5950\n",
      "Epoch 12: val_accuracy improved from 0.67261 to 0.68574, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - accuracy: 0.6844 - loss: 0.5950 - val_accuracy: 0.6857 - val_loss: 0.6034\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6999 - loss: 0.5768\n",
      "Epoch 13: val_accuracy improved from 0.68574 to 0.68668, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.6999 - loss: 0.5767 - val_accuracy: 0.6867 - val_loss: 0.5903\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7117 - loss: 0.5579\n",
      "Epoch 14: val_accuracy improved from 0.68668 to 0.69231, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - accuracy: 0.7117 - loss: 0.5579 - val_accuracy: 0.6923 - val_loss: 0.5825\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7240 - loss: 0.5433\n",
      "Epoch 15: val_accuracy improved from 0.69231 to 0.69794, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.7240 - loss: 0.5434 - val_accuracy: 0.6979 - val_loss: 0.5798\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7324 - loss: 0.5348\n",
      "Epoch 16: val_accuracy improved from 0.69794 to 0.70356, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - accuracy: 0.7324 - loss: 0.5348 - val_accuracy: 0.7036 - val_loss: 0.5729\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7374 - loss: 0.5284\n",
      "Epoch 17: val_accuracy improved from 0.70356 to 0.70544, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - accuracy: 0.7374 - loss: 0.5284 - val_accuracy: 0.7054 - val_loss: 0.5654\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7419 - loss: 0.5229\n",
      "Epoch 18: val_accuracy improved from 0.70544 to 0.71201, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.7419 - loss: 0.5229 - val_accuracy: 0.7120 - val_loss: 0.5587\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7449 - loss: 0.5179\n",
      "Epoch 19: val_accuracy did not improve from 0.71201\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 116ms/step - accuracy: 0.7448 - loss: 0.5179 - val_accuracy: 0.7120 - val_loss: 0.5526\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7516 - loss: 0.5134\n",
      "Epoch 20: val_accuracy improved from 0.71201 to 0.71951, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - accuracy: 0.7516 - loss: 0.5134 - val_accuracy: 0.7195 - val_loss: 0.5471\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7555 - loss: 0.5092\n",
      "Epoch 21: val_accuracy improved from 0.71951 to 0.72045, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - accuracy: 0.7554 - loss: 0.5092 - val_accuracy: 0.7205 - val_loss: 0.5421\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7570 - loss: 0.5053\n",
      "Epoch 22: val_accuracy improved from 0.72045 to 0.72983, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.7569 - loss: 0.5053 - val_accuracy: 0.7298 - val_loss: 0.5376\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7612 - loss: 0.5016\n",
      "Epoch 23: val_accuracy improved from 0.72983 to 0.73358, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 123ms/step - accuracy: 0.7611 - loss: 0.5016 - val_accuracy: 0.7336 - val_loss: 0.5336\n",
      "Epoch 24/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7637 - loss: 0.4981\n",
      "Epoch 24: val_accuracy improved from 0.73358 to 0.73921, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.7637 - loss: 0.4981 - val_accuracy: 0.7392 - val_loss: 0.5299\n",
      "Epoch 25/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7647 - loss: 0.4948\n",
      "Epoch 25: val_accuracy did not improve from 0.73921\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 117ms/step - accuracy: 0.7646 - loss: 0.4948 - val_accuracy: 0.7392 - val_loss: 0.5265\n",
      "Epoch 26/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7662 - loss: 0.4916\n",
      "Epoch 26: val_accuracy improved from 0.73921 to 0.74390, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.7661 - loss: 0.4916 - val_accuracy: 0.7439 - val_loss: 0.5235\n",
      "Epoch 27/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7666 - loss: 0.4885\n",
      "Epoch 27: val_accuracy improved from 0.74390 to 0.74765, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - accuracy: 0.7665 - loss: 0.4886 - val_accuracy: 0.7477 - val_loss: 0.5208\n",
      "Epoch 28/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7676 - loss: 0.4856\n",
      "Epoch 28: val_accuracy improved from 0.74765 to 0.74859, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - accuracy: 0.7675 - loss: 0.4856 - val_accuracy: 0.7486 - val_loss: 0.5183\n",
      "Epoch 29/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7693 - loss: 0.4827\n",
      "Epoch 29: val_accuracy did not improve from 0.74859\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 115ms/step - accuracy: 0.7692 - loss: 0.4828 - val_accuracy: 0.7486 - val_loss: 0.5160\n",
      "Epoch 30/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7712 - loss: 0.4800\n",
      "Epoch 30: val_accuracy did not improve from 0.74859\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 115ms/step - accuracy: 0.7712 - loss: 0.4800 - val_accuracy: 0.7486 - val_loss: 0.5140\n",
      "Epoch 31/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7740 - loss: 0.4773\n",
      "Epoch 31: val_accuracy improved from 0.74859 to 0.74953, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 119ms/step - accuracy: 0.7740 - loss: 0.4773 - val_accuracy: 0.7495 - val_loss: 0.5121\n",
      "Epoch 32/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7740 - loss: 0.4747\n",
      "Epoch 32: val_accuracy improved from 0.74953 to 0.75141, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 120ms/step - accuracy: 0.7739 - loss: 0.4748 - val_accuracy: 0.7514 - val_loss: 0.5104\n",
      "Epoch 33/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7751 - loss: 0.4722\n",
      "Epoch 33: val_accuracy improved from 0.75141 to 0.75422, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 120ms/step - accuracy: 0.7751 - loss: 0.4722 - val_accuracy: 0.7542 - val_loss: 0.5088\n",
      "Epoch 34/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7766 - loss: 0.4697\n",
      "Epoch 34: val_accuracy improved from 0.75422 to 0.75704, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 120ms/step - accuracy: 0.7766 - loss: 0.4698 - val_accuracy: 0.7570 - val_loss: 0.5074\n",
      "Epoch 35/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7781 - loss: 0.4673\n",
      "Epoch 35: val_accuracy did not improve from 0.75704\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 115ms/step - accuracy: 0.7781 - loss: 0.4673 - val_accuracy: 0.7542 - val_loss: 0.5060\n",
      "Epoch 36/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7808 - loss: 0.4649\n",
      "Epoch 36: val_accuracy did not improve from 0.75704\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 113ms/step - accuracy: 0.7808 - loss: 0.4650 - val_accuracy: 0.7523 - val_loss: 0.5048\n",
      "Epoch 37/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7808 - loss: 0.4626\n",
      "Epoch 37: val_accuracy did not improve from 0.75704\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 116ms/step - accuracy: 0.7808 - loss: 0.4627 - val_accuracy: 0.7514 - val_loss: 0.5037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Sequential name=sequential_73, built=True>,\n",
       " <keras.src.callbacks.history.History at 0x24293788fe0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7120 - loss: 0.5646\n",
      "Test accuracy: 0.7532833218574524\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_combined.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Keeping the above two adjustments, replace your simple RNN model in Part 2 with a Convolutional Neural Network (CNN) to produce sentence representations and perform sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Convolution1D, Flatten\n",
    "\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_combined.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=True),  # Embedding layer is trainable\n",
    "        Convolution1D(16, kernel_size=3, activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.4938 - loss: 0.7037\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53846, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 133ms/step - accuracy: 0.4939 - loss: 0.7036 - val_accuracy: 0.5385 - val_loss: 0.6903\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5456 - loss: 0.6871\n",
      "Epoch 2: val_accuracy improved from 0.53846 to 0.58161, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 131ms/step - accuracy: 0.5457 - loss: 0.6870 - val_accuracy: 0.5816 - val_loss: 0.6789\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5965 - loss: 0.6690\n",
      "Epoch 3: val_accuracy improved from 0.58161 to 0.60694, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 131ms/step - accuracy: 0.5966 - loss: 0.6690 - val_accuracy: 0.6069 - val_loss: 0.6650\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6333 - loss: 0.6457\n",
      "Epoch 4: val_accuracy improved from 0.60694 to 0.62946, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.6334 - loss: 0.6456 - val_accuracy: 0.6295 - val_loss: 0.6523\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6642 - loss: 0.6217\n",
      "Epoch 5: val_accuracy improved from 0.62946 to 0.64540, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 183ms/step - accuracy: 0.6642 - loss: 0.6217 - val_accuracy: 0.6454 - val_loss: 0.6421\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6931 - loss: 0.5992\n",
      "Epoch 6: val_accuracy improved from 0.64540 to 0.65854, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.6931 - loss: 0.5991 - val_accuracy: 0.6585 - val_loss: 0.6341\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.7078 - loss: 0.5809\n",
      "Epoch 7: val_accuracy improved from 0.65854 to 0.67167, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 221ms/step - accuracy: 0.7078 - loss: 0.5809 - val_accuracy: 0.6717 - val_loss: 0.6266\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.7210 - loss: 0.5665\n",
      "Epoch 8: val_accuracy improved from 0.67167 to 0.67261, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 186ms/step - accuracy: 0.7210 - loss: 0.5665 - val_accuracy: 0.6726 - val_loss: 0.6178\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7289 - loss: 0.5550\n",
      "Epoch 9: val_accuracy improved from 0.67261 to 0.67730, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.7288 - loss: 0.5550 - val_accuracy: 0.6773 - val_loss: 0.6100\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7341 - loss: 0.5457\n",
      "Epoch 10: val_accuracy improved from 0.67730 to 0.68199, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.7341 - loss: 0.5457 - val_accuracy: 0.6820 - val_loss: 0.6029\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7388 - loss: 0.5377\n",
      "Epoch 11: val_accuracy improved from 0.68199 to 0.69043, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.7388 - loss: 0.5377 - val_accuracy: 0.6904 - val_loss: 0.5969\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7410 - loss: 0.5306\n",
      "Epoch 12: val_accuracy improved from 0.69043 to 0.69794, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.7410 - loss: 0.5306 - val_accuracy: 0.6979 - val_loss: 0.5916\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7447 - loss: 0.5244\n",
      "Epoch 13: val_accuracy improved from 0.69794 to 0.70263, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.7447 - loss: 0.5244 - val_accuracy: 0.7026 - val_loss: 0.5867\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7485 - loss: 0.5187\n",
      "Epoch 14: val_accuracy did not improve from 0.70263\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 132ms/step - accuracy: 0.7485 - loss: 0.5187 - val_accuracy: 0.7026 - val_loss: 0.5825\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7519 - loss: 0.5134\n",
      "Epoch 15: val_accuracy did not improve from 0.70263\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.7519 - loss: 0.5134 - val_accuracy: 0.7008 - val_loss: 0.5783\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7542 - loss: 0.5085\n",
      "Epoch 16: val_accuracy did not improve from 0.70263\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 167ms/step - accuracy: 0.7542 - loss: 0.5085 - val_accuracy: 0.7026 - val_loss: 0.5749\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6092 - loss: 0.7034\n",
      "Test accuracy: 0.7101313471794128\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_combined.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
