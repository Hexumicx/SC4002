{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3T3QwMxwPhv",
        "outputId": "84061c71-066a-45cf-ac64-2851f6ef9643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (0.26.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from aiohttp->datasets) (1.15.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.22.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: colorama in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: nltk in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: click in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (2.17.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.67.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.9.2)\n",
            "Requirement already satisfied: namex in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jjwx\\anaconda3\\envs\\nlp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets\n",
        "%pip install nltk\n",
        "%pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6McSeWSrwI43"
      },
      "source": [
        "# Part 0. Data Prepraration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc6eHQ8IwI45",
        "outputId": "b4da5896-49dc-45f9-d143-100dc35c6f0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"rotten_tomatoes\")\n",
        "train_dataset = dataset ['train']\n",
        "validation_dataset = dataset ['validation']\n",
        "test_dataset = dataset ['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhTvsb7swI46"
      },
      "source": [
        "# Part 1. Preparing Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BfyWI60wI47"
      },
      "source": [
        "#### (a) What is the size of the vocabulary formed from your training data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffYmg5t5wI47",
        "outputId": "eedb6b74-1d27-4c90-b5cd-0184cfb0b70b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\JJWX\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "vocab = set()\n",
        "for text in train_dataset['text']:\n",
        "    ls = nltk.word_tokenize(text)\n",
        "    for word in ls:\n",
        "        if word.isalpha(): vocab.add(word)\n",
        "#Size of the vocabulary: 15812"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEaufFA1wI47",
        "outputId": "9c58e5ef-a3c7-4103-a665-cb946d93d8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of the vocabulary: 15812\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of the vocabulary:\", len(vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OUr03AqwI48"
      },
      "source": [
        "#### (b) We use OOV (out-of-vocabulary) to refer to those words appeared in the training data but not in the Word2vec (or Glove) dictionary. How many OOV words exist in your training data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_MnWtslwI48",
        "outputId": "7633267e-8f95-48f0-87a1-987c734b35cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fasttext-wiki-news-subwords-300\n",
            "conceptnet-numberbatch-17-06-300\n",
            "word2vec-ruscorpora-300\n",
            "word2vec-google-news-300\n",
            "glove-wiki-gigaword-50\n",
            "glove-wiki-gigaword-100\n",
            "glove-wiki-gigaword-200\n",
            "glove-wiki-gigaword-300\n",
            "glove-twitter-25\n",
            "glove-twitter-50\n",
            "glove-twitter-100\n",
            "glove-twitter-200\n",
            "__testing_word2vec-matrix-synopsis\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "for key in api.info()['models'].keys():\n",
        "    print(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7ZEvG2TawI48"
      },
      "outputs": [],
      "source": [
        "model = api.load(\"glove-wiki-gigaword-100\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujb7pnArwI49",
        "outputId": "58e8d33a-d52b-4c0a-be6f-7962c8427b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of OOV words: 550\n"
          ]
        }
      ],
      "source": [
        "oov_words = set()\n",
        "for word in vocab:\n",
        "    if word not in model:\n",
        "        oov_words.add(word)\n",
        "\n",
        "print(\"Number of OOV words:\", len(oov_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSy_BD90wI49"
      },
      "source": [
        "#### (c) The existence of the OOV words is one of the well-known limitations of Word2vec (or Glove). Without using any transformer-based language models (e.g., BERT, GPT, T5), what do you think is the best strategy to mitigate such limitation? Implement your solution in your source code. Show the corresponding code snippet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bO_10iKqwI49"
      },
      "outputs": [],
      "source": [
        "# Group any words that are not in the model into a single token\n",
        "def wordtovec(word):\n",
        "    if word in model:\n",
        "        return model[word]\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ6rLQa-wI49"
      },
      "source": [
        "# Part 2. Model Training & Evaluation - RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aJZRcXbpwI49"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yTMLPug0wI49"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(model.index_to_key) + 1\n",
        "embedding_dim = model.vector_size\n",
        "word_index = {word: index+1 for index, word in enumerate(model.index_to_key)} # index 0 is reserved for padding\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "biNlG_4VwI4-"
      },
      "outputs": [],
      "source": [
        "for word, idx in word_index.items():\n",
        "    if word in model:\n",
        "        embedding_matrix[idx] = model[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fTACwi_SwI4-"
      },
      "outputs": [],
      "source": [
        "def tokenize(text, word_index):\n",
        "    ls = nltk.word_tokenize(text)\n",
        "    return [word_index[word] for word in ls if word in word_index]\n",
        "\n",
        "X_train = [tokenize(text, word_index) for text in train_dataset['text']]\n",
        "X_val = [tokenize(text, word_index) for text in validation_dataset['text']]\n",
        "X_test = [tokenize(text, word_index) for text in test_dataset['text']]\n",
        "max_length = max(len(seq) for seq in X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2deriXYKwI4-"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n",
        "X_val = pad_sequences(X_val, maxlen=max_length, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ia8WYob7z0qP"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(train_dataset['label'])\n",
        "y_val = np.array(validation_dataset['label'])\n",
        "y_test = np.array(test_dataset['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJT5G8794ZXC"
      },
      "source": [
        "Model Training - Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "best_accuracy = {}\n",
        "class CustomCallback(Callback):\n",
        "    accuracy = 0\n",
        "    cur_key = \"\"\n",
        "    epochs = 0\n",
        "    optimizer = \"\"\n",
        "    batch_size = 0\n",
        "    best_model = None\n",
        "    lr = 0\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.accuracy = 0\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        global best_accuracy\n",
        "        if self.accuracy > best_accuracy.get(\"accuracy\", 0):\n",
        "            best_accuracy = {\n",
        "                \"accuracy\": self.accuracy,\n",
        "                \"epoch\": self.epochs,\n",
        "                \"optimizer\": self.optimizer,\n",
        "                \"batch_size\": self.batch_size,\n",
        "                \"lr\": self.lr\n",
        "            }\n",
        "            print(\"Saved best accuracy for current run:\", self.accuracy, \"at epoch\", self.epochs)\n",
        "            self.best_model.save(filepath=\"best_model.keras\")\n",
        "        print(\"Run completed on:\")\n",
        "        print(self.cur_key)\n",
        "        print(\"Best accuracy for current run:\", self.accuracy, \"at epoch\", self.epochs)\n",
        "        print(\"Training ended\")\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_accuracy = logs['val_accuracy']\n",
        "        if val_accuracy > self.accuracy:\n",
        "            self.accuracy = val_accuracy\n",
        "            self.epochs = epoch\n",
        "            self.best_model = self.model\n",
        "\n",
        "    def set_key(self, optimizer, batch_size, lr):\n",
        "        self.optimizer = optimizer\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.cur_key = f\"optimizer: {optimizer}, batch_size: {batch_size}, lr: {lr}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pvFnR88r6XZJ"
      },
      "outputs": [],
      "source": [
        "def train_model(optimizer, epochs, batch_size, lr):\n",
        "    tf.random.set_seed(0)\n",
        "    np.random.seed(0)\n",
        "    random.seed(0)\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    custom_callback = CustomCallback()\n",
        "    custom_callback.set_key(optimizer, batch_size, lr)\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size,\n",
        "                  output_dim=embedding_dim,\n",
        "                  weights=[embedding_matrix],\n",
        "                  trainable=False),  # Embedding layer is frozen\n",
        "        SimpleRNN(16, return_sequences=False),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[custom_callback, early_stopping]\n",
        "    )\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEFnPNmg7N-Z",
        "outputId": "2545a360-7231-482f-9598-81a616752eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5024 - loss: 0.6963 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5022 - loss: 0.6941 - val_accuracy: 0.4991 - val_loss: 0.6935\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5014 - loss: 0.6936 - val_accuracy: 0.5169 - val_loss: 0.6924\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4911 - loss: 0.6968 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4946 - loss: 0.6936 - val_accuracy: 0.5009 - val_loss: 0.6934\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4982 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
            "Saved best accuracy for current run: 0.5168855786323547 at epoch 2\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 16, lr: 0.005\n",
            "Best accuracy for current run: 0.5168855786323547 at epoch 2\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.5034 - loss: 0.6960 - val_accuracy: 0.5056 - val_loss: 0.6942\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5198 - loss: 0.6926 - val_accuracy: 0.5188 - val_loss: 0.6928\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5258 - loss: 0.6912 - val_accuracy: 0.5009 - val_loss: 0.6949\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5349 - loss: 0.6902 - val_accuracy: 0.5000 - val_loss: 0.7112\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5413 - loss: 0.6904 - val_accuracy: 0.4981 - val_loss: 0.7003\n",
            "Saved best accuracy for current run: 0.5187617540359497 at epoch 1\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 16, lr: 0.005\n",
            "Best accuracy for current run: 0.5187617540359497 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.4996 - loss: 0.6972 - val_accuracy: 0.4991 - val_loss: 0.6994\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5103 - loss: 0.6961 - val_accuracy: 0.5019 - val_loss: 0.6952\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5008 - loss: 0.6967 - val_accuracy: 0.4897 - val_loss: 0.6954\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4946 - loss: 0.6963 - val_accuracy: 0.5019 - val_loss: 0.6954\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4986 - loss: 0.6962 - val_accuracy: 0.5084 - val_loss: 0.6964\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 16, lr: 0.005\n",
            "Best accuracy for current run: 0.508442759513855 at epoch 4\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5200 - loss: 0.6936 - val_accuracy: 0.5704 - val_loss: 0.6848\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5636 - loss: 0.6834 - val_accuracy: 0.5779 - val_loss: 0.6762\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5831 - loss: 0.6738 - val_accuracy: 0.5854 - val_loss: 0.6677\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6120 - loss: 0.6645 - val_accuracy: 0.6032 - val_loss: 0.6616\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6205 - loss: 0.6561 - val_accuracy: 0.6173 - val_loss: 0.6562\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6300 - loss: 0.6487 - val_accuracy: 0.6210 - val_loss: 0.6522\n",
            "Epoch 7/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6413 - loss: 0.6423 - val_accuracy: 0.6248 - val_loss: 0.6491\n",
            "Epoch 8/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6508 - loss: 0.6364 - val_accuracy: 0.6266 - val_loss: 0.6457\n",
            "Epoch 9/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6569 - loss: 0.6312 - val_accuracy: 0.6304 - val_loss: 0.6427\n",
            "Epoch 10/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6641 - loss: 0.6264 - val_accuracy: 0.6351 - val_loss: 0.6403\n",
            "Epoch 11/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6720 - loss: 0.6217 - val_accuracy: 0.6445 - val_loss: 0.6388\n",
            "Epoch 12/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6783 - loss: 0.6177 - val_accuracy: 0.6492 - val_loss: 0.6376\n",
            "Epoch 13/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6804 - loss: 0.6143 - val_accuracy: 0.6501 - val_loss: 0.6364\n",
            "Epoch 14/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6828 - loss: 0.6113 - val_accuracy: 0.6520 - val_loss: 0.6348\n",
            "Epoch 15/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6866 - loss: 0.6083 - val_accuracy: 0.6520 - val_loss: 0.6333\n",
            "Epoch 16/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6916 - loss: 0.6059 - val_accuracy: 0.6595 - val_loss: 0.6315\n",
            "Epoch 17/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6900 - loss: 0.6034 - val_accuracy: 0.6651 - val_loss: 0.6299\n",
            "Epoch 18/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6914 - loss: 0.6011 - val_accuracy: 0.6632 - val_loss: 0.6276\n",
            "Epoch 19/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6895 - loss: 0.5986 - val_accuracy: 0.6632 - val_loss: 0.6254\n",
            "Epoch 20/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6920 - loss: 0.5966 - val_accuracy: 0.6632 - val_loss: 0.6234\n",
            "Epoch 21/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6944 - loss: 0.5946 - val_accuracy: 0.6651 - val_loss: 0.6228\n",
            "Epoch 22/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6944 - loss: 0.5929 - val_accuracy: 0.6651 - val_loss: 0.6216\n",
            "Epoch 23/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6977 - loss: 0.5909 - val_accuracy: 0.6651 - val_loss: 0.6202\n",
            "Epoch 24/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6988 - loss: 0.5891 - val_accuracy: 0.6679 - val_loss: 0.6191\n",
            "Epoch 25/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7039 - loss: 0.5876 - val_accuracy: 0.6698 - val_loss: 0.6182\n",
            "Epoch 26/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7002 - loss: 0.5860 - val_accuracy: 0.6698 - val_loss: 0.6178\n",
            "Epoch 27/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7017 - loss: 0.5845 - val_accuracy: 0.6698 - val_loss: 0.6173\n",
            "Epoch 28/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7017 - loss: 0.5838 - val_accuracy: 0.6698 - val_loss: 0.6172\n",
            "Epoch 29/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7040 - loss: 0.5823 - val_accuracy: 0.6707 - val_loss: 0.6166\n",
            "Epoch 30/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7055 - loss: 0.5813 - val_accuracy: 0.6726 - val_loss: 0.6164\n",
            "Epoch 31/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7084 - loss: 0.5795 - val_accuracy: 0.6745 - val_loss: 0.6158\n",
            "Epoch 32/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7094 - loss: 0.5781 - val_accuracy: 0.6726 - val_loss: 0.6163\n",
            "Epoch 33/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7100 - loss: 0.5782 - val_accuracy: 0.6735 - val_loss: 0.6151\n",
            "Epoch 34/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7113 - loss: 0.5762 - val_accuracy: 0.6735 - val_loss: 0.6161\n",
            "Epoch 35/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7143 - loss: 0.5756 - val_accuracy: 0.6764 - val_loss: 0.6153\n",
            "Epoch 36/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7149 - loss: 0.5738 - val_accuracy: 0.6801 - val_loss: 0.6150\n",
            "Epoch 37/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7165 - loss: 0.5722 - val_accuracy: 0.6782 - val_loss: 0.6145\n",
            "Epoch 38/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7165 - loss: 0.5714 - val_accuracy: 0.6764 - val_loss: 0.6144\n",
            "Epoch 39/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7181 - loss: 0.5702 - val_accuracy: 0.6820 - val_loss: 0.6138\n",
            "Epoch 40/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7194 - loss: 0.5691 - val_accuracy: 0.6792 - val_loss: 0.6136\n",
            "Epoch 41/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7193 - loss: 0.5688 - val_accuracy: 0.6792 - val_loss: 0.6140\n",
            "Epoch 42/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7217 - loss: 0.5676 - val_accuracy: 0.6801 - val_loss: 0.6144\n",
            "Epoch 43/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7193 - loss: 0.5668 - val_accuracy: 0.6820 - val_loss: 0.6141\n",
            "Saved best accuracy for current run: 0.6819887161254883 at epoch 38\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 16, lr: 0.005\n",
            "Best accuracy for current run: 0.6819887161254883 at epoch 38\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4963 - loss: 0.7000 - val_accuracy: 0.4822 - val_loss: 0.7041\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4880 - loss: 0.6980 - val_accuracy: 0.4775 - val_loss: 0.7016\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4901 - loss: 0.6965 - val_accuracy: 0.4737 - val_loss: 0.6978\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5082 - loss: 0.7000 - val_accuracy: 0.5075 - val_loss: 0.6969\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5031 - loss: 0.6973 - val_accuracy: 0.5122 - val_loss: 0.7022\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5014 - loss: 0.6984 - val_accuracy: 0.4812 - val_loss: 0.6961\n",
            "Epoch 7/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5045 - loss: 0.6973 - val_accuracy: 0.5047 - val_loss: 0.6935\n",
            "Epoch 8/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4842 - loss: 0.7002 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
            "Epoch 9/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4767 - loss: 0.6998 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 10/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4814 - loss: 0.6996 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
            "Epoch 11/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4885 - loss: 0.6993 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
            "Epoch 12/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5002 - loss: 0.6977 - val_accuracy: 0.5056 - val_loss: 0.6932\n",
            "Epoch 13/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5080 - loss: 0.6980 - val_accuracy: 0.5047 - val_loss: 0.6931\n",
            "Epoch 14/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5075 - loss: 0.6981 - val_accuracy: 0.5047 - val_loss: 0.6931\n",
            "Epoch 15/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5072 - loss: 0.6981 - val_accuracy: 0.5047 - val_loss: 0.6930\n",
            "Epoch 16/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5066 - loss: 0.6979 - val_accuracy: 0.5047 - val_loss: 0.6932\n",
            "Epoch 17/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5030 - loss: 0.6979 - val_accuracy: 0.5038 - val_loss: 0.6931\n",
            "Epoch 18/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5089 - loss: 0.6971 - val_accuracy: 0.5019 - val_loss: 0.7050\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 16, lr: 0.01\n",
            "Best accuracy for current run: 0.5121951103210449 at epoch 4\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5041 - loss: 0.6967 - val_accuracy: 0.5113 - val_loss: 0.6942\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5094 - loss: 0.6930 - val_accuracy: 0.5216 - val_loss: 0.6931\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5178 - loss: 0.6922 - val_accuracy: 0.5225 - val_loss: 0.6926\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5305 - loss: 0.6918 - val_accuracy: 0.4981 - val_loss: 0.6932\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5230 - loss: 0.6916 - val_accuracy: 0.5338 - val_loss: 0.6917\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5283 - loss: 0.6912 - val_accuracy: 0.5056 - val_loss: 0.6939\n",
            "Epoch 7/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5192 - loss: 0.6930 - val_accuracy: 0.5038 - val_loss: 0.6929\n",
            "Epoch 8/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5264 - loss: 0.6911 - val_accuracy: 0.5075 - val_loss: 0.6929\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 16, lr: 0.01\n",
            "Best accuracy for current run: 0.5337710976600647 at epoch 4\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4862 - loss: 0.7004 - val_accuracy: 0.5000 - val_loss: 0.7176\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4952 - loss: 0.6975 - val_accuracy: 0.5000 - val_loss: 0.7341\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5085 - loss: 0.6972 - val_accuracy: 0.5000 - val_loss: 0.7295\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5019 - loss: 0.6975 - val_accuracy: 0.5159 - val_loss: 0.7040\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5015 - loss: 0.6977 - val_accuracy: 0.4991 - val_loss: 0.6975\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4883 - loss: 0.6984 - val_accuracy: 0.4991 - val_loss: 0.7022\n",
            "Epoch 7/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5068 - loss: 0.6975 - val_accuracy: 0.4887 - val_loss: 0.6987\n",
            "Epoch 8/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4930 - loss: 0.6980 - val_accuracy: 0.4981 - val_loss: 0.6965\n",
            "Epoch 9/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4851 - loss: 0.6990 - val_accuracy: 0.5009 - val_loss: 0.6983\n",
            "Epoch 10/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4955 - loss: 0.6981 - val_accuracy: 0.5075 - val_loss: 0.7017\n",
            "Epoch 11/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5005 - loss: 0.6981 - val_accuracy: 0.4991 - val_loss: 0.7037\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 16, lr: 0.01\n",
            "Best accuracy for current run: 0.5159474611282349 at epoch 3\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5127 - loss: 0.6946 - val_accuracy: 0.5009 - val_loss: 0.7184\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5484 - loss: 0.6876 - val_accuracy: 0.5507 - val_loss: 0.6886\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5997 - loss: 0.6681 - val_accuracy: 0.5760 - val_loss: 0.6709\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6317 - loss: 0.6506 - val_accuracy: 0.6332 - val_loss: 0.6486\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6566 - loss: 0.6371 - val_accuracy: 0.6417 - val_loss: 0.6414\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6577 - loss: 0.6348 - val_accuracy: 0.6557 - val_loss: 0.6318\n",
            "Epoch 7/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6747 - loss: 0.6204 - val_accuracy: 0.6473 - val_loss: 0.6355\n",
            "Epoch 8/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6762 - loss: 0.6198 - val_accuracy: 0.6501 - val_loss: 0.6323\n",
            "Epoch 9/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6825 - loss: 0.6144 - val_accuracy: 0.6595 - val_loss: 0.6258\n",
            "Epoch 10/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6823 - loss: 0.6069 - val_accuracy: 0.6576 - val_loss: 0.6218\n",
            "Epoch 11/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6933 - loss: 0.6005 - val_accuracy: 0.6576 - val_loss: 0.6270\n",
            "Epoch 12/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6904 - loss: 0.6017 - val_accuracy: 0.6735 - val_loss: 0.6230\n",
            "Epoch 13/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6969 - loss: 0.5963 - val_accuracy: 0.6689 - val_loss: 0.6234\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 16, lr: 0.01\n",
            "Best accuracy for current run: 0.6735459566116333 at epoch 11\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5002 - loss: 0.7234 - val_accuracy: 0.4991 - val_loss: 0.8067\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4951 - loss: 0.7350 - val_accuracy: 0.4991 - val_loss: 0.7856\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5060 - loss: 0.7294 - val_accuracy: 0.4991 - val_loss: 0.7728\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5038 - loss: 0.7289 - val_accuracy: 0.4991 - val_loss: 0.7686\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5032 - loss: 0.7287 - val_accuracy: 0.4991 - val_loss: 0.7891\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5014 - loss: 0.7319 - val_accuracy: 0.4991 - val_loss: 0.7932\n",
            "Epoch 7/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5061 - loss: 0.7309 - val_accuracy: 0.4991 - val_loss: 0.7880\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 16, lr: 0.05\n",
            "Best accuracy for current run: 0.4990619122982025 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4958 - loss: 0.6977 - val_accuracy: 0.4972 - val_loss: 0.6955\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5099 - loss: 0.6938 - val_accuracy: 0.5019 - val_loss: 0.6940\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5093 - loss: 0.6935 - val_accuracy: 0.5338 - val_loss: 0.6909\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5144 - loss: 0.6933 - val_accuracy: 0.4934 - val_loss: 0.6939\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5115 - loss: 0.6934 - val_accuracy: 0.4841 - val_loss: 0.6941\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5007 - loss: 0.6936 - val_accuracy: 0.4944 - val_loss: 0.6939\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 16, lr: 0.05\n",
            "Best accuracy for current run: 0.5337710976600647 at epoch 2\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4926 - loss: 0.7378 - val_accuracy: 0.4991 - val_loss: 1.3570\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4992 - loss: 0.7294 - val_accuracy: 0.5000 - val_loss: 0.8464\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5037 - loss: 0.7204 - val_accuracy: 0.4700 - val_loss: 0.9244\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5041 - loss: 0.7223 - val_accuracy: 0.4962 - val_loss: 0.8054\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5109 - loss: 0.7229 - val_accuracy: 0.5263 - val_loss: 0.7344\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5039 - loss: 0.7226 - val_accuracy: 0.4981 - val_loss: 0.7400\n",
            "Epoch 7/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5015 - loss: 0.7226 - val_accuracy: 0.5000 - val_loss: 0.7275\n",
            "Epoch 8/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5006 - loss: 0.7217 - val_accuracy: 0.5000 - val_loss: 1.2179\n",
            "Epoch 9/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5047 - loss: 0.7288 - val_accuracy: 0.4944 - val_loss: 0.7907\n",
            "Epoch 10/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5087 - loss: 0.7237 - val_accuracy: 0.5000 - val_loss: 0.9722\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 16, lr: 0.05\n",
            "Best accuracy for current run: 0.5262663960456848 at epoch 4\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5017 - loss: 0.6984 - val_accuracy: 0.5206 - val_loss: 0.6925\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4777 - loss: 0.6956 - val_accuracy: 0.5075 - val_loss: 0.6936\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5004 - loss: 0.6946 - val_accuracy: 0.5122 - val_loss: 0.6932\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4905 - loss: 0.6951 - val_accuracy: 0.5038 - val_loss: 0.6930\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 16, lr: 0.05\n",
            "Best accuracy for current run: 0.5206378698348999 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5111 - loss: 0.7412 - val_accuracy: 0.4972 - val_loss: 0.8348\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8336\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8333\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8331\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8330\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8329\n",
            "Epoch 7/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8329\n",
            "Epoch 8/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8329\n",
            "Epoch 9/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8329\n",
            "Epoch 10/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8329\n",
            "Epoch 11/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8329\n",
            "Epoch 12/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5109 - loss: 0.7480 - val_accuracy: 0.4972 - val_loss: 0.8329\n",
            "Epoch 13/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5111 - loss: 0.7476 - val_accuracy: 0.5000 - val_loss: 0.8166\n",
            "Epoch 14/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5144 - loss: 0.7491 - val_accuracy: 0.5000 - val_loss: 0.8182\n",
            "Epoch 15/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5144 - loss: 0.7491 - val_accuracy: 0.5000 - val_loss: 0.8171\n",
            "Epoch 16/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5150 - loss: 0.7491 - val_accuracy: 0.5000 - val_loss: 0.8180\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 16, lr: 0.1\n",
            "Best accuracy for current run: 0.5 at epoch 12\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5000 - loss: 0.6990 - val_accuracy: 0.4784 - val_loss: 0.9795\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4976 - loss: 0.7021 - val_accuracy: 0.4916 - val_loss: 0.6941\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5048 - loss: 0.6943 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5045 - loss: 0.6937 - val_accuracy: 0.5009 - val_loss: 0.6934\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5081 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5058 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
            "Epoch 7/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5052 - loss: 0.6935 - val_accuracy: 0.5009 - val_loss: 0.6933\n",
            "Epoch 8/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5054 - loss: 0.6934 - val_accuracy: 0.5009 - val_loss: 0.6933\n",
            "Epoch 9/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5052 - loss: 0.6934 - val_accuracy: 0.5009 - val_loss: 0.6933\n",
            "Epoch 10/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5047 - loss: 0.6934 - val_accuracy: 0.5019 - val_loss: 0.6933\n",
            "Epoch 11/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5050 - loss: 0.6934 - val_accuracy: 0.5019 - val_loss: 0.6933\n",
            "Epoch 12/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5040 - loss: 0.6934 - val_accuracy: 0.5009 - val_loss: 0.6933\n",
            "Epoch 13/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5036 - loss: 0.6934 - val_accuracy: 0.4953 - val_loss: 0.6933\n",
            "Epoch 14/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5043 - loss: 0.6943 - val_accuracy: 0.5038 - val_loss: 0.6938\n",
            "Epoch 15/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5057 - loss: 0.6947 - val_accuracy: 0.4812 - val_loss: 0.7213\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 16, lr: 0.1\n",
            "Best accuracy for current run: 0.5037523508071899 at epoch 13\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5017 - loss: 0.8009 - val_accuracy: 0.5000 - val_loss: 1.2052\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5099 - loss: 0.7692 - val_accuracy: 0.5000 - val_loss: 1.1223\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5119 - loss: 0.7758 - val_accuracy: 0.5000 - val_loss: 1.5146\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5041 - loss: 0.8039 - val_accuracy: 0.5000 - val_loss: 1.5161\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5039 - loss: 0.8064 - val_accuracy: 0.5000 - val_loss: 1.5106\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 16, lr: 0.1\n",
            "Best accuracy for current run: 0.5 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4878 - loss: 0.7022 - val_accuracy: 0.4934 - val_loss: 0.7045\n",
            "Epoch 2/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5085 - loss: 0.6952 - val_accuracy: 0.4812 - val_loss: 0.6997\n",
            "Epoch 3/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5061 - loss: 0.6950 - val_accuracy: 0.4812 - val_loss: 0.6982\n",
            "Epoch 4/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5003 - loss: 0.6947 - val_accuracy: 0.4812 - val_loss: 0.6975\n",
            "Epoch 5/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4985 - loss: 0.6947 - val_accuracy: 0.4822 - val_loss: 0.6972\n",
            "Epoch 6/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4965 - loss: 0.6945 - val_accuracy: 0.4812 - val_loss: 0.6964\n",
            "Epoch 7/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4964 - loss: 0.6944 - val_accuracy: 0.4822 - val_loss: 0.6962\n",
            "Epoch 8/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4950 - loss: 0.6944 - val_accuracy: 0.4822 - val_loss: 0.6957\n",
            "Epoch 9/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4950 - loss: 0.6943 - val_accuracy: 0.4822 - val_loss: 0.6957\n",
            "Epoch 10/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4960 - loss: 0.6942 - val_accuracy: 0.4822 - val_loss: 0.6952\n",
            "Epoch 11/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4960 - loss: 0.6941 - val_accuracy: 0.4822 - val_loss: 0.6951\n",
            "Epoch 12/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4986 - loss: 0.6941 - val_accuracy: 0.4822 - val_loss: 0.6949\n",
            "Epoch 13/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4987 - loss: 0.6941 - val_accuracy: 0.4822 - val_loss: 0.6948\n",
            "Epoch 14/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4985 - loss: 0.6940 - val_accuracy: 0.4822 - val_loss: 0.6947\n",
            "Epoch 15/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4994 - loss: 0.6940 - val_accuracy: 0.4822 - val_loss: 0.6946\n",
            "Epoch 16/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4989 - loss: 0.6940 - val_accuracy: 0.4822 - val_loss: 0.6945\n",
            "Epoch 17/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4973 - loss: 0.6939 - val_accuracy: 0.4822 - val_loss: 0.6945\n",
            "Epoch 18/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4972 - loss: 0.6939 - val_accuracy: 0.4822 - val_loss: 0.6944\n",
            "Epoch 19/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4965 - loss: 0.6939 - val_accuracy: 0.4822 - val_loss: 0.6943\n",
            "Epoch 20/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4960 - loss: 0.6939 - val_accuracy: 0.4822 - val_loss: 0.6943\n",
            "Epoch 21/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4959 - loss: 0.6939 - val_accuracy: 0.4822 - val_loss: 0.6942\n",
            "Epoch 22/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4958 - loss: 0.6938 - val_accuracy: 0.4822 - val_loss: 0.6942\n",
            "Epoch 23/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4958 - loss: 0.6938 - val_accuracy: 0.4822 - val_loss: 0.6941\n",
            "Epoch 24/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4958 - loss: 0.6938 - val_accuracy: 0.4822 - val_loss: 0.6941\n",
            "Epoch 25/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4961 - loss: 0.6938 - val_accuracy: 0.4822 - val_loss: 0.6941\n",
            "Epoch 26/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4970 - loss: 0.6938 - val_accuracy: 0.4822 - val_loss: 0.6940\n",
            "Epoch 27/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4980 - loss: 0.6938 - val_accuracy: 0.4822 - val_loss: 0.6940\n",
            "Epoch 28/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4979 - loss: 0.6937 - val_accuracy: 0.4822 - val_loss: 0.6940\n",
            "Epoch 29/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4959 - loss: 0.6937 - val_accuracy: 0.4822 - val_loss: 0.6939\n",
            "Epoch 30/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4966 - loss: 0.6937 - val_accuracy: 0.4822 - val_loss: 0.6939\n",
            "Epoch 31/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4963 - loss: 0.6937 - val_accuracy: 0.4822 - val_loss: 0.6938\n",
            "Epoch 32/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4967 - loss: 0.6937 - val_accuracy: 0.4822 - val_loss: 0.6938\n",
            "Epoch 33/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4954 - loss: 0.6937 - val_accuracy: 0.4822 - val_loss: 0.6937\n",
            "Epoch 34/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4958 - loss: 0.6937 - val_accuracy: 0.4822 - val_loss: 0.6938\n",
            "Epoch 35/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4965 - loss: 0.6937 - val_accuracy: 0.4822 - val_loss: 0.6937\n",
            "Epoch 36/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4965 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6937\n",
            "Epoch 37/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4965 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6937\n",
            "Epoch 38/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4968 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6937\n",
            "Epoch 39/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4959 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6937\n",
            "Epoch 40/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4959 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6937\n",
            "Epoch 41/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4974 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6936\n",
            "Epoch 42/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4976 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6936\n",
            "Epoch 43/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4961 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6936\n",
            "Epoch 44/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4966 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6936\n",
            "Epoch 45/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4966 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6936\n",
            "Epoch 46/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4967 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6936\n",
            "Epoch 47/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4976 - loss: 0.6936 - val_accuracy: 0.4812 - val_loss: 0.6936\n",
            "Epoch 48/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4967 - loss: 0.6936 - val_accuracy: 0.4812 - val_loss: 0.6936\n",
            "Epoch 49/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4970 - loss: 0.6936 - val_accuracy: 0.4812 - val_loss: 0.6936\n",
            "Epoch 50/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4971 - loss: 0.6935 - val_accuracy: 0.4812 - val_loss: 0.6936\n",
            "Epoch 51/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4969 - loss: 0.6935 - val_accuracy: 0.4812 - val_loss: 0.6935\n",
            "Epoch 52/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4969 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 53/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4969 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 54/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4971 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 55/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4978 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 56/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4967 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 57/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4964 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 58/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4959 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 59/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4979 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 60/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4977 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 61/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4976 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 62/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4979 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 63/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4975 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6934\n",
            "Epoch 64/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4987 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6934\n",
            "Epoch 65/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4988 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6934\n",
            "Epoch 66/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4976 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6934\n",
            "Epoch 67/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4975 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6934\n",
            "Epoch 68/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4971 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6934\n",
            "Epoch 69/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4968 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6934\n",
            "Epoch 70/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4975 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6935\n",
            "Epoch 71/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4973 - loss: 0.6935 - val_accuracy: 0.4812 - val_loss: 0.6935\n",
            "Epoch 72/100\n",
            "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4980 - loss: 0.6935 - val_accuracy: 0.4822 - val_loss: 0.6934\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 16, lr: 0.1\n",
            "Best accuracy for current run: 0.4934333860874176 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4980 - loss: 0.6958 - val_accuracy: 0.4887 - val_loss: 0.6939\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5043 - loss: 0.6941 - val_accuracy: 0.4991 - val_loss: 0.6933\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5024 - loss: 0.6935 - val_accuracy: 0.4972 - val_loss: 0.6938\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4992 - loss: 0.6935 - val_accuracy: 0.4953 - val_loss: 0.6936\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4980 - loss: 0.6936 - val_accuracy: 0.4962 - val_loss: 0.6937\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 32, lr: 0.005\n",
            "Best accuracy for current run: 0.4990619122982025 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5039 - loss: 0.6956 - val_accuracy: 0.5178 - val_loss: 0.6934\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5171 - loss: 0.6923 - val_accuracy: 0.5300 - val_loss: 0.6914\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5283 - loss: 0.6908 - val_accuracy: 0.5478 - val_loss: 0.6887\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5353 - loss: 0.6894 - val_accuracy: 0.5544 - val_loss: 0.6862\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5395 - loss: 0.6883 - val_accuracy: 0.5516 - val_loss: 0.6875\n",
            "Epoch 6/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5422 - loss: 0.6877 - val_accuracy: 0.5619 - val_loss: 0.6839\n",
            "Epoch 7/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5520 - loss: 0.6856 - val_accuracy: 0.5347 - val_loss: 0.6880\n",
            "Epoch 8/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5668 - loss: 0.6829 - val_accuracy: 0.5385 - val_loss: 0.6872\n",
            "Epoch 9/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5746 - loss: 0.6805 - val_accuracy: 0.5441 - val_loss: 0.6875\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 32, lr: 0.005\n",
            "Best accuracy for current run: 0.5619136691093445 at epoch 5\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5017 - loss: 0.6965 - val_accuracy: 0.4953 - val_loss: 0.6933\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4978 - loss: 0.6942 - val_accuracy: 0.4953 - val_loss: 0.6930\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4934 - loss: 0.6940 - val_accuracy: 0.4991 - val_loss: 0.6933\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4897 - loss: 0.6936 - val_accuracy: 0.5141 - val_loss: 0.6950\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5053 - loss: 0.6944 - val_accuracy: 0.5038 - val_loss: 0.6943\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 32, lr: 0.005\n",
            "Best accuracy for current run: 0.5140712857246399 at epoch 3\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5103 - loss: 0.6942 - val_accuracy: 0.5591 - val_loss: 0.6875\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5522 - loss: 0.6874 - val_accuracy: 0.5685 - val_loss: 0.6822\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5709 - loss: 0.6813 - val_accuracy: 0.5666 - val_loss: 0.6765\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5825 - loss: 0.6752 - val_accuracy: 0.5816 - val_loss: 0.6710\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6003 - loss: 0.6692 - val_accuracy: 0.5854 - val_loss: 0.6666\n",
            "Epoch 6/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6095 - loss: 0.6634 - val_accuracy: 0.5929 - val_loss: 0.6627\n",
            "Epoch 7/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6181 - loss: 0.6578 - val_accuracy: 0.5985 - val_loss: 0.6586\n",
            "Epoch 8/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6275 - loss: 0.6524 - val_accuracy: 0.6041 - val_loss: 0.6553\n",
            "Epoch 9/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6347 - loss: 0.6473 - val_accuracy: 0.6135 - val_loss: 0.6524\n",
            "Epoch 10/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6423 - loss: 0.6424 - val_accuracy: 0.6191 - val_loss: 0.6500\n",
            "Epoch 11/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6497 - loss: 0.6379 - val_accuracy: 0.6266 - val_loss: 0.6476\n",
            "Epoch 12/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6555 - loss: 0.6336 - val_accuracy: 0.6370 - val_loss: 0.6450\n",
            "Epoch 13/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6590 - loss: 0.6295 - val_accuracy: 0.6407 - val_loss: 0.6423\n",
            "Epoch 14/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6654 - loss: 0.6258 - val_accuracy: 0.6388 - val_loss: 0.6402\n",
            "Epoch 15/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6694 - loss: 0.6220 - val_accuracy: 0.6417 - val_loss: 0.6385\n",
            "Epoch 16/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6737 - loss: 0.6189 - val_accuracy: 0.6463 - val_loss: 0.6369\n",
            "Epoch 17/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6740 - loss: 0.6166 - val_accuracy: 0.6520 - val_loss: 0.6360\n",
            "Epoch 18/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6779 - loss: 0.6137 - val_accuracy: 0.6520 - val_loss: 0.6346\n",
            "Epoch 19/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6821 - loss: 0.6105 - val_accuracy: 0.6614 - val_loss: 0.6331\n",
            "Epoch 20/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6832 - loss: 0.6078 - val_accuracy: 0.6595 - val_loss: 0.6313\n",
            "Epoch 21/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6854 - loss: 0.6052 - val_accuracy: 0.6604 - val_loss: 0.6287\n",
            "Epoch 22/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6858 - loss: 0.6022 - val_accuracy: 0.6632 - val_loss: 0.6272\n",
            "Epoch 23/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6868 - loss: 0.5997 - val_accuracy: 0.6679 - val_loss: 0.6256\n",
            "Epoch 24/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6902 - loss: 0.5970 - val_accuracy: 0.6689 - val_loss: 0.6246\n",
            "Epoch 25/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6906 - loss: 0.5945 - val_accuracy: 0.6717 - val_loss: 0.6230\n",
            "Epoch 26/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6935 - loss: 0.5928 - val_accuracy: 0.6707 - val_loss: 0.6217\n",
            "Epoch 27/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6961 - loss: 0.5909 - val_accuracy: 0.6707 - val_loss: 0.6200\n",
            "Epoch 28/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6966 - loss: 0.5893 - val_accuracy: 0.6726 - val_loss: 0.6190\n",
            "Epoch 29/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7000 - loss: 0.5878 - val_accuracy: 0.6792 - val_loss: 0.6183\n",
            "Epoch 30/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7008 - loss: 0.5866 - val_accuracy: 0.6811 - val_loss: 0.6180\n",
            "Epoch 31/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7007 - loss: 0.5850 - val_accuracy: 0.6839 - val_loss: 0.6172\n",
            "Epoch 32/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7035 - loss: 0.5838 - val_accuracy: 0.6811 - val_loss: 0.6166\n",
            "Epoch 33/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7040 - loss: 0.5831 - val_accuracy: 0.6792 - val_loss: 0.6161\n",
            "Epoch 34/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7053 - loss: 0.5829 - val_accuracy: 0.6782 - val_loss: 0.6146\n",
            "Epoch 35/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7068 - loss: 0.5827 - val_accuracy: 0.6792 - val_loss: 0.6136\n",
            "Epoch 36/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7059 - loss: 0.5817 - val_accuracy: 0.6829 - val_loss: 0.6139\n",
            "Epoch 37/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7079 - loss: 0.5795 - val_accuracy: 0.6811 - val_loss: 0.6130\n",
            "Epoch 38/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7074 - loss: 0.5790 - val_accuracy: 0.6820 - val_loss: 0.6121\n",
            "Epoch 39/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7103 - loss: 0.5768 - val_accuracy: 0.6848 - val_loss: 0.6109\n",
            "Epoch 40/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7119 - loss: 0.5769 - val_accuracy: 0.6867 - val_loss: 0.6105\n",
            "Epoch 41/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7117 - loss: 0.5759 - val_accuracy: 0.6839 - val_loss: 0.6102\n",
            "Epoch 42/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7136 - loss: 0.5745 - val_accuracy: 0.6829 - val_loss: 0.6092\n",
            "Epoch 43/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7138 - loss: 0.5737 - val_accuracy: 0.6820 - val_loss: 0.6091\n",
            "Epoch 44/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7158 - loss: 0.5725 - val_accuracy: 0.6801 - val_loss: 0.6088\n",
            "Epoch 45/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7164 - loss: 0.5723 - val_accuracy: 0.6829 - val_loss: 0.6088\n",
            "Epoch 46/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7173 - loss: 0.5710 - val_accuracy: 0.6792 - val_loss: 0.6090\n",
            "Epoch 47/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7158 - loss: 0.5711 - val_accuracy: 0.6801 - val_loss: 0.6088\n",
            "Saved best accuracy for current run: 0.6866791844367981 at epoch 39\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 32, lr: 0.005\n",
            "Best accuracy for current run: 0.6866791844367981 at epoch 39\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5015 - loss: 0.6966 - val_accuracy: 0.5009 - val_loss: 0.6937\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4977 - loss: 0.6939 - val_accuracy: 0.4897 - val_loss: 0.6995\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5066 - loss: 0.6987 - val_accuracy: 0.4991 - val_loss: 0.6974\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4972 - loss: 0.6987 - val_accuracy: 0.4709 - val_loss: 0.7287\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 32, lr: 0.01\n",
            "Best accuracy for current run: 0.5009380578994751 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5034 - loss: 0.6962 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5069 - loss: 0.6929 - val_accuracy: 0.5197 - val_loss: 0.6928\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5186 - loss: 0.6919 - val_accuracy: 0.5338 - val_loss: 0.6909\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5371 - loss: 0.6908 - val_accuracy: 0.5478 - val_loss: 0.6893\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5386 - loss: 0.6894 - val_accuracy: 0.5310 - val_loss: 0.6904\n",
            "Epoch 6/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5395 - loss: 0.6894 - val_accuracy: 0.5582 - val_loss: 0.6860\n",
            "Epoch 7/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5497 - loss: 0.6874 - val_accuracy: 0.5159 - val_loss: 0.6894\n",
            "Epoch 8/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5558 - loss: 0.6863 - val_accuracy: 0.5000 - val_loss: 0.7235\n",
            "Epoch 9/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5584 - loss: 0.6851 - val_accuracy: 0.5253 - val_loss: 0.6932\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 32, lr: 0.01\n",
            "Best accuracy for current run: 0.5581613779067993 at epoch 5\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5021 - loss: 0.7001 - val_accuracy: 0.4737 - val_loss: 0.6957\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4986 - loss: 0.6965 - val_accuracy: 0.5131 - val_loss: 0.6931\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4881 - loss: 0.6966 - val_accuracy: 0.5028 - val_loss: 0.6939\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4986 - loss: 0.6963 - val_accuracy: 0.5038 - val_loss: 0.6938\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4864 - loss: 0.6968 - val_accuracy: 0.5056 - val_loss: 0.6938\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 32, lr: 0.01\n",
            "Best accuracy for current run: 0.5131332278251648 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5067 - loss: 0.6949 - val_accuracy: 0.5497 - val_loss: 0.6899\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5411 - loss: 0.6892 - val_accuracy: 0.5413 - val_loss: 0.6866\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5690 - loss: 0.6810 - val_accuracy: 0.5779 - val_loss: 0.6716\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5987 - loss: 0.6678 - val_accuracy: 0.6098 - val_loss: 0.6587\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6257 - loss: 0.6545 - val_accuracy: 0.6182 - val_loss: 0.6510\n",
            "Epoch 6/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6458 - loss: 0.6425 - val_accuracy: 0.6276 - val_loss: 0.6456\n",
            "Epoch 7/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6570 - loss: 0.6341 - val_accuracy: 0.6266 - val_loss: 0.6420\n",
            "Epoch 8/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6676 - loss: 0.6271 - val_accuracy: 0.6445 - val_loss: 0.6362\n",
            "Epoch 9/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6679 - loss: 0.6221 - val_accuracy: 0.6595 - val_loss: 0.6315\n",
            "Epoch 10/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6752 - loss: 0.6176 - val_accuracy: 0.6538 - val_loss: 0.6336\n",
            "Epoch 11/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6834 - loss: 0.6123 - val_accuracy: 0.6679 - val_loss: 0.6221\n",
            "Epoch 12/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6911 - loss: 0.6004 - val_accuracy: 0.6642 - val_loss: 0.6216\n",
            "Epoch 13/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6916 - loss: 0.6027 - val_accuracy: 0.6717 - val_loss: 0.6197\n",
            "Epoch 14/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6955 - loss: 0.5972 - val_accuracy: 0.6811 - val_loss: 0.6075\n",
            "Epoch 15/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6961 - loss: 0.5916 - val_accuracy: 0.6707 - val_loss: 0.6310\n",
            "Epoch 16/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7015 - loss: 0.5913 - val_accuracy: 0.6792 - val_loss: 0.6042\n",
            "Epoch 17/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7030 - loss: 0.5870 - val_accuracy: 0.6764 - val_loss: 0.6104\n",
            "Epoch 18/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7078 - loss: 0.5816 - val_accuracy: 0.6811 - val_loss: 0.6057\n",
            "Epoch 19/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6983 - loss: 0.5842 - val_accuracy: 0.6867 - val_loss: 0.6003\n",
            "Epoch 20/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7144 - loss: 0.5723 - val_accuracy: 0.6839 - val_loss: 0.6044\n",
            "Epoch 21/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7164 - loss: 0.5728 - val_accuracy: 0.6839 - val_loss: 0.5996\n",
            "Epoch 22/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7190 - loss: 0.5719 - val_accuracy: 0.6970 - val_loss: 0.5983\n",
            "Epoch 23/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7143 - loss: 0.5763 - val_accuracy: 0.6914 - val_loss: 0.5960\n",
            "Epoch 24/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7237 - loss: 0.5636 - val_accuracy: 0.6914 - val_loss: 0.5979\n",
            "Epoch 25/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7246 - loss: 0.5606 - val_accuracy: 0.6914 - val_loss: 0.5969\n",
            "Epoch 26/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7234 - loss: 0.5597 - val_accuracy: 0.6951 - val_loss: 0.5999\n",
            "Saved best accuracy for current run: 0.696998119354248 at epoch 21\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 32, lr: 0.01\n",
            "Best accuracy for current run: 0.696998119354248 at epoch 21\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5054 - loss: 0.7100 - val_accuracy: 0.4812 - val_loss: 0.7475\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4975 - loss: 0.7128 - val_accuracy: 0.4803 - val_loss: 0.7681\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5046 - loss: 0.7102 - val_accuracy: 0.4831 - val_loss: 0.7683\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5059 - loss: 0.7127 - val_accuracy: 0.4841 - val_loss: 0.7695\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 32, lr: 0.05\n",
            "Best accuracy for current run: 0.48405253887176514 at epoch 3\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5020 - loss: 0.6972 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5106 - loss: 0.6937 - val_accuracy: 0.5263 - val_loss: 0.6934\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5081 - loss: 0.6934 - val_accuracy: 0.5103 - val_loss: 0.6935\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5081 - loss: 0.6933 - val_accuracy: 0.4934 - val_loss: 0.6935\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5030 - loss: 0.6933 - val_accuracy: 0.4944 - val_loss: 0.6934\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 32, lr: 0.05\n",
            "Best accuracy for current run: 0.5262663960456848 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5013 - loss: 0.7265 - val_accuracy: 0.4887 - val_loss: 0.7605\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5075 - loss: 0.7150 - val_accuracy: 0.5000 - val_loss: 0.9678\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5010 - loss: 0.7220 - val_accuracy: 0.5000 - val_loss: 0.7700\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5051 - loss: 0.7151 - val_accuracy: 0.4756 - val_loss: 0.7943\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 32, lr: 0.05\n",
            "Best accuracy for current run: 0.5 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5062 - loss: 0.6970 - val_accuracy: 0.4765 - val_loss: 0.7068\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4938 - loss: 0.6953 - val_accuracy: 0.4803 - val_loss: 0.6987\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4902 - loss: 0.6947 - val_accuracy: 0.4812 - val_loss: 0.6968\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4939 - loss: 0.6944 - val_accuracy: 0.4812 - val_loss: 0.6964\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4910 - loss: 0.6942 - val_accuracy: 0.4822 - val_loss: 0.6956\n",
            "Epoch 6/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4920 - loss: 0.6941 - val_accuracy: 0.4822 - val_loss: 0.6954\n",
            "Epoch 7/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4894 - loss: 0.6940 - val_accuracy: 0.4822 - val_loss: 0.6948\n",
            "Epoch 8/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4908 - loss: 0.6939 - val_accuracy: 0.4841 - val_loss: 0.6944\n",
            "Epoch 9/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4997 - loss: 0.6938 - val_accuracy: 0.4812 - val_loss: 0.6949\n",
            "Epoch 10/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4884 - loss: 0.6938 - val_accuracy: 0.4822 - val_loss: 0.6947\n",
            "Epoch 11/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4897 - loss: 0.6936 - val_accuracy: 0.4822 - val_loss: 0.6945\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 32, lr: 0.05\n",
            "Best accuracy for current run: 0.48405253887176514 at epoch 7\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5181 - loss: 0.7216 - val_accuracy: 0.5000 - val_loss: 0.7166\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5138 - loss: 0.7177 - val_accuracy: 0.5000 - val_loss: 0.7152\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5120 - loss: 0.7177 - val_accuracy: 0.5000 - val_loss: 0.7111\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5073 - loss: 0.7175 - val_accuracy: 0.5000 - val_loss: 0.7103\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5041 - loss: 0.7186 - val_accuracy: 0.5019 - val_loss: 0.7144\n",
            "Epoch 6/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5098 - loss: 0.7165 - val_accuracy: 0.5019 - val_loss: 0.7147\n",
            "Epoch 7/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5098 - loss: 0.7165 - val_accuracy: 0.5019 - val_loss: 0.7149\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 32, lr: 0.1\n",
            "Best accuracy for current run: 0.501876175403595 at epoch 4\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4954 - loss: 0.6978 - val_accuracy: 0.4991 - val_loss: 0.6945\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5066 - loss: 0.6942 - val_accuracy: 0.4934 - val_loss: 0.6942\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5054 - loss: 0.6939 - val_accuracy: 0.4737 - val_loss: 0.6948\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5034 - loss: 0.6941 - val_accuracy: 0.4859 - val_loss: 0.6944\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5126 - loss: 0.6931 - val_accuracy: 0.4869 - val_loss: 0.6934\n",
            "Epoch 6/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5016 - loss: 0.6935 - val_accuracy: 0.4841 - val_loss: 0.6939\n",
            "Epoch 7/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5034 - loss: 0.6935 - val_accuracy: 0.4803 - val_loss: 0.6940\n",
            "Epoch 8/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5002 - loss: 0.6935 - val_accuracy: 0.4812 - val_loss: 0.6944\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 32, lr: 0.1\n",
            "Best accuracy for current run: 0.4990619122982025 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5014 - loss: 0.7912 - val_accuracy: 0.4794 - val_loss: 0.9308\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4967 - loss: 0.7676 - val_accuracy: 0.4794 - val_loss: 0.9292\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4975 - loss: 0.7659 - val_accuracy: 0.5000 - val_loss: 0.9160\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5044 - loss: 0.7665 - val_accuracy: 0.4803 - val_loss: 0.9620\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4958 - loss: 0.7780 - val_accuracy: 0.4803 - val_loss: 0.9275\n",
            "Epoch 6/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4972 - loss: 0.7642 - val_accuracy: 0.4803 - val_loss: 0.9150\n",
            "Epoch 7/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4966 - loss: 0.7627 - val_accuracy: 0.4803 - val_loss: 0.8862\n",
            "Epoch 8/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4969 - loss: 0.7633 - val_accuracy: 0.5000 - val_loss: 0.9048\n",
            "Epoch 9/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5019 - loss: 0.7580 - val_accuracy: 0.5113 - val_loss: 0.7517\n",
            "Epoch 10/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4958 - loss: 0.7584 - val_accuracy: 0.4803 - val_loss: 0.8018\n",
            "Epoch 11/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4907 - loss: 0.7462 - val_accuracy: 0.4784 - val_loss: 0.7786\n",
            "Epoch 12/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4947 - loss: 0.7490 - val_accuracy: 0.5000 - val_loss: 0.9896\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 32, lr: 0.1\n",
            "Best accuracy for current run: 0.5112570524215698 at epoch 8\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4995 - loss: 0.7029 - val_accuracy: 0.4906 - val_loss: 0.6943\n",
            "Epoch 2/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5059 - loss: 0.6951 - val_accuracy: 0.5122 - val_loss: 0.6942\n",
            "Epoch 3/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4958 - loss: 0.6943 - val_accuracy: 0.4962 - val_loss: 0.6941\n",
            "Epoch 4/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5142 - loss: 0.6942 - val_accuracy: 0.5094 - val_loss: 0.6932\n",
            "Epoch 5/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5094 - loss: 0.6938 - val_accuracy: 0.4906 - val_loss: 0.6931\n",
            "Epoch 6/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4956 - loss: 0.6937 - val_accuracy: 0.4962 - val_loss: 0.6935\n",
            "Epoch 7/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4867 - loss: 0.6937 - val_accuracy: 0.4841 - val_loss: 0.6935\n",
            "Epoch 8/100\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4903 - loss: 0.6938 - val_accuracy: 0.4962 - val_loss: 0.6933\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 32, lr: 0.1\n",
            "Best accuracy for current run: 0.5121951103210449 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5011 - loss: 0.6957 - val_accuracy: 0.4981 - val_loss: 0.6932\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5030 - loss: 0.6936 - val_accuracy: 0.4981 - val_loss: 0.6932\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5023 - loss: 0.6933 - val_accuracy: 0.4972 - val_loss: 0.6933\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5010 - loss: 0.6933 - val_accuracy: 0.4962 - val_loss: 0.6933\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 64, lr: 0.005\n",
            "Best accuracy for current run: 0.49812382459640503 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5065 - loss: 0.6954 - val_accuracy: 0.5150 - val_loss: 0.6940\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5256 - loss: 0.6924 - val_accuracy: 0.5291 - val_loss: 0.6927\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5255 - loss: 0.6911 - val_accuracy: 0.5291 - val_loss: 0.6912\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5323 - loss: 0.6897 - val_accuracy: 0.5328 - val_loss: 0.6898\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5393 - loss: 0.6883 - val_accuracy: 0.5244 - val_loss: 0.6896\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5475 - loss: 0.6871 - val_accuracy: 0.5291 - val_loss: 0.6916\n",
            "Epoch 7/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5485 - loss: 0.6863 - val_accuracy: 0.5319 - val_loss: 0.6929\n",
            "Epoch 8/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5532 - loss: 0.6856 - val_accuracy: 0.5356 - val_loss: 0.6924\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 64, lr: 0.005\n",
            "Best accuracy for current run: 0.5356472730636597 at epoch 7\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5109 - loss: 0.6963 - val_accuracy: 0.4962 - val_loss: 0.6930\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5040 - loss: 0.6941 - val_accuracy: 0.4869 - val_loss: 0.6932\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5025 - loss: 0.6937 - val_accuracy: 0.5169 - val_loss: 0.6933\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5037 - loss: 0.6942 - val_accuracy: 0.4784 - val_loss: 0.7099\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 64, lr: 0.005\n",
            "Best accuracy for current run: 0.5168855786323547 at epoch 2\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5114 - loss: 0.6944 - val_accuracy: 0.5319 - val_loss: 0.6910\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5369 - loss: 0.6895 - val_accuracy: 0.5610 - val_loss: 0.6861\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5581 - loss: 0.6857 - val_accuracy: 0.5619 - val_loss: 0.6837\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5685 - loss: 0.6822 - val_accuracy: 0.5619 - val_loss: 0.6809\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5767 - loss: 0.6788 - val_accuracy: 0.5704 - val_loss: 0.6779\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5865 - loss: 0.6753 - val_accuracy: 0.5741 - val_loss: 0.6746\n",
            "Epoch 7/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5932 - loss: 0.6719 - val_accuracy: 0.5807 - val_loss: 0.6712\n",
            "Epoch 8/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6050 - loss: 0.6684 - val_accuracy: 0.5863 - val_loss: 0.6683\n",
            "Epoch 9/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6121 - loss: 0.6649 - val_accuracy: 0.5919 - val_loss: 0.6658\n",
            "Epoch 10/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6154 - loss: 0.6616 - val_accuracy: 0.5957 - val_loss: 0.6633\n",
            "Epoch 11/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6167 - loss: 0.6583 - val_accuracy: 0.5947 - val_loss: 0.6605\n",
            "Epoch 12/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6220 - loss: 0.6549 - val_accuracy: 0.5976 - val_loss: 0.6579\n",
            "Epoch 13/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6285 - loss: 0.6515 - val_accuracy: 0.6060 - val_loss: 0.6555\n",
            "Epoch 14/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6324 - loss: 0.6481 - val_accuracy: 0.6098 - val_loss: 0.6534\n",
            "Epoch 15/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6368 - loss: 0.6449 - val_accuracy: 0.6144 - val_loss: 0.6515\n",
            "Epoch 16/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6442 - loss: 0.6417 - val_accuracy: 0.6163 - val_loss: 0.6497\n",
            "Epoch 17/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6484 - loss: 0.6386 - val_accuracy: 0.6248 - val_loss: 0.6478\n",
            "Epoch 18/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6508 - loss: 0.6354 - val_accuracy: 0.6313 - val_loss: 0.6460\n",
            "Epoch 19/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6554 - loss: 0.6323 - val_accuracy: 0.6341 - val_loss: 0.6442\n",
            "Epoch 20/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6601 - loss: 0.6294 - val_accuracy: 0.6435 - val_loss: 0.6422\n",
            "Epoch 21/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6625 - loss: 0.6265 - val_accuracy: 0.6417 - val_loss: 0.6404\n",
            "Epoch 22/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6673 - loss: 0.6237 - val_accuracy: 0.6463 - val_loss: 0.6389\n",
            "Epoch 23/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6715 - loss: 0.6212 - val_accuracy: 0.6473 - val_loss: 0.6375\n",
            "Epoch 24/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6748 - loss: 0.6189 - val_accuracy: 0.6473 - val_loss: 0.6363\n",
            "Epoch 25/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6762 - loss: 0.6168 - val_accuracy: 0.6482 - val_loss: 0.6353\n",
            "Epoch 26/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6764 - loss: 0.6147 - val_accuracy: 0.6538 - val_loss: 0.6349\n",
            "Epoch 27/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6792 - loss: 0.6125 - val_accuracy: 0.6548 - val_loss: 0.6340\n",
            "Epoch 28/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6808 - loss: 0.6103 - val_accuracy: 0.6595 - val_loss: 0.6328\n",
            "Epoch 29/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6824 - loss: 0.6083 - val_accuracy: 0.6576 - val_loss: 0.6312\n",
            "Epoch 30/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6842 - loss: 0.6062 - val_accuracy: 0.6623 - val_loss: 0.6298\n",
            "Epoch 31/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6849 - loss: 0.6041 - val_accuracy: 0.6642 - val_loss: 0.6283\n",
            "Epoch 32/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6881 - loss: 0.6021 - val_accuracy: 0.6698 - val_loss: 0.6268\n",
            "Epoch 33/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6885 - loss: 0.6001 - val_accuracy: 0.6717 - val_loss: 0.6255\n",
            "Epoch 34/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6894 - loss: 0.5980 - val_accuracy: 0.6726 - val_loss: 0.6243\n",
            "Epoch 35/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6927 - loss: 0.5960 - val_accuracy: 0.6745 - val_loss: 0.6233\n",
            "Epoch 36/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6918 - loss: 0.5942 - val_accuracy: 0.6717 - val_loss: 0.6223\n",
            "Epoch 37/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6949 - loss: 0.5929 - val_accuracy: 0.6754 - val_loss: 0.6215\n",
            "Epoch 38/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6947 - loss: 0.5916 - val_accuracy: 0.6773 - val_loss: 0.6208\n",
            "Epoch 39/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6973 - loss: 0.5901 - val_accuracy: 0.6764 - val_loss: 0.6202\n",
            "Epoch 40/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6985 - loss: 0.5889 - val_accuracy: 0.6792 - val_loss: 0.6195\n",
            "Epoch 41/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6991 - loss: 0.5875 - val_accuracy: 0.6773 - val_loss: 0.6189\n",
            "Epoch 42/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7006 - loss: 0.5863 - val_accuracy: 0.6745 - val_loss: 0.6178\n",
            "Epoch 43/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7006 - loss: 0.5848 - val_accuracy: 0.6726 - val_loss: 0.6162\n",
            "Epoch 44/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7043 - loss: 0.5837 - val_accuracy: 0.6735 - val_loss: 0.6154\n",
            "Epoch 45/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7038 - loss: 0.5828 - val_accuracy: 0.6754 - val_loss: 0.6151\n",
            "Epoch 46/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7033 - loss: 0.5823 - val_accuracy: 0.6773 - val_loss: 0.6147\n",
            "Epoch 47/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7044 - loss: 0.5804 - val_accuracy: 0.6764 - val_loss: 0.6146\n",
            "Epoch 48/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7060 - loss: 0.5792 - val_accuracy: 0.6782 - val_loss: 0.6143\n",
            "Epoch 49/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7067 - loss: 0.5788 - val_accuracy: 0.6792 - val_loss: 0.6137\n",
            "Epoch 50/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7079 - loss: 0.5790 - val_accuracy: 0.6811 - val_loss: 0.6133\n",
            "Epoch 51/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7086 - loss: 0.5774 - val_accuracy: 0.6839 - val_loss: 0.6113\n",
            "Epoch 52/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7087 - loss: 0.5769 - val_accuracy: 0.6820 - val_loss: 0.6103\n",
            "Epoch 53/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7084 - loss: 0.5760 - val_accuracy: 0.6811 - val_loss: 0.6097\n",
            "Epoch 54/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7090 - loss: 0.5752 - val_accuracy: 0.6811 - val_loss: 0.6095\n",
            "Epoch 55/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7097 - loss: 0.5745 - val_accuracy: 0.6820 - val_loss: 0.6090\n",
            "Epoch 56/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7080 - loss: 0.5736 - val_accuracy: 0.6811 - val_loss: 0.6092\n",
            "Epoch 57/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7100 - loss: 0.5723 - val_accuracy: 0.6829 - val_loss: 0.6092\n",
            "Epoch 58/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7097 - loss: 0.5709 - val_accuracy: 0.6811 - val_loss: 0.6094\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 64, lr: 0.005\n",
            "Best accuracy for current run: 0.6838648915290833 at epoch 50\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5160 - loss: 0.6970 - val_accuracy: 0.4944 - val_loss: 0.6933\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5016 - loss: 0.6936 - val_accuracy: 0.5009 - val_loss: 0.6934\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5062 - loss: 0.6936 - val_accuracy: 0.4981 - val_loss: 0.6935\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5016 - loss: 0.6934 - val_accuracy: 0.4991 - val_loss: 0.6935\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 64, lr: 0.01\n",
            "Best accuracy for current run: 0.5009380578994751 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5074 - loss: 0.6956 - val_accuracy: 0.5066 - val_loss: 0.6947\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5156 - loss: 0.6924 - val_accuracy: 0.5150 - val_loss: 0.6933\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5251 - loss: 0.6913 - val_accuracy: 0.5216 - val_loss: 0.6918\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5314 - loss: 0.6897 - val_accuracy: 0.5216 - val_loss: 0.6934\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5432 - loss: 0.6883 - val_accuracy: 0.5281 - val_loss: 0.6953\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5449 - loss: 0.6869 - val_accuracy: 0.5300 - val_loss: 0.6960\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 64, lr: 0.01\n",
            "Best accuracy for current run: 0.5300187468528748 at epoch 5\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5004 - loss: 0.7006 - val_accuracy: 0.4775 - val_loss: 0.7270\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5014 - loss: 0.6972 - val_accuracy: 0.4784 - val_loss: 0.7314\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5028 - loss: 0.6975 - val_accuracy: 0.4784 - val_loss: 0.7002\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4964 - loss: 0.6956 - val_accuracy: 0.4944 - val_loss: 0.7088\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4970 - loss: 0.6961 - val_accuracy: 0.4784 - val_loss: 0.7050\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4955 - loss: 0.6960 - val_accuracy: 0.5216 - val_loss: 0.6928\n",
            "Epoch 7/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5015 - loss: 0.6953 - val_accuracy: 0.5094 - val_loss: 0.6969\n",
            "Epoch 8/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4870 - loss: 0.6955 - val_accuracy: 0.4822 - val_loss: 0.6971\n",
            "Epoch 9/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4984 - loss: 0.6944 - val_accuracy: 0.5000 - val_loss: 0.6950\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 64, lr: 0.01\n",
            "Best accuracy for current run: 0.5215759873390198 at epoch 5\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5105 - loss: 0.6948 - val_accuracy: 0.5197 - val_loss: 0.6923\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5309 - loss: 0.6905 - val_accuracy: 0.5328 - val_loss: 0.6939\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5518 - loss: 0.6851 - val_accuracy: 0.5403 - val_loss: 0.6921\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5769 - loss: 0.6785 - val_accuracy: 0.5647 - val_loss: 0.6795\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5967 - loss: 0.6708 - val_accuracy: 0.5966 - val_loss: 0.6665\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6163 - loss: 0.6623 - val_accuracy: 0.6060 - val_loss: 0.6592\n",
            "Epoch 7/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6243 - loss: 0.6548 - val_accuracy: 0.6238 - val_loss: 0.6542\n",
            "Epoch 8/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6324 - loss: 0.6478 - val_accuracy: 0.6257 - val_loss: 0.6507\n",
            "Epoch 9/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6454 - loss: 0.6411 - val_accuracy: 0.6351 - val_loss: 0.6463\n",
            "Epoch 10/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6546 - loss: 0.6352 - val_accuracy: 0.6341 - val_loss: 0.6421\n",
            "Epoch 11/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6631 - loss: 0.6279 - val_accuracy: 0.6370 - val_loss: 0.6413\n",
            "Epoch 12/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6695 - loss: 0.6215 - val_accuracy: 0.6510 - val_loss: 0.6353\n",
            "Epoch 13/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6701 - loss: 0.6182 - val_accuracy: 0.6482 - val_loss: 0.6297\n",
            "Epoch 14/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6814 - loss: 0.6124 - val_accuracy: 0.6567 - val_loss: 0.6312\n",
            "Epoch 15/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6842 - loss: 0.6049 - val_accuracy: 0.6623 - val_loss: 0.6210\n",
            "Epoch 16/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6812 - loss: 0.6053 - val_accuracy: 0.6632 - val_loss: 0.6202\n",
            "Epoch 17/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6896 - loss: 0.5979 - val_accuracy: 0.6782 - val_loss: 0.6136\n",
            "Epoch 18/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6945 - loss: 0.5953 - val_accuracy: 0.6679 - val_loss: 0.6125\n",
            "Epoch 19/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6995 - loss: 0.5890 - val_accuracy: 0.6745 - val_loss: 0.6096\n",
            "Epoch 20/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6985 - loss: 0.5863 - val_accuracy: 0.6754 - val_loss: 0.6143\n",
            "Epoch 21/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7038 - loss: 0.5885 - val_accuracy: 0.6829 - val_loss: 0.6071\n",
            "Epoch 22/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7052 - loss: 0.5834 - val_accuracy: 0.6735 - val_loss: 0.6107\n",
            "Epoch 23/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7069 - loss: 0.5854 - val_accuracy: 0.6820 - val_loss: 0.6183\n",
            "Epoch 24/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7092 - loss: 0.5811 - val_accuracy: 0.6839 - val_loss: 0.6023\n",
            "Epoch 25/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7129 - loss: 0.5756 - val_accuracy: 0.6811 - val_loss: 0.6087\n",
            "Epoch 26/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7135 - loss: 0.5730 - val_accuracy: 0.6820 - val_loss: 0.6104\n",
            "Epoch 27/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7136 - loss: 0.5753 - val_accuracy: 0.6914 - val_loss: 0.6017\n",
            "Epoch 28/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7193 - loss: 0.5694 - val_accuracy: 0.6914 - val_loss: 0.6010\n",
            "Epoch 29/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7150 - loss: 0.5709 - val_accuracy: 0.6829 - val_loss: 0.6015\n",
            "Epoch 30/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7202 - loss: 0.5665 - val_accuracy: 0.6886 - val_loss: 0.6004\n",
            "Epoch 31/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7276 - loss: 0.5641 - val_accuracy: 0.6979 - val_loss: 0.5986\n",
            "Epoch 32/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7262 - loss: 0.5636 - val_accuracy: 0.6970 - val_loss: 0.6035\n",
            "Epoch 33/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7289 - loss: 0.5607 - val_accuracy: 0.6989 - val_loss: 0.5978\n",
            "Epoch 34/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7263 - loss: 0.5589 - val_accuracy: 0.6848 - val_loss: 0.5940\n",
            "Epoch 35/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7305 - loss: 0.5575 - val_accuracy: 0.6914 - val_loss: 0.5960\n",
            "Epoch 36/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7317 - loss: 0.5574 - val_accuracy: 0.7017 - val_loss: 0.5975\n",
            "Epoch 37/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7312 - loss: 0.5545 - val_accuracy: 0.6923 - val_loss: 0.5950\n",
            "Saved best accuracy for current run: 0.7016885280609131 at epoch 35\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 64, lr: 0.01\n",
            "Best accuracy for current run: 0.7016885280609131 at epoch 35\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4951 - loss: 0.7036 - val_accuracy: 0.4794 - val_loss: 0.7207\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4929 - loss: 0.7158 - val_accuracy: 0.4803 - val_loss: 0.7792\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5000 - loss: 0.7122 - val_accuracy: 0.4803 - val_loss: 0.7729\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5020 - loss: 0.7120 - val_accuracy: 0.4803 - val_loss: 0.7773\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 64, lr: 0.05\n",
            "Best accuracy for current run: 0.4803001880645752 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5113 - loss: 0.6966 - val_accuracy: 0.4991 - val_loss: 0.6949\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5133 - loss: 0.6932 - val_accuracy: 0.5094 - val_loss: 0.6941\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5151 - loss: 0.6929 - val_accuracy: 0.5216 - val_loss: 0.6939\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5152 - loss: 0.6928 - val_accuracy: 0.5159 - val_loss: 0.6937\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5129 - loss: 0.6927 - val_accuracy: 0.5216 - val_loss: 0.6937\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5171 - loss: 0.6927 - val_accuracy: 0.5169 - val_loss: 0.6938\n",
            "Epoch 7/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5198 - loss: 0.6927 - val_accuracy: 0.5103 - val_loss: 0.6939\n",
            "Epoch 8/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5195 - loss: 0.6926 - val_accuracy: 0.5009 - val_loss: 0.6941\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 64, lr: 0.05\n",
            "Best accuracy for current run: 0.5215759873390198 at epoch 2\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5005 - loss: 0.7319 - val_accuracy: 0.4822 - val_loss: 0.7174\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5157 - loss: 0.7072 - val_accuracy: 0.4784 - val_loss: 0.7589\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4976 - loss: 0.7165 - val_accuracy: 0.4784 - val_loss: 0.7903\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4978 - loss: 0.7137 - val_accuracy: 0.5000 - val_loss: 0.7968\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 64, lr: 0.05\n",
            "Best accuracy for current run: 0.5 at epoch 3\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5024 - loss: 0.6965 - val_accuracy: 0.4981 - val_loss: 0.6946\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5082 - loss: 0.6935 - val_accuracy: 0.5122 - val_loss: 0.6937\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5090 - loss: 0.6930 - val_accuracy: 0.4953 - val_loss: 0.6967\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4977 - loss: 0.6941 - val_accuracy: 0.4962 - val_loss: 0.6938\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5024 - loss: 0.6933 - val_accuracy: 0.4897 - val_loss: 0.6939\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 64, lr: 0.05\n",
            "Best accuracy for current run: 0.5121951103210449 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5063 - loss: 0.7100 - val_accuracy: 0.4794 - val_loss: 0.7731\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4951 - loss: 0.7242 - val_accuracy: 0.4794 - val_loss: 0.7424\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4953 - loss: 0.7175 - val_accuracy: 0.4794 - val_loss: 0.7420\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4959 - loss: 0.7160 - val_accuracy: 0.4794 - val_loss: 0.7458\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4961 - loss: 0.7175 - val_accuracy: 0.4794 - val_loss: 0.7451\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4970 - loss: 0.7171 - val_accuracy: 0.4794 - val_loss: 0.7527\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 64, lr: 0.1\n",
            "Best accuracy for current run: 0.4793621003627777 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5056 - loss: 0.6967 - val_accuracy: 0.5009 - val_loss: 0.6974\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5106 - loss: 0.6940 - val_accuracy: 0.4991 - val_loss: 0.6950\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5081 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5077 - loss: 0.6933 - val_accuracy: 0.5141 - val_loss: 0.6939\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5058 - loss: 0.6932 - val_accuracy: 0.5066 - val_loss: 0.6940\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5092 - loss: 0.6932 - val_accuracy: 0.4962 - val_loss: 0.6939\n",
            "Epoch 7/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5104 - loss: 0.6931 - val_accuracy: 0.5056 - val_loss: 0.6939\n",
            "Epoch 8/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5087 - loss: 0.6931 - val_accuracy: 0.5019 - val_loss: 0.6941\n",
            "Epoch 9/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5095 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 64, lr: 0.1\n",
            "Best accuracy for current run: 0.5140712857246399 at epoch 3\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5192 - loss: 0.8015 - val_accuracy: 0.4756 - val_loss: 1.0145\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5169 - loss: 0.7738 - val_accuracy: 0.4803 - val_loss: 0.9897\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5060 - loss: 0.7357 - val_accuracy: 0.5028 - val_loss: 0.7582\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4999 - loss: 0.7427 - val_accuracy: 0.4972 - val_loss: 1.1399\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4992 - loss: 0.7682 - val_accuracy: 0.4991 - val_loss: 1.0351\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5067 - loss: 0.7782 - val_accuracy: 0.4991 - val_loss: 1.0920\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 64, lr: 0.1\n",
            "Best accuracy for current run: 0.5028142333030701 at epoch 2\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5043 - loss: 0.6980 - val_accuracy: 0.5019 - val_loss: 0.6947\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5059 - loss: 0.6938 - val_accuracy: 0.5009 - val_loss: 0.6939\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5077 - loss: 0.6935 - val_accuracy: 0.4906 - val_loss: 0.6937\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5111 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5113 - loss: 0.6932 - val_accuracy: 0.5131 - val_loss: 0.6928\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5052 - loss: 0.6931 - val_accuracy: 0.5019 - val_loss: 0.6932\n",
            "Epoch 7/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5124 - loss: 0.6931 - val_accuracy: 0.4850 - val_loss: 0.6936\n",
            "Epoch 8/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5058 - loss: 0.6931 - val_accuracy: 0.4962 - val_loss: 0.6930\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 64, lr: 0.1\n",
            "Best accuracy for current run: 0.5131332278251648 at epoch 4\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.5013 - loss: 0.6949 - val_accuracy: 0.4934 - val_loss: 0.6935\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4952 - loss: 0.6941 - val_accuracy: 0.4972 - val_loss: 0.6934\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4986 - loss: 0.6936 - val_accuracy: 0.4981 - val_loss: 0.6933\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4940 - loss: 0.6935 - val_accuracy: 0.4981 - val_loss: 0.6932\n",
            "Epoch 5/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4907 - loss: 0.6935 - val_accuracy: 0.4991 - val_loss: 0.6933\n",
            "Epoch 6/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4940 - loss: 0.6934 - val_accuracy: 0.5009 - val_loss: 0.6934\n",
            "Epoch 7/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4980 - loss: 0.6935 - val_accuracy: 0.4981 - val_loss: 0.6931\n",
            "Epoch 8/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5014 - loss: 0.6933 - val_accuracy: 0.4981 - val_loss: 0.6930\n",
            "Epoch 9/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5003 - loss: 0.6935 - val_accuracy: 0.4991 - val_loss: 0.6953\n",
            "Epoch 10/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4978 - loss: 0.6937 - val_accuracy: 0.4991 - val_loss: 0.6931\n",
            "Epoch 11/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4951 - loss: 0.6934 - val_accuracy: 0.4981 - val_loss: 0.6933\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 128, lr: 0.005\n",
            "Best accuracy for current run: 0.5009380578994751 at epoch 5\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.5026 - loss: 0.6955 - val_accuracy: 0.5141 - val_loss: 0.6941\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5097 - loss: 0.6934 - val_accuracy: 0.5310 - val_loss: 0.6932\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5143 - loss: 0.6923 - val_accuracy: 0.5300 - val_loss: 0.6921\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5200 - loss: 0.6913 - val_accuracy: 0.5319 - val_loss: 0.6907\n",
            "Epoch 5/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5297 - loss: 0.6903 - val_accuracy: 0.5375 - val_loss: 0.6891\n",
            "Epoch 6/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5334 - loss: 0.6893 - val_accuracy: 0.5497 - val_loss: 0.6876\n",
            "Epoch 7/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5404 - loss: 0.6884 - val_accuracy: 0.5525 - val_loss: 0.6864\n",
            "Epoch 8/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5418 - loss: 0.6877 - val_accuracy: 0.5563 - val_loss: 0.6853\n",
            "Epoch 9/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5453 - loss: 0.6871 - val_accuracy: 0.5572 - val_loss: 0.6845\n",
            "Epoch 10/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5477 - loss: 0.6865 - val_accuracy: 0.5572 - val_loss: 0.6838\n",
            "Epoch 11/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5515 - loss: 0.6858 - val_accuracy: 0.5600 - val_loss: 0.6836\n",
            "Epoch 12/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5573 - loss: 0.6852 - val_accuracy: 0.5610 - val_loss: 0.6835\n",
            "Epoch 13/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5607 - loss: 0.6846 - val_accuracy: 0.5638 - val_loss: 0.6832\n",
            "Epoch 14/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5607 - loss: 0.6840 - val_accuracy: 0.5647 - val_loss: 0.6824\n",
            "Epoch 15/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5632 - loss: 0.6832 - val_accuracy: 0.5647 - val_loss: 0.6815\n",
            "Epoch 16/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5658 - loss: 0.6825 - val_accuracy: 0.5722 - val_loss: 0.6805\n",
            "Epoch 17/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5665 - loss: 0.6817 - val_accuracy: 0.5675 - val_loss: 0.6798\n",
            "Epoch 18/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5706 - loss: 0.6809 - val_accuracy: 0.5647 - val_loss: 0.6792\n",
            "Epoch 19/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5739 - loss: 0.6802 - val_accuracy: 0.5675 - val_loss: 0.6786\n",
            "Epoch 20/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5753 - loss: 0.6795 - val_accuracy: 0.5713 - val_loss: 0.6782\n",
            "Epoch 21/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5774 - loss: 0.6787 - val_accuracy: 0.5713 - val_loss: 0.6777\n",
            "Epoch 22/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5776 - loss: 0.6780 - val_accuracy: 0.5713 - val_loss: 0.6772\n",
            "Epoch 23/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5800 - loss: 0.6772 - val_accuracy: 0.5732 - val_loss: 0.6767\n",
            "Epoch 24/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5816 - loss: 0.6764 - val_accuracy: 0.5750 - val_loss: 0.6762\n",
            "Epoch 25/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5844 - loss: 0.6754 - val_accuracy: 0.5750 - val_loss: 0.6757\n",
            "Epoch 26/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5861 - loss: 0.6745 - val_accuracy: 0.5788 - val_loss: 0.6751\n",
            "Epoch 27/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5908 - loss: 0.6735 - val_accuracy: 0.5769 - val_loss: 0.6743\n",
            "Epoch 28/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5926 - loss: 0.6724 - val_accuracy: 0.5788 - val_loss: 0.6733\n",
            "Epoch 29/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5951 - loss: 0.6714 - val_accuracy: 0.5797 - val_loss: 0.6719\n",
            "Epoch 30/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5981 - loss: 0.6703 - val_accuracy: 0.5835 - val_loss: 0.6700\n",
            "Epoch 31/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6014 - loss: 0.6693 - val_accuracy: 0.5835 - val_loss: 0.6680\n",
            "Epoch 32/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6033 - loss: 0.6682 - val_accuracy: 0.5929 - val_loss: 0.6661\n",
            "Epoch 33/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6057 - loss: 0.6672 - val_accuracy: 0.5891 - val_loss: 0.6647\n",
            "Epoch 34/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6087 - loss: 0.6661 - val_accuracy: 0.5901 - val_loss: 0.6636\n",
            "Epoch 35/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6112 - loss: 0.6652 - val_accuracy: 0.5891 - val_loss: 0.6629\n",
            "Epoch 36/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6114 - loss: 0.6642 - val_accuracy: 0.5910 - val_loss: 0.6627\n",
            "Epoch 37/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6101 - loss: 0.6632 - val_accuracy: 0.5929 - val_loss: 0.6625\n",
            "Epoch 38/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6082 - loss: 0.6621 - val_accuracy: 0.5966 - val_loss: 0.6619\n",
            "Epoch 39/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6095 - loss: 0.6609 - val_accuracy: 0.5966 - val_loss: 0.6604\n",
            "Epoch 40/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6107 - loss: 0.6595 - val_accuracy: 0.6032 - val_loss: 0.6586\n",
            "Epoch 41/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6155 - loss: 0.6580 - val_accuracy: 0.6023 - val_loss: 0.6567\n",
            "Epoch 42/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6199 - loss: 0.6566 - val_accuracy: 0.6163 - val_loss: 0.6549\n",
            "Epoch 43/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6257 - loss: 0.6551 - val_accuracy: 0.6098 - val_loss: 0.6538\n",
            "Epoch 44/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6287 - loss: 0.6535 - val_accuracy: 0.6069 - val_loss: 0.6529\n",
            "Epoch 45/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6308 - loss: 0.6523 - val_accuracy: 0.6135 - val_loss: 0.6521\n",
            "Epoch 46/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6343 - loss: 0.6519 - val_accuracy: 0.6135 - val_loss: 0.6515\n",
            "Epoch 47/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6357 - loss: 0.6507 - val_accuracy: 0.6163 - val_loss: 0.6508\n",
            "Epoch 48/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6374 - loss: 0.6487 - val_accuracy: 0.6163 - val_loss: 0.6501\n",
            "Epoch 49/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6417 - loss: 0.6464 - val_accuracy: 0.6201 - val_loss: 0.6489\n",
            "Epoch 50/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6447 - loss: 0.6451 - val_accuracy: 0.6285 - val_loss: 0.6482\n",
            "Epoch 51/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6443 - loss: 0.6440 - val_accuracy: 0.6229 - val_loss: 0.6476\n",
            "Epoch 52/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6483 - loss: 0.6422 - val_accuracy: 0.6220 - val_loss: 0.6473\n",
            "Epoch 53/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6503 - loss: 0.6409 - val_accuracy: 0.6238 - val_loss: 0.6511\n",
            "Epoch 54/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6460 - loss: 0.6429 - val_accuracy: 0.6248 - val_loss: 0.6473\n",
            "Epoch 55/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6543 - loss: 0.6385 - val_accuracy: 0.6201 - val_loss: 0.6482\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 128, lr: 0.005\n",
            "Best accuracy for current run: 0.6285178065299988 at epoch 49\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.5086 - loss: 0.6955 - val_accuracy: 0.4991 - val_loss: 0.6949\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4996 - loss: 0.6953 - val_accuracy: 0.4953 - val_loss: 0.6941\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5027 - loss: 0.6934 - val_accuracy: 0.4906 - val_loss: 0.6935\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4938 - loss: 0.6936 - val_accuracy: 0.5019 - val_loss: 0.6935\n",
            "Epoch 5/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5068 - loss: 0.6938 - val_accuracy: 0.4962 - val_loss: 0.6932\n",
            "Epoch 6/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4939 - loss: 0.6934 - val_accuracy: 0.4972 - val_loss: 0.6929\n",
            "Epoch 7/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4908 - loss: 0.6935 - val_accuracy: 0.4972 - val_loss: 0.6932\n",
            "Epoch 8/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4903 - loss: 0.6933 - val_accuracy: 0.5113 - val_loss: 0.6926\n",
            "Epoch 9/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4996 - loss: 0.6936 - val_accuracy: 0.5019 - val_loss: 0.6932\n",
            "Epoch 10/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4934 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
            "Epoch 11/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4928 - loss: 0.6934 - val_accuracy: 0.4953 - val_loss: 0.6933\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 128, lr: 0.005\n",
            "Best accuracy for current run: 0.5112570524215698 at epoch 7\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.5046 - loss: 0.6948 - val_accuracy: 0.5328 - val_loss: 0.6924\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5294 - loss: 0.6914 - val_accuracy: 0.5366 - val_loss: 0.6889\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5400 - loss: 0.6888 - val_accuracy: 0.5563 - val_loss: 0.6856\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5501 - loss: 0.6867 - val_accuracy: 0.5600 - val_loss: 0.6833\n",
            "Epoch 5/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5569 - loss: 0.6848 - val_accuracy: 0.5572 - val_loss: 0.6814\n",
            "Epoch 6/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5642 - loss: 0.6829 - val_accuracy: 0.5619 - val_loss: 0.6798\n",
            "Epoch 7/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5699 - loss: 0.6809 - val_accuracy: 0.5657 - val_loss: 0.6784\n",
            "Epoch 8/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5781 - loss: 0.6790 - val_accuracy: 0.5647 - val_loss: 0.6771\n",
            "Epoch 9/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5818 - loss: 0.6771 - val_accuracy: 0.5647 - val_loss: 0.6757\n",
            "Epoch 10/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5879 - loss: 0.6751 - val_accuracy: 0.5647 - val_loss: 0.6741\n",
            "Epoch 11/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5917 - loss: 0.6732 - val_accuracy: 0.5741 - val_loss: 0.6725\n",
            "Epoch 12/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5944 - loss: 0.6712 - val_accuracy: 0.5807 - val_loss: 0.6709\n",
            "Epoch 13/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5980 - loss: 0.6692 - val_accuracy: 0.5854 - val_loss: 0.6694\n",
            "Epoch 14/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6016 - loss: 0.6671 - val_accuracy: 0.5891 - val_loss: 0.6679\n",
            "Epoch 15/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6022 - loss: 0.6650 - val_accuracy: 0.5872 - val_loss: 0.6664\n",
            "Epoch 16/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6050 - loss: 0.6628 - val_accuracy: 0.5891 - val_loss: 0.6648\n",
            "Epoch 17/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6081 - loss: 0.6607 - val_accuracy: 0.5929 - val_loss: 0.6632\n",
            "Epoch 18/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6133 - loss: 0.6585 - val_accuracy: 0.5929 - val_loss: 0.6614\n",
            "Epoch 19/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6189 - loss: 0.6564 - val_accuracy: 0.5947 - val_loss: 0.6597\n",
            "Epoch 20/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6224 - loss: 0.6542 - val_accuracy: 0.5957 - val_loss: 0.6579\n",
            "Epoch 21/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6271 - loss: 0.6519 - val_accuracy: 0.5966 - val_loss: 0.6563\n",
            "Epoch 22/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6287 - loss: 0.6497 - val_accuracy: 0.6013 - val_loss: 0.6548\n",
            "Epoch 23/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6335 - loss: 0.6474 - val_accuracy: 0.6051 - val_loss: 0.6534\n",
            "Epoch 24/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6362 - loss: 0.6452 - val_accuracy: 0.6107 - val_loss: 0.6522\n",
            "Epoch 25/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6390 - loss: 0.6430 - val_accuracy: 0.6135 - val_loss: 0.6510\n",
            "Epoch 26/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6416 - loss: 0.6408 - val_accuracy: 0.6154 - val_loss: 0.6498\n",
            "Epoch 27/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6429 - loss: 0.6386 - val_accuracy: 0.6154 - val_loss: 0.6486\n",
            "Epoch 28/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6489 - loss: 0.6364 - val_accuracy: 0.6210 - val_loss: 0.6474\n",
            "Epoch 29/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6510 - loss: 0.6342 - val_accuracy: 0.6238 - val_loss: 0.6462\n",
            "Epoch 30/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6537 - loss: 0.6320 - val_accuracy: 0.6285 - val_loss: 0.6450\n",
            "Epoch 31/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6566 - loss: 0.6299 - val_accuracy: 0.6332 - val_loss: 0.6439\n",
            "Epoch 32/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6606 - loss: 0.6278 - val_accuracy: 0.6360 - val_loss: 0.6427\n",
            "Epoch 33/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6639 - loss: 0.6257 - val_accuracy: 0.6407 - val_loss: 0.6414\n",
            "Epoch 34/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6652 - loss: 0.6236 - val_accuracy: 0.6426 - val_loss: 0.6402\n",
            "Epoch 35/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6694 - loss: 0.6215 - val_accuracy: 0.6463 - val_loss: 0.6389\n",
            "Epoch 36/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6709 - loss: 0.6194 - val_accuracy: 0.6492 - val_loss: 0.6378\n",
            "Epoch 37/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6706 - loss: 0.6175 - val_accuracy: 0.6585 - val_loss: 0.6366\n",
            "Epoch 38/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6715 - loss: 0.6157 - val_accuracy: 0.6604 - val_loss: 0.6353\n",
            "Epoch 39/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6751 - loss: 0.6140 - val_accuracy: 0.6585 - val_loss: 0.6347\n",
            "Epoch 40/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6768 - loss: 0.6124 - val_accuracy: 0.6604 - val_loss: 0.6340\n",
            "Epoch 41/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6778 - loss: 0.6107 - val_accuracy: 0.6632 - val_loss: 0.6335\n",
            "Epoch 42/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6805 - loss: 0.6090 - val_accuracy: 0.6670 - val_loss: 0.6333\n",
            "Epoch 43/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6811 - loss: 0.6070 - val_accuracy: 0.6660 - val_loss: 0.6324\n",
            "Epoch 44/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6821 - loss: 0.6051 - val_accuracy: 0.6651 - val_loss: 0.6313\n",
            "Epoch 45/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6829 - loss: 0.6033 - val_accuracy: 0.6632 - val_loss: 0.6304\n",
            "Epoch 46/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6831 - loss: 0.6016 - val_accuracy: 0.6632 - val_loss: 0.6294\n",
            "Epoch 47/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6841 - loss: 0.5998 - val_accuracy: 0.6642 - val_loss: 0.6285\n",
            "Epoch 48/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6852 - loss: 0.5980 - val_accuracy: 0.6660 - val_loss: 0.6278\n",
            "Epoch 49/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6873 - loss: 0.5964 - val_accuracy: 0.6679 - val_loss: 0.6273\n",
            "Epoch 50/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6887 - loss: 0.5949 - val_accuracy: 0.6717 - val_loss: 0.6269\n",
            "Epoch 51/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6888 - loss: 0.5936 - val_accuracy: 0.6764 - val_loss: 0.6257\n",
            "Epoch 52/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6899 - loss: 0.5922 - val_accuracy: 0.6792 - val_loss: 0.6245\n",
            "Epoch 53/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6918 - loss: 0.5911 - val_accuracy: 0.6782 - val_loss: 0.6230\n",
            "Epoch 54/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6919 - loss: 0.5903 - val_accuracy: 0.6754 - val_loss: 0.6218\n",
            "Epoch 55/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6942 - loss: 0.5895 - val_accuracy: 0.6773 - val_loss: 0.6214\n",
            "Epoch 56/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6956 - loss: 0.5885 - val_accuracy: 0.6764 - val_loss: 0.6211\n",
            "Epoch 57/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6958 - loss: 0.5877 - val_accuracy: 0.6689 - val_loss: 0.6210\n",
            "Epoch 58/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6962 - loss: 0.5872 - val_accuracy: 0.6801 - val_loss: 0.6187\n",
            "Epoch 59/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6971 - loss: 0.5857 - val_accuracy: 0.6820 - val_loss: 0.6183\n",
            "Epoch 60/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6971 - loss: 0.5843 - val_accuracy: 0.6792 - val_loss: 0.6176\n",
            "Epoch 61/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6968 - loss: 0.5829 - val_accuracy: 0.6754 - val_loss: 0.6171\n",
            "Epoch 62/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6979 - loss: 0.5817 - val_accuracy: 0.6820 - val_loss: 0.6157\n",
            "Epoch 63/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6992 - loss: 0.5807 - val_accuracy: 0.6839 - val_loss: 0.6135\n",
            "Epoch 64/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7010 - loss: 0.5805 - val_accuracy: 0.6811 - val_loss: 0.6130\n",
            "Epoch 65/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7002 - loss: 0.5795 - val_accuracy: 0.6792 - val_loss: 0.6129\n",
            "Epoch 66/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7001 - loss: 0.5791 - val_accuracy: 0.6801 - val_loss: 0.6123\n",
            "Epoch 67/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7015 - loss: 0.5780 - val_accuracy: 0.6839 - val_loss: 0.6122\n",
            "Epoch 68/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7009 - loss: 0.5773 - val_accuracy: 0.6848 - val_loss: 0.6117\n",
            "Epoch 69/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7027 - loss: 0.5760 - val_accuracy: 0.6848 - val_loss: 0.6122\n",
            "Epoch 70/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7026 - loss: 0.5760 - val_accuracy: 0.6801 - val_loss: 0.6129\n",
            "Epoch 71/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7036 - loss: 0.5754 - val_accuracy: 0.6811 - val_loss: 0.6131\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 128, lr: 0.005\n",
            "Best accuracy for current run: 0.6848030090332031 at epoch 67\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5077 - loss: 0.6958 - val_accuracy: 0.4962 - val_loss: 0.6960\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5024 - loss: 0.6953 - val_accuracy: 0.5178 - val_loss: 0.6940\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4932 - loss: 0.6968 - val_accuracy: 0.4737 - val_loss: 0.6982\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5017 - loss: 0.6949 - val_accuracy: 0.5056 - val_loss: 0.6942\n",
            "Epoch 5/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4918 - loss: 0.6949 - val_accuracy: 0.5028 - val_loss: 0.6956\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 128, lr: 0.01\n",
            "Best accuracy for current run: 0.5178236365318298 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5038 - loss: 0.6954 - val_accuracy: 0.5235 - val_loss: 0.6936\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5176 - loss: 0.6927 - val_accuracy: 0.5338 - val_loss: 0.6923\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5262 - loss: 0.6914 - val_accuracy: 0.5281 - val_loss: 0.6904\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5339 - loss: 0.6901 - val_accuracy: 0.5535 - val_loss: 0.6882\n",
            "Epoch 5/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5368 - loss: 0.6890 - val_accuracy: 0.5591 - val_loss: 0.6867\n",
            "Epoch 6/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5422 - loss: 0.6880 - val_accuracy: 0.5572 - val_loss: 0.6860\n",
            "Epoch 7/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5468 - loss: 0.6872 - val_accuracy: 0.5629 - val_loss: 0.6835\n",
            "Epoch 8/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5508 - loss: 0.6861 - val_accuracy: 0.5525 - val_loss: 0.6863\n",
            "Epoch 9/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5543 - loss: 0.6856 - val_accuracy: 0.5178 - val_loss: 0.6897\n",
            "Epoch 10/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5541 - loss: 0.6849 - val_accuracy: 0.5197 - val_loss: 0.6894\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 128, lr: 0.01\n",
            "Best accuracy for current run: 0.5628517866134644 at epoch 6\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5072 - loss: 0.6995 - val_accuracy: 0.4794 - val_loss: 0.7116\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4964 - loss: 0.6973 - val_accuracy: 0.4728 - val_loss: 0.7006\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5006 - loss: 0.6958 - val_accuracy: 0.4869 - val_loss: 0.6942\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4950 - loss: 0.6956 - val_accuracy: 0.5084 - val_loss: 0.6931\n",
            "Epoch 5/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4862 - loss: 0.6959 - val_accuracy: 0.4822 - val_loss: 0.7126\n",
            "Epoch 6/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4977 - loss: 0.6959 - val_accuracy: 0.4812 - val_loss: 0.7052\n",
            "Epoch 7/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4982 - loss: 0.6953 - val_accuracy: 0.4803 - val_loss: 0.7089\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 128, lr: 0.01\n",
            "Best accuracy for current run: 0.508442759513855 at epoch 3\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5045 - loss: 0.6950 - val_accuracy: 0.5356 - val_loss: 0.6925\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5280 - loss: 0.6911 - val_accuracy: 0.5600 - val_loss: 0.6879\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5447 - loss: 0.6882 - val_accuracy: 0.5619 - val_loss: 0.6844\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5603 - loss: 0.6849 - val_accuracy: 0.5713 - val_loss: 0.6809\n",
            "Epoch 5/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5713 - loss: 0.6812 - val_accuracy: 0.5732 - val_loss: 0.6784\n",
            "Epoch 6/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5805 - loss: 0.6770 - val_accuracy: 0.5750 - val_loss: 0.6755\n",
            "Epoch 7/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5915 - loss: 0.6724 - val_accuracy: 0.5750 - val_loss: 0.6699\n",
            "Epoch 8/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6048 - loss: 0.6677 - val_accuracy: 0.5872 - val_loss: 0.6643\n",
            "Epoch 9/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6129 - loss: 0.6629 - val_accuracy: 0.5891 - val_loss: 0.6610\n",
            "Epoch 10/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6166 - loss: 0.6583 - val_accuracy: 0.5957 - val_loss: 0.6573\n",
            "Epoch 11/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6262 - loss: 0.6532 - val_accuracy: 0.6116 - val_loss: 0.6539\n",
            "Epoch 12/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6356 - loss: 0.6484 - val_accuracy: 0.6116 - val_loss: 0.6517\n",
            "Epoch 13/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6432 - loss: 0.6437 - val_accuracy: 0.6107 - val_loss: 0.6497\n",
            "Epoch 14/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6448 - loss: 0.6388 - val_accuracy: 0.6248 - val_loss: 0.6473\n",
            "Epoch 15/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6503 - loss: 0.6346 - val_accuracy: 0.6295 - val_loss: 0.6437\n",
            "Epoch 16/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6589 - loss: 0.6294 - val_accuracy: 0.6360 - val_loss: 0.6404\n",
            "Epoch 17/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6647 - loss: 0.6238 - val_accuracy: 0.6445 - val_loss: 0.6461\n",
            "Epoch 18/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6664 - loss: 0.6241 - val_accuracy: 0.6473 - val_loss: 0.6439\n",
            "Epoch 19/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6689 - loss: 0.6195 - val_accuracy: 0.6510 - val_loss: 0.6412\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 128, lr: 0.01\n",
            "Best accuracy for current run: 0.6510319113731384 at epoch 18\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.4911 - loss: 0.7096 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4994 - loss: 0.7011 - val_accuracy: 0.5009 - val_loss: 0.7113\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4955 - loss: 0.7022 - val_accuracy: 0.5000 - val_loss: 0.7016\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4866 - loss: 0.6981 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 128, lr: 0.05\n",
            "Best accuracy for current run: 0.5009380578994751 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4967 - loss: 0.6968 - val_accuracy: 0.5131 - val_loss: 0.6942\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5114 - loss: 0.6929 - val_accuracy: 0.5197 - val_loss: 0.6932\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5195 - loss: 0.6922 - val_accuracy: 0.5216 - val_loss: 0.6925\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5206 - loss: 0.6916 - val_accuracy: 0.5422 - val_loss: 0.6917\n",
            "Epoch 5/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5325 - loss: 0.6910 - val_accuracy: 0.5300 - val_loss: 0.6916\n",
            "Epoch 6/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5331 - loss: 0.6910 - val_accuracy: 0.5047 - val_loss: 0.6924\n",
            "Epoch 7/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5232 - loss: 0.6920 - val_accuracy: 0.5197 - val_loss: 0.6915\n",
            "Epoch 8/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5302 - loss: 0.6910 - val_accuracy: 0.5347 - val_loss: 0.6917\n",
            "Epoch 9/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5228 - loss: 0.6908 - val_accuracy: 0.5066 - val_loss: 0.6944\n",
            "Epoch 10/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5383 - loss: 0.6899 - val_accuracy: 0.5478 - val_loss: 0.6861\n",
            "Epoch 11/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5452 - loss: 0.6911 - val_accuracy: 0.5385 - val_loss: 0.6898\n",
            "Epoch 12/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5435 - loss: 0.6878 - val_accuracy: 0.4962 - val_loss: 0.6941\n",
            "Epoch 13/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4994 - loss: 0.6938 - val_accuracy: 0.4962 - val_loss: 0.6939\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 128, lr: 0.05\n",
            "Best accuracy for current run: 0.5478423833847046 at epoch 9\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.4933 - loss: 0.7425 - val_accuracy: 0.5000 - val_loss: 0.7242\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4976 - loss: 0.7092 - val_accuracy: 0.5000 - val_loss: 0.7685\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4914 - loss: 0.7130 - val_accuracy: 0.5000 - val_loss: 0.7294\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4972 - loss: 0.7106 - val_accuracy: 0.5000 - val_loss: 0.7522\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 128, lr: 0.05\n",
            "Best accuracy for current run: 0.5 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.4999 - loss: 0.6969 - val_accuracy: 0.5075 - val_loss: 0.6934\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5087 - loss: 0.6933 - val_accuracy: 0.4897 - val_loss: 0.6938\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5091 - loss: 0.6931 - val_accuracy: 0.4906 - val_loss: 0.6941\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5149 - loss: 0.6929 - val_accuracy: 0.4878 - val_loss: 0.6940\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 128, lr: 0.05\n",
            "Best accuracy for current run: 0.5075047016143799 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5082 - loss: 0.7198 - val_accuracy: 0.5047 - val_loss: 0.7100\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4913 - loss: 0.7116 - val_accuracy: 0.5000 - val_loss: 0.6968\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5011 - loss: 0.7022 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5011 - loss: 0.7018 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 5/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4999 - loss: 0.7016 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 6/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4999 - loss: 0.7016 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 7/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4999 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 8/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4999 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 9/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4999 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 10/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4999 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 11/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4999 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 12/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4999 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 13/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4991 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 14/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4991 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 15/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 16/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 17/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 18/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 19/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 20/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 21/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 22/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 23/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 24/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 25/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 26/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 27/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 28/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 29/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 30/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 31/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 32/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 33/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 34/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 35/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 36/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 37/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 38/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 39/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 40/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 41/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 42/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 43/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 44/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 45/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 46/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 47/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 48/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 49/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 50/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 51/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 52/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 53/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 54/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 55/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 56/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 57/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 58/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 59/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 60/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 61/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 62/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 63/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 64/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 65/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 66/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 67/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 68/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 69/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 70/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 71/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 72/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 73/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 74/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 75/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 76/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 77/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 78/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 79/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 80/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 81/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 82/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 83/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 84/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 85/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 86/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 87/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 88/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 89/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 90/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 91/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 92/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 93/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 94/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 95/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 96/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 97/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 98/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7016 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 99/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 100/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4992 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Run completed on:\n",
            "optimizer: adam, batch_size: 128, lr: 0.1\n",
            "Best accuracy for current run: 0.504690408706665 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.4996 - loss: 0.6971 - val_accuracy: 0.5084 - val_loss: 0.6933\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5039 - loss: 0.6935 - val_accuracy: 0.5188 - val_loss: 0.6934\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5106 - loss: 0.6933 - val_accuracy: 0.4962 - val_loss: 0.6936\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5056 - loss: 0.6931 - val_accuracy: 0.4878 - val_loss: 0.6941\n",
            "Run completed on:\n",
            "optimizer: sgd, batch_size: 128, lr: 0.1\n",
            "Best accuracy for current run: 0.5187617540359497 at epoch 1\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5074 - loss: 0.8074 - val_accuracy: 0.4765 - val_loss: 0.7558\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4993 - loss: 0.7588 - val_accuracy: 0.4765 - val_loss: 0.8824\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4968 - loss: 0.7750 - val_accuracy: 0.4765 - val_loss: 0.7844\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4983 - loss: 0.7640 - val_accuracy: 0.4765 - val_loss: 0.7999\n",
            "Run completed on:\n",
            "optimizer: rmsprop, batch_size: 128, lr: 0.1\n",
            "Best accuracy for current run: 0.47654783725738525 at epoch 0\n",
            "Training ended\n",
            "Epoch 1/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.4914 - loss: 0.6982 - val_accuracy: 0.4962 - val_loss: 0.6935\n",
            "Epoch 2/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5074 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 3/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5102 - loss: 0.6931 - val_accuracy: 0.5131 - val_loss: 0.6936\n",
            "Epoch 4/100\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5110 - loss: 0.6935 - val_accuracy: 0.4934 - val_loss: 0.6942\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 128, lr: 0.1\n",
            "Best accuracy for current run: 0.5131332278251648 at epoch 2\n",
            "Training ended\n"
          ]
        }
      ],
      "source": [
        "for batch_size in [16, 32, 64, 128]:\n",
        "    for lr in [0.005, 0.01, 0.05, 0.1]:\n",
        "        for optimizer in ['adam', 'sgd', 'rmsprop', 'adagrad']:\n",
        "            train_model(optimizer, 100, batch_size, lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.7016885280609131,\n",
              " 'epoch': 35,\n",
              " 'optimizer': 'adagrad',\n",
              " 'batch_size': 64,\n",
              " 'lr': 0.01}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best model is trained with Optimizer: adagrad, Epoch: 35, Batch_size: 64, Learning_rate: 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cQjhQD_JwI4-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5067 - loss: 0.6949 - val_accuracy: 0.5497 - val_loss: 0.6899\n",
            "Epoch 2/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5411 - loss: 0.6892 - val_accuracy: 0.5413 - val_loss: 0.6866\n",
            "Epoch 3/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5690 - loss: 0.6810 - val_accuracy: 0.5779 - val_loss: 0.6716\n",
            "Epoch 4/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5987 - loss: 0.6678 - val_accuracy: 0.6098 - val_loss: 0.6587\n",
            "Epoch 5/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6257 - loss: 0.6545 - val_accuracy: 0.6182 - val_loss: 0.6510\n",
            "Epoch 6/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6458 - loss: 0.6425 - val_accuracy: 0.6276 - val_loss: 0.6456\n",
            "Epoch 7/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6570 - loss: 0.6341 - val_accuracy: 0.6266 - val_loss: 0.6420\n",
            "Epoch 8/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6676 - loss: 0.6271 - val_accuracy: 0.6445 - val_loss: 0.6362\n",
            "Epoch 9/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6679 - loss: 0.6221 - val_accuracy: 0.6595 - val_loss: 0.6315\n",
            "Epoch 10/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6752 - loss: 0.6176 - val_accuracy: 0.6538 - val_loss: 0.6336\n",
            "Epoch 11/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6834 - loss: 0.6123 - val_accuracy: 0.6679 - val_loss: 0.6221\n",
            "Epoch 12/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6911 - loss: 0.6004 - val_accuracy: 0.6642 - val_loss: 0.6216\n",
            "Epoch 13/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6916 - loss: 0.6027 - val_accuracy: 0.6717 - val_loss: 0.6197\n",
            "Epoch 14/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6955 - loss: 0.5972 - val_accuracy: 0.6811 - val_loss: 0.6075\n",
            "Epoch 15/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6961 - loss: 0.5916 - val_accuracy: 0.6707 - val_loss: 0.6310\n",
            "Epoch 16/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7015 - loss: 0.5913 - val_accuracy: 0.6792 - val_loss: 0.6042\n",
            "Epoch 17/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7030 - loss: 0.5870 - val_accuracy: 0.6764 - val_loss: 0.6104\n",
            "Epoch 18/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7078 - loss: 0.5816 - val_accuracy: 0.6811 - val_loss: 0.6057\n",
            "Epoch 19/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6983 - loss: 0.5842 - val_accuracy: 0.6867 - val_loss: 0.6003\n",
            "Epoch 20/20\n",
            "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7144 - loss: 0.5723 - val_accuracy: 0.6839 - val_loss: 0.6044\n",
            "Run completed on:\n",
            "optimizer: adagrad, batch_size: 32, lr: 0.01\n",
            "Best accuracy for current run: 0.6866791844367981 at epoch 18\n",
            "Training ended\n"
          ]
        }
      ],
      "source": [
        "model, history = train_model(\"adagrad\", 40, 64, 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "37gu7KI9_eWG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6832 - loss: 0.5830 \n",
            "Test accuracy: 0.692307710647583\n"
          ]
        }
      ],
      "source": [
        "best_model = tf.keras.models.load_model(\"best_model.keras\")\n",
        "accuracy = best_model.evaluate(X_val, y_val)\n",
        "print(\"Test accuracy:\", accuracy[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'optimizer': {'module': 'keras.optimizers',\n",
              "  'class_name': 'Adagrad',\n",
              "  'config': {'name': 'adagrad',\n",
              "   'learning_rate': 0.009999999776482582,\n",
              "   'weight_decay': None,\n",
              "   'clipnorm': None,\n",
              "   'global_clipnorm': None,\n",
              "   'clipvalue': None,\n",
              "   'use_ema': False,\n",
              "   'ema_momentum': 0.99,\n",
              "   'ema_overwrite_frequency': None,\n",
              "   'loss_scale_factor': None,\n",
              "   'gradient_accumulation_steps': None,\n",
              "   'initial_accumulator_value': 0.1,\n",
              "   'epsilon': 1e-07},\n",
              "  'registered_name': None},\n",
              " 'loss': 'binary_crossentropy',\n",
              " 'loss_weights': None,\n",
              " 'metrics': ['accuracy'],\n",
              " 'weighted_metrics': None,\n",
              " 'run_eagerly': False,\n",
              " 'steps_per_execution': 1,\n",
              " 'jit_compile': False}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model.get_compile_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Mean pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import AveragePooling1D, GlobalAveragePooling1D\n",
        "def train_model(optimizer, epochs, batch_size, lr):\n",
        "    tf.random.set_seed(0)\n",
        "    np.random.seed(0)\n",
        "    random.seed(0)\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"model_mean.keras\", \n",
        "        monitor='val_accuracy',            \n",
        "        save_best_only=True,           \n",
        "        mode='max',                 \n",
        "        save_weights_only=False,       \n",
        "        verbose=1\n",
        "    )\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size,\n",
        "                  output_dim=embedding_dim,\n",
        "                  weights=[embedding_matrix],\n",
        "                  trainable=False),  # Embedding layer is frozen\n",
        "        SimpleRNN(16, return_sequences=True),\n",
        "        GlobalAveragePooling1D(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[checkpoint_callback, early_stopping]\n",
        "    )\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4601 - loss: 0.6998\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48311, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4605 - loss: 0.6997 - val_accuracy: 0.4831 - val_loss: 0.6947\n",
            "Epoch 2/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4787 - loss: 0.6953\n",
            "Epoch 2: val_accuracy improved from 0.48311 to 0.49062, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.4793 - loss: 0.6953 - val_accuracy: 0.4906 - val_loss: 0.6933\n",
            "Epoch 3/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4952 - loss: 0.6938\n",
            "Epoch 3: val_accuracy improved from 0.49062 to 0.50750, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4956 - loss: 0.6938 - val_accuracy: 0.5075 - val_loss: 0.6922\n",
            "Epoch 4/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5123 - loss: 0.6927\n",
            "Epoch 4: val_accuracy improved from 0.50750 to 0.52533, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5127 - loss: 0.6927 - val_accuracy: 0.5253 - val_loss: 0.6913\n",
            "Epoch 5/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5285 - loss: 0.6917\n",
            "Epoch 5: val_accuracy improved from 0.52533 to 0.53659, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5289 - loss: 0.6916 - val_accuracy: 0.5366 - val_loss: 0.6904\n",
            "Epoch 6/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5450 - loss: 0.6907\n",
            "Epoch 6: val_accuracy improved from 0.53659 to 0.54409, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5451 - loss: 0.6907 - val_accuracy: 0.5441 - val_loss: 0.6895\n",
            "Epoch 7/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5594 - loss: 0.6897\n",
            "Epoch 7: val_accuracy improved from 0.54409 to 0.56004, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.5598 - loss: 0.6897 - val_accuracy: 0.5600 - val_loss: 0.6886\n",
            "Epoch 8/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5722 - loss: 0.6887\n",
            "Epoch 8: val_accuracy improved from 0.56004 to 0.56848, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5723 - loss: 0.6887 - val_accuracy: 0.5685 - val_loss: 0.6876\n",
            "Epoch 9/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5810 - loss: 0.6876\n",
            "Epoch 9: val_accuracy improved from 0.56848 to 0.58068, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5812 - loss: 0.6876 - val_accuracy: 0.5807 - val_loss: 0.6865\n",
            "Epoch 10/100\n",
            "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5916 - loss: 0.6864\n",
            "Epoch 10: val_accuracy improved from 0.58068 to 0.58818, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5918 - loss: 0.6864 - val_accuracy: 0.5882 - val_loss: 0.6853\n",
            "Epoch 11/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6021 - loss: 0.6850\n",
            "Epoch 11: val_accuracy improved from 0.58818 to 0.61069, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6021 - loss: 0.6850 - val_accuracy: 0.6107 - val_loss: 0.6835\n",
            "Epoch 12/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6087 - loss: 0.6827\n",
            "Epoch 12: val_accuracy did not improve from 0.61069\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6085 - loss: 0.6827 - val_accuracy: 0.5901 - val_loss: 0.6763\n",
            "Epoch 13/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5891 - loss: 0.6718\n",
            "Epoch 13: val_accuracy did not improve from 0.61069\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5891 - loss: 0.6718 - val_accuracy: 0.5863 - val_loss: 0.6690\n",
            "Epoch 14/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6123 - loss: 0.6547\n",
            "Epoch 14: val_accuracy did not improve from 0.61069\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6123 - loss: 0.6546 - val_accuracy: 0.6051 - val_loss: 0.6593\n",
            "Epoch 15/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6127 - loss: 0.6544\n",
            "Epoch 15: val_accuracy improved from 0.61069 to 0.63227, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6127 - loss: 0.6542 - val_accuracy: 0.6323 - val_loss: 0.6423\n",
            "Epoch 16/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6410 - loss: 0.6358\n",
            "Epoch 16: val_accuracy did not improve from 0.63227\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6409 - loss: 0.6358 - val_accuracy: 0.6210 - val_loss: 0.6440\n",
            "Epoch 17/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6461 - loss: 0.6316\n",
            "Epoch 17: val_accuracy improved from 0.63227 to 0.63602, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6461 - loss: 0.6315 - val_accuracy: 0.6360 - val_loss: 0.6371\n",
            "Epoch 18/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5980 - loss: 0.6664\n",
            "Epoch 18: val_accuracy did not improve from 0.63602\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5984 - loss: 0.6661 - val_accuracy: 0.6276 - val_loss: 0.6403\n",
            "Epoch 19/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6617 - loss: 0.6233\n",
            "Epoch 19: val_accuracy did not improve from 0.63602\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6616 - loss: 0.6234 - val_accuracy: 0.6351 - val_loss: 0.6366\n",
            "Epoch 20/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6552 - loss: 0.6235\n",
            "Epoch 20: val_accuracy improved from 0.63602 to 0.64447, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6551 - loss: 0.6235 - val_accuracy: 0.6445 - val_loss: 0.6309\n",
            "Epoch 21/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6555 - loss: 0.6251\n",
            "Epoch 21: val_accuracy did not improve from 0.64447\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6552 - loss: 0.6253 - val_accuracy: 0.6379 - val_loss: 0.6352\n",
            "Epoch 22/100\n",
            "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6663 - loss: 0.6207\n",
            "Epoch 22: val_accuracy did not improve from 0.64447\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6655 - loss: 0.6214 - val_accuracy: 0.6360 - val_loss: 0.6390\n",
            "Epoch 23/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6616 - loss: 0.6188\n",
            "Epoch 23: val_accuracy improved from 0.64447 to 0.64916, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6616 - loss: 0.6187 - val_accuracy: 0.6492 - val_loss: 0.6282\n",
            "Epoch 24/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6611 - loss: 0.6184\n",
            "Epoch 24: val_accuracy did not improve from 0.64916\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6610 - loss: 0.6184 - val_accuracy: 0.6426 - val_loss: 0.6314\n",
            "Epoch 25/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6713 - loss: 0.6130\n",
            "Epoch 25: val_accuracy improved from 0.64916 to 0.66041, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6710 - loss: 0.6131 - val_accuracy: 0.6604 - val_loss: 0.6216\n",
            "Epoch 26/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6796 - loss: 0.6057\n",
            "Epoch 26: val_accuracy improved from 0.66041 to 0.66510, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6793 - loss: 0.6059 - val_accuracy: 0.6651 - val_loss: 0.6193\n",
            "Epoch 27/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5710 - loss: 0.6967\n",
            "Epoch 27: val_accuracy did not improve from 0.66510\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5719 - loss: 0.6959 - val_accuracy: 0.6604 - val_loss: 0.6225\n",
            "Epoch 28/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6794 - loss: 0.6094\n",
            "Epoch 28: val_accuracy did not improve from 0.66510\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6788 - loss: 0.6097 - val_accuracy: 0.6623 - val_loss: 0.6202\n",
            "Epoch 29/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6804 - loss: 0.6078\n",
            "Epoch 29: val_accuracy improved from 0.66510 to 0.66698, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6802 - loss: 0.6080 - val_accuracy: 0.6670 - val_loss: 0.6186\n",
            "Epoch 30/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6779 - loss: 0.6079\n",
            "Epoch 30: val_accuracy did not improve from 0.66698\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6773 - loss: 0.6083 - val_accuracy: 0.6520 - val_loss: 0.6266\n",
            "Epoch 31/100\n",
            "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6781 - loss: 0.6091\n",
            "Epoch 31: val_accuracy improved from 0.66698 to 0.66979, saving model to model_mean.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6778 - loss: 0.6093 - val_accuracy: 0.6698 - val_loss: 0.6173\n",
            "Epoch 32/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6778 - loss: 0.6075\n",
            "Epoch 32: val_accuracy did not improve from 0.66979\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6775 - loss: 0.6077 - val_accuracy: 0.6632 - val_loss: 0.6180\n",
            "Epoch 33/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6838 - loss: 0.6029\n",
            "Epoch 33: val_accuracy did not improve from 0.66979\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6835 - loss: 0.6031 - val_accuracy: 0.6295 - val_loss: 0.6549\n",
            "Epoch 34/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6268 - loss: 0.6511\n",
            "Epoch 34: val_accuracy did not improve from 0.66979\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6274 - loss: 0.6505 - val_accuracy: 0.6548 - val_loss: 0.6263\n"
          ]
        }
      ],
      "source": [
        "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.6595\n",
            "Test accuracy: 0.6594746708869934\n"
          ]
        }
      ],
      "source": [
        "best_model = tf.keras.models.load_model(\"model_mean.keras\")\n",
        "accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", accuracy[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Max pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPooling1D\n",
        "def train_model(optimizer, epochs, batch_size, lr):\n",
        "    tf.random.set_seed(0)\n",
        "    np.random.seed(0)\n",
        "    random.seed(0)\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"model_max.keras\", \n",
        "        monitor='val_accuracy',            \n",
        "        save_best_only=True,           \n",
        "        mode='max',                 \n",
        "        save_weights_only=False,       \n",
        "        verbose=1\n",
        "    )\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size,\n",
        "                  output_dim=embedding_dim,\n",
        "                  weights=[embedding_matrix],\n",
        "                  trainable=False),  # Embedding layer is frozen\n",
        "        SimpleRNN(16, return_sequences=True),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[checkpoint_callback, early_stopping]\n",
        "    )\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5151 - loss: 0.7030\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53565, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5150 - loss: 0.7028 - val_accuracy: 0.5356 - val_loss: 0.6869\n",
            "Epoch 2/100\n",
            "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5330 - loss: 0.6903\n",
            "Epoch 2: val_accuracy improved from 0.53565 to 0.55629, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5328 - loss: 0.6903 - val_accuracy: 0.5563 - val_loss: 0.6838\n",
            "Epoch 3/100\n",
            "\u001b[1m124/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5487 - loss: 0.6866\n",
            "Epoch 3: val_accuracy improved from 0.55629 to 0.57129, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5487 - loss: 0.6866 - val_accuracy: 0.5713 - val_loss: 0.6805\n",
            "Epoch 4/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5630 - loss: 0.6823\n",
            "Epoch 4: val_accuracy improved from 0.57129 to 0.59568, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5630 - loss: 0.6824 - val_accuracy: 0.5957 - val_loss: 0.6769\n",
            "Epoch 5/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5837 - loss: 0.6765\n",
            "Epoch 5: val_accuracy did not improve from 0.59568\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5837 - loss: 0.6765 - val_accuracy: 0.5947 - val_loss: 0.6728\n",
            "Epoch 6/100\n",
            "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6057 - loss: 0.6695\n",
            "Epoch 6: val_accuracy improved from 0.59568 to 0.60507, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6056 - loss: 0.6695 - val_accuracy: 0.6051 - val_loss: 0.6670\n",
            "Epoch 7/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6229 - loss: 0.6618\n",
            "Epoch 7: val_accuracy improved from 0.60507 to 0.61914, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6230 - loss: 0.6618 - val_accuracy: 0.6191 - val_loss: 0.6602\n",
            "Epoch 8/100\n",
            "\u001b[1m125/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6357 - loss: 0.6535\n",
            "Epoch 8: val_accuracy improved from 0.61914 to 0.62946, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6360 - loss: 0.6535 - val_accuracy: 0.6295 - val_loss: 0.6522\n",
            "Epoch 9/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6503 - loss: 0.6452\n",
            "Epoch 9: val_accuracy improved from 0.62946 to 0.64916, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6504 - loss: 0.6452 - val_accuracy: 0.6492 - val_loss: 0.6443\n",
            "Epoch 10/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6654 - loss: 0.6364\n",
            "Epoch 10: val_accuracy improved from 0.64916 to 0.65760, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6655 - loss: 0.6364 - val_accuracy: 0.6576 - val_loss: 0.6363\n",
            "Epoch 11/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6755 - loss: 0.6270\n",
            "Epoch 11: val_accuracy improved from 0.65760 to 0.66604, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6755 - loss: 0.6270 - val_accuracy: 0.6660 - val_loss: 0.6287\n",
            "Epoch 12/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6813 - loss: 0.6176\n",
            "Epoch 12: val_accuracy improved from 0.66604 to 0.66979, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6815 - loss: 0.6176 - val_accuracy: 0.6698 - val_loss: 0.6213\n",
            "Epoch 13/100\n",
            "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6914 - loss: 0.6081\n",
            "Epoch 13: val_accuracy improved from 0.66979 to 0.67167, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6914 - loss: 0.6081 - val_accuracy: 0.6717 - val_loss: 0.6135\n",
            "Epoch 14/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7013 - loss: 0.5991\n",
            "Epoch 14: val_accuracy improved from 0.67167 to 0.67636, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7012 - loss: 0.5991 - val_accuracy: 0.6764 - val_loss: 0.6056\n",
            "Epoch 15/100\n",
            "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7113 - loss: 0.5910\n",
            "Epoch 15: val_accuracy improved from 0.67636 to 0.68293, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7110 - loss: 0.5910 - val_accuracy: 0.6829 - val_loss: 0.5979\n",
            "Epoch 16/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7184 - loss: 0.5833\n",
            "Epoch 16: val_accuracy improved from 0.68293 to 0.69418, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7181 - loss: 0.5834 - val_accuracy: 0.6942 - val_loss: 0.5907\n",
            "Epoch 17/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7199 - loss: 0.5762\n",
            "Epoch 17: val_accuracy improved from 0.69418 to 0.70544, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7196 - loss: 0.5762 - val_accuracy: 0.7054 - val_loss: 0.5839\n",
            "Epoch 18/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7226 - loss: 0.5693\n",
            "Epoch 18: val_accuracy improved from 0.70544 to 0.71295, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7222 - loss: 0.5694 - val_accuracy: 0.7129 - val_loss: 0.5780\n",
            "Epoch 19/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7270 - loss: 0.5630\n",
            "Epoch 19: val_accuracy improved from 0.71295 to 0.71857, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7268 - loss: 0.5630 - val_accuracy: 0.7186 - val_loss: 0.5726\n",
            "Epoch 20/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7319 - loss: 0.5571\n",
            "Epoch 20: val_accuracy improved from 0.71857 to 0.72514, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7317 - loss: 0.5572 - val_accuracy: 0.7251 - val_loss: 0.5678\n",
            "Epoch 21/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7347 - loss: 0.5517\n",
            "Epoch 21: val_accuracy did not improve from 0.72514\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7344 - loss: 0.5517 - val_accuracy: 0.7251 - val_loss: 0.5633\n",
            "Epoch 22/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7379 - loss: 0.5465\n",
            "Epoch 22: val_accuracy improved from 0.72514 to 0.72608, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7376 - loss: 0.5466 - val_accuracy: 0.7261 - val_loss: 0.5590\n",
            "Epoch 23/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7396 - loss: 0.5417\n",
            "Epoch 23: val_accuracy did not improve from 0.72608\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7393 - loss: 0.5418 - val_accuracy: 0.7195 - val_loss: 0.5553\n",
            "Epoch 24/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7405 - loss: 0.5373\n",
            "Epoch 24: val_accuracy did not improve from 0.72608\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7402 - loss: 0.5374 - val_accuracy: 0.7186 - val_loss: 0.5518\n",
            "Epoch 25/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7433 - loss: 0.5336\n",
            "Epoch 25: val_accuracy did not improve from 0.72608\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7431 - loss: 0.5337 - val_accuracy: 0.7195 - val_loss: 0.5489\n",
            "Epoch 26/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7450 - loss: 0.5294\n",
            "Epoch 26: val_accuracy did not improve from 0.72608\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7447 - loss: 0.5295 - val_accuracy: 0.7223 - val_loss: 0.5460\n",
            "Epoch 27/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7478 - loss: 0.5259\n",
            "Epoch 27: val_accuracy improved from 0.72608 to 0.73077, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7477 - loss: 0.5259 - val_accuracy: 0.7308 - val_loss: 0.5438\n",
            "Epoch 28/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7492 - loss: 0.5230\n",
            "Epoch 28: val_accuracy did not improve from 0.73077\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7489 - loss: 0.5231 - val_accuracy: 0.7280 - val_loss: 0.5409\n",
            "Epoch 29/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7511 - loss: 0.5199\n",
            "Epoch 29: val_accuracy did not improve from 0.73077\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7511 - loss: 0.5199 - val_accuracy: 0.7298 - val_loss: 0.5394\n",
            "Epoch 30/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7518 - loss: 0.5174\n",
            "Epoch 30: val_accuracy improved from 0.73077 to 0.73734, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7515 - loss: 0.5175 - val_accuracy: 0.7373 - val_loss: 0.5381\n",
            "Epoch 31/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7504 - loss: 0.5145\n",
            "Epoch 31: val_accuracy did not improve from 0.73734\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7502 - loss: 0.5146 - val_accuracy: 0.7364 - val_loss: 0.5371\n",
            "Epoch 32/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7523 - loss: 0.5130\n",
            "Epoch 32: val_accuracy did not improve from 0.73734\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7522 - loss: 0.5131 - val_accuracy: 0.7364 - val_loss: 0.5348\n",
            "Epoch 33/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7546 - loss: 0.5102\n",
            "Epoch 33: val_accuracy did not improve from 0.73734\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7544 - loss: 0.5103 - val_accuracy: 0.7364 - val_loss: 0.5330\n",
            "Epoch 34/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7528 - loss: 0.5096\n",
            "Epoch 34: val_accuracy improved from 0.73734 to 0.74109, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7527 - loss: 0.5096 - val_accuracy: 0.7411 - val_loss: 0.5321\n",
            "Epoch 35/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7552 - loss: 0.5064\n",
            "Epoch 35: val_accuracy improved from 0.74109 to 0.74296, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7551 - loss: 0.5064 - val_accuracy: 0.7430 - val_loss: 0.5315\n",
            "Epoch 36/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7508 - loss: 0.5143\n",
            "Epoch 36: val_accuracy did not improve from 0.74296\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7503 - loss: 0.5146 - val_accuracy: 0.7336 - val_loss: 0.5369\n",
            "Epoch 37/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7595 - loss: 0.5051\n",
            "Epoch 37: val_accuracy did not improve from 0.74296\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7594 - loss: 0.5051 - val_accuracy: 0.7411 - val_loss: 0.5323\n",
            "Epoch 38/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7610 - loss: 0.5011\n",
            "Epoch 38: val_accuracy improved from 0.74296 to 0.74390, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7609 - loss: 0.5012 - val_accuracy: 0.7439 - val_loss: 0.5289\n",
            "Epoch 39/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7586 - loss: 0.4999\n",
            "Epoch 39: val_accuracy did not improve from 0.74390\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7585 - loss: 0.5000 - val_accuracy: 0.7439 - val_loss: 0.5281\n",
            "Epoch 40/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7607 - loss: 0.4983\n",
            "Epoch 40: val_accuracy did not improve from 0.74390\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7605 - loss: 0.4984 - val_accuracy: 0.7430 - val_loss: 0.5272\n",
            "Epoch 41/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7616 - loss: 0.4969\n",
            "Epoch 41: val_accuracy did not improve from 0.74390\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7614 - loss: 0.4970 - val_accuracy: 0.7430 - val_loss: 0.5268\n",
            "Epoch 42/100\n",
            "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7599 - loss: 0.4981\n",
            "Epoch 42: val_accuracy did not improve from 0.74390\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7597 - loss: 0.4982 - val_accuracy: 0.7439 - val_loss: 0.5249\n",
            "Epoch 43/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7684 - loss: 0.4938\n",
            "Epoch 43: val_accuracy did not improve from 0.74390\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7680 - loss: 0.4940 - val_accuracy: 0.7430 - val_loss: 0.5248\n",
            "Epoch 44/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7677 - loss: 0.4927\n",
            "Epoch 44: val_accuracy did not improve from 0.74390\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7676 - loss: 0.4928 - val_accuracy: 0.7430 - val_loss: 0.5244\n",
            "Epoch 45/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7685 - loss: 0.4912\n",
            "Epoch 45: val_accuracy did not improve from 0.74390\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7682 - loss: 0.4913 - val_accuracy: 0.7439 - val_loss: 0.5241\n",
            "Epoch 46/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7695 - loss: 0.4908\n",
            "Epoch 46: val_accuracy improved from 0.74390 to 0.74765, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7692 - loss: 0.4910 - val_accuracy: 0.7477 - val_loss: 0.5230\n",
            "Epoch 47/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7712 - loss: 0.4912\n",
            "Epoch 47: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7709 - loss: 0.4912 - val_accuracy: 0.7448 - val_loss: 0.5227\n",
            "Epoch 48/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7706 - loss: 0.4882\n",
            "Epoch 48: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7704 - loss: 0.4883 - val_accuracy: 0.7411 - val_loss: 0.5228\n",
            "Epoch 49/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7712 - loss: 0.4869\n",
            "Epoch 49: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7711 - loss: 0.4869 - val_accuracy: 0.7458 - val_loss: 0.5222\n",
            "Epoch 50/100\n",
            "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7734 - loss: 0.4851\n",
            "Epoch 50: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7731 - loss: 0.4852 - val_accuracy: 0.7439 - val_loss: 0.5213\n",
            "Epoch 51/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7745 - loss: 0.4841\n",
            "Epoch 51: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7743 - loss: 0.4842 - val_accuracy: 0.7467 - val_loss: 0.5211\n",
            "Epoch 52/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7744 - loss: 0.4836\n",
            "Epoch 52: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7743 - loss: 0.4836 - val_accuracy: 0.7458 - val_loss: 0.5206\n",
            "Epoch 53/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7763 - loss: 0.4822\n",
            "Epoch 53: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7761 - loss: 0.4823 - val_accuracy: 0.7477 - val_loss: 0.5200\n",
            "Epoch 54/100\n",
            "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7780 - loss: 0.4810\n",
            "Epoch 54: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7778 - loss: 0.4811 - val_accuracy: 0.7467 - val_loss: 0.5205\n",
            "Epoch 55/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7778 - loss: 0.4805\n",
            "Epoch 55: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7776 - loss: 0.4805 - val_accuracy: 0.7458 - val_loss: 0.5205\n",
            "Epoch 56/100\n",
            "\u001b[1m126/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7796 - loss: 0.4793\n",
            "Epoch 56: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7789 - loss: 0.4795 - val_accuracy: 0.7467 - val_loss: 0.5200\n",
            "Epoch 57/100\n",
            "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7806 - loss: 0.4786\n",
            "Epoch 57: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7801 - loss: 0.4787 - val_accuracy: 0.7458 - val_loss: 0.5197\n",
            "Epoch 58/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7803 - loss: 0.4787\n",
            "Epoch 58: val_accuracy did not improve from 0.74765\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7801 - loss: 0.4788 - val_accuracy: 0.7167 - val_loss: 0.5482\n",
            "Epoch 59/100\n",
            "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7653 - loss: 0.4942\n",
            "Epoch 59: val_accuracy improved from 0.74765 to 0.75047, saving model to model_max.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7653 - loss: 0.4941 - val_accuracy: 0.7505 - val_loss: 0.5241\n",
            "Epoch 60/100\n",
            "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7747 - loss: 0.4776\n",
            "Epoch 60: val_accuracy did not improve from 0.75047\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7744 - loss: 0.4777 - val_accuracy: 0.7486 - val_loss: 0.5205\n"
          ]
        }
      ],
      "source": [
        "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7174 - loss: 0.5568\n",
            "Test accuracy: 0.7514071464538574\n"
          ]
        }
      ],
      "source": [
        "best_model = tf.keras.models.load_model(\"model_max.keras\")\n",
        "accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", accuracy[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "def train_model(optimizer, epochs, batch_size, lr):\n",
        "    tf.random.set_seed(0)\n",
        "    np.random.seed(0)\n",
        "    random.seed(0)\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"model_dense.keras\", \n",
        "        monitor='val_accuracy',            \n",
        "        save_best_only=True,           \n",
        "        mode='max',                 \n",
        "        save_weights_only=False,       \n",
        "        verbose=1\n",
        "    )\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size,\n",
        "                  output_dim=embedding_dim,\n",
        "                  weights=[embedding_matrix],\n",
        "                  trainable=True),  # Embedding layer is frozen\n",
        "        SimpleRNN(16, return_sequences=True),\n",
        "        Flatten(),\n",
        "        Dense(62, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[checkpoint_callback, early_stopping]\n",
        "    )\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5301 - loss: 0.7015\n",
            "Epoch 1: val_accuracy improved from -inf to 0.54128, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 185ms/step - accuracy: 0.5303 - loss: 0.7014 - val_accuracy: 0.5413 - val_loss: 0.6979\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.6130 - loss: 0.6606\n",
            "Epoch 2: val_accuracy improved from 0.54128 to 0.56848, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 145ms/step - accuracy: 0.6131 - loss: 0.6605 - val_accuracy: 0.5685 - val_loss: 0.7107\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6440 - loss: 0.6323\n",
            "Epoch 3: val_accuracy improved from 0.56848 to 0.60413, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 147ms/step - accuracy: 0.6440 - loss: 0.6322 - val_accuracy: 0.6041 - val_loss: 0.6806\n",
            "Epoch 4/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6822 - loss: 0.6002\n",
            "Epoch 4: val_accuracy improved from 0.60413 to 0.61351, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 146ms/step - accuracy: 0.6822 - loss: 0.6002 - val_accuracy: 0.6135 - val_loss: 0.6676\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7066 - loss: 0.5786\n",
            "Epoch 5: val_accuracy improved from 0.61351 to 0.63602, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.7066 - loss: 0.5786 - val_accuracy: 0.6360 - val_loss: 0.6486\n",
            "Epoch 6/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7247 - loss: 0.5593\n",
            "Epoch 6: val_accuracy improved from 0.63602 to 0.63790, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 147ms/step - accuracy: 0.7246 - loss: 0.5593 - val_accuracy: 0.6379 - val_loss: 0.6427\n",
            "Epoch 7/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7338 - loss: 0.5452\n",
            "Epoch 7: val_accuracy improved from 0.63790 to 0.66135, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.7337 - loss: 0.5452 - val_accuracy: 0.6614 - val_loss: 0.6292\n",
            "Epoch 8/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7417 - loss: 0.5327\n",
            "Epoch 8: val_accuracy improved from 0.66135 to 0.66510, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.7417 - loss: 0.5327 - val_accuracy: 0.6651 - val_loss: 0.6173\n",
            "Epoch 9/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7505 - loss: 0.5222\n",
            "Epoch 9: val_accuracy improved from 0.66510 to 0.67636, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.7505 - loss: 0.5223 - val_accuracy: 0.6764 - val_loss: 0.6069\n",
            "Epoch 10/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7535 - loss: 0.5149\n",
            "Epoch 10: val_accuracy improved from 0.67636 to 0.68386, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 147ms/step - accuracy: 0.7534 - loss: 0.5149 - val_accuracy: 0.6839 - val_loss: 0.6032\n",
            "Epoch 11/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7631 - loss: 0.5037\n",
            "Epoch 11: val_accuracy improved from 0.68386 to 0.68762, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.7630 - loss: 0.5037 - val_accuracy: 0.6876 - val_loss: 0.5981\n",
            "Epoch 12/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7663 - loss: 0.4971\n",
            "Epoch 12: val_accuracy improved from 0.68762 to 0.68856, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 152ms/step - accuracy: 0.7662 - loss: 0.4971 - val_accuracy: 0.6886 - val_loss: 0.5951\n",
            "Epoch 13/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7725 - loss: 0.4892\n",
            "Epoch 13: val_accuracy improved from 0.68856 to 0.69512, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 157ms/step - accuracy: 0.7724 - loss: 0.4892 - val_accuracy: 0.6951 - val_loss: 0.5917\n",
            "Epoch 14/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7775 - loss: 0.4809\n",
            "Epoch 14: val_accuracy improved from 0.69512 to 0.69700, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 156ms/step - accuracy: 0.7774 - loss: 0.4810 - val_accuracy: 0.6970 - val_loss: 0.5860\n",
            "Epoch 15/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7820 - loss: 0.4745\n",
            "Epoch 15: val_accuracy did not improve from 0.69700\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 146ms/step - accuracy: 0.7819 - loss: 0.4746 - val_accuracy: 0.6942 - val_loss: 0.5931\n",
            "Epoch 16/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7855 - loss: 0.4672\n",
            "Epoch 16: val_accuracy improved from 0.69700 to 0.69794, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 152ms/step - accuracy: 0.7855 - loss: 0.4672 - val_accuracy: 0.6979 - val_loss: 0.5843\n",
            "Epoch 17/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7884 - loss: 0.4604\n",
            "Epoch 17: val_accuracy improved from 0.69794 to 0.70075, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 160ms/step - accuracy: 0.7883 - loss: 0.4604 - val_accuracy: 0.7008 - val_loss: 0.5775\n",
            "Epoch 18/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7945 - loss: 0.4535\n",
            "Epoch 18: val_accuracy improved from 0.70075 to 0.70732, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 165ms/step - accuracy: 0.7945 - loss: 0.4535 - val_accuracy: 0.7073 - val_loss: 0.5747\n",
            "Epoch 19/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7965 - loss: 0.4472\n",
            "Epoch 19: val_accuracy did not improve from 0.70732\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.7965 - loss: 0.4472 - val_accuracy: 0.7036 - val_loss: 0.5740\n",
            "Epoch 20/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.8014 - loss: 0.4406\n",
            "Epoch 20: val_accuracy improved from 0.70732 to 0.70919, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.8014 - loss: 0.4407 - val_accuracy: 0.7092 - val_loss: 0.5678\n",
            "Epoch 21/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.8030 - loss: 0.4352\n",
            "Epoch 21: val_accuracy did not improve from 0.70919\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 138ms/step - accuracy: 0.8030 - loss: 0.4353 - val_accuracy: 0.7073 - val_loss: 0.5660\n",
            "Epoch 22/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.8093 - loss: 0.4292\n",
            "Epoch 22: val_accuracy did not improve from 0.70919\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 139ms/step - accuracy: 0.8092 - loss: 0.4292 - val_accuracy: 0.7064 - val_loss: 0.5719\n",
            "Epoch 23/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.8145 - loss: 0.4231\n",
            "Epoch 23: val_accuracy improved from 0.70919 to 0.71013, saving model to model_dense.keras\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.8144 - loss: 0.4232 - val_accuracy: 0.7101 - val_loss: 0.5620\n",
            "Epoch 24/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8190 - loss: 0.4165\n",
            "Epoch 24: val_accuracy did not improve from 0.71013\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 168ms/step - accuracy: 0.8189 - loss: 0.4165 - val_accuracy: 0.7101 - val_loss: 0.5596\n",
            "Epoch 25/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.8217 - loss: 0.4106\n",
            "Epoch 25: val_accuracy did not improve from 0.71013\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 193ms/step - accuracy: 0.8217 - loss: 0.4106 - val_accuracy: 0.7083 - val_loss: 0.5612\n",
            "Epoch 26/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8235 - loss: 0.4053\n",
            "Epoch 26: val_accuracy did not improve from 0.71013\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 183ms/step - accuracy: 0.8235 - loss: 0.4053 - val_accuracy: 0.7083 - val_loss: 0.5615\n",
            "Epoch 27/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8259 - loss: 0.3992\n",
            "Epoch 27: val_accuracy did not improve from 0.71013\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 160ms/step - accuracy: 0.8259 - loss: 0.3992 - val_accuracy: 0.7083 - val_loss: 0.5606\n"
          ]
        }
      ],
      "source": [
        "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6231 - loss: 0.7368\n",
            "Test accuracy: 0.7232645153999329\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "best_model = tf.keras.models.load_model(\"model_dense.keras\")\n",
        "accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", accuracy[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk92r_ZsrSpi"
      },
      "source": [
        "# Part 3. Enhancement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KqKwEpbsrdS"
      },
      "source": [
        "#### 1. Instead of keeping the word embeddings fixed, now update the word embeddings (the same way as model parameters) during the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K0Do_y_onlw"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size,\n",
        "              output_dim=embedding_dim,\n",
        "              weights=[embedding_matrix],\n",
        "              trainable=True),  # Embedding layer is frozen\n",
        "    SimpleRNN(16, return_sequences=False),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01) #Static learning rate\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXX18PkzurVx"
      },
      "source": [
        "#### 2. As discussed in Question 1(c), apply your solution in mitigating the influence of OOV words and train your model again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqnGXOHhvkMX"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(model.index_to_key) + 1\n",
        "embedding_dim = model.vector_size\n",
        "word_index = {word: index+1 for index, word in enumerate(model.index_to_key)} # index 0 is reserved for padding\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF-3ABACvkMZ"
      },
      "outputs": [],
      "source": [
        "for word, idx in word_index.items():\n",
        "    if word in model:\n",
        "        embedding_matrix[idx] = model[word]\n",
        "embedding_matrix[-1] = np.zeros(embedding_dim) #Add last idx as UNK word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43whGTSCvkMZ"
      },
      "outputs": [],
      "source": [
        "def tokenize(text, word_index):\n",
        "    ls = nltk.word_tokenize(text)\n",
        "    return [word_index[word] for word in ls if word in word_index else vocab_size+1]\n",
        "\n",
        "X_train = [tokenize(text, word_index) for text in train_dataset['text']]\n",
        "X_val = [tokenize(text, word_index) for text in validation_dataset['text']]\n",
        "X_test = [tokenize(text, word_index) for text in test_dataset['text']]\n",
        "max_length = max(len(seq) for seq in X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdWGgBiavkMZ"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n",
        "X_val = pad_sequences(X_val, maxlen=max_length, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUXkRq0gvkMa"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(train_dataset['label'])\n",
        "y_val = np.array(validation_dataset['label'])\n",
        "y_test = np.array(test_dataset['label'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NLP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
