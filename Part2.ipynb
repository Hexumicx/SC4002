{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0. Data Prepraration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset ['train']\n",
    "validation_dataset = dataset ['validation']\n",
    "test_dataset = dataset ['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Model Training & Evaluation - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-100\")\n",
    "vocab_size = len(model.index_to_key) + 1\n",
    "embedding_dim = model.vector_size\n",
    "word_index = {word: index+1 for index, word in enumerate(model.index_to_key)} # index 0 is reserved for padding\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[idx] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, word_index):\n",
    "    ls = nltk.word_tokenize(text)\n",
    "    return [word_index[word] for word in ls if word in word_index]\n",
    "\n",
    "X_train = [tokenize(text, word_index) for text in train_dataset['text']]\n",
    "X_val = [tokenize(text, word_index) for text in validation_dataset['text']]\n",
    "X_test = [tokenize(text, word_index) for text in test_dataset['text']]\n",
    "max_length = max(len(seq) for seq in X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_val = pad_sequences(X_val, maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_dataset['label'])\n",
    "y_val = np.array(validation_dataset['label'])\n",
    "y_test = np.array(test_dataset['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "best_accuracy = {}\n",
    "class CustomCallback(Callback):\n",
    "    accuracy = 0\n",
    "    cur_key = \"\"\n",
    "    epochs = 0\n",
    "    optimizer = \"\"\n",
    "    batch_size = 0\n",
    "    best_model = None\n",
    "    lr = 0\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.accuracy = 0\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        global best_accuracy\n",
    "        if self.accuracy > best_accuracy.get(\"accuracy\", 0):\n",
    "            best_accuracy = {\n",
    "                \"accuracy\": self.accuracy,\n",
    "                \"epoch\": self.epochs,\n",
    "                \"optimizer\": self.optimizer,\n",
    "                \"batch_size\": self.batch_size,\n",
    "                \"lr\": self.lr\n",
    "            }\n",
    "            print(\"Saved best accuracy for current run:\", self.accuracy, \"at epoch\", self.epochs)\n",
    "            self.best_model.save(filepath=\"best_model.keras\")\n",
    "        print(\"Run completed on:\")\n",
    "        print(self.cur_key)\n",
    "        print(\"Best accuracy for current run:\", self.accuracy, \"at epoch\", self.epochs)\n",
    "        print(\"Training ended\")\n",
    "\n",
    "\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_accuracy = logs['val_accuracy']\n",
    "        if val_accuracy > self.accuracy:\n",
    "            self.accuracy = val_accuracy\n",
    "            self.epochs = epoch\n",
    "            self.best_model = self.model\n",
    "\n",
    "    def set_key(self, optimizer, batch_size, lr):\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.cur_key = f\"optimizer: {optimizer}, batch_size: {batch_size}, lr: {lr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    custom_callback = CustomCallback()\n",
    "    custom_callback.set_key(optimizer, batch_size, lr)\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False),  \n",
    "        SimpleRNN(16, return_sequences=False),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[custom_callback, early_stopping],\n",
    "        verbose=2\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "534/534 - 7s - 12ms/step - accuracy: 0.5705 - loss: 0.6765 - val_accuracy: 0.6116 - val_loss: 0.6587\n",
      "Epoch 2/100\n",
      "534/534 - 3s - 6ms/step - accuracy: 0.6012 - loss: 0.6633 - val_accuracy: 0.6670 - val_loss: 0.6203\n",
      "Epoch 3/100\n",
      "534/534 - 4s - 7ms/step - accuracy: 0.6363 - loss: 0.6449 - val_accuracy: 0.6238 - val_loss: 0.6531\n",
      "Epoch 4/100\n",
      "534/534 - 4s - 7ms/step - accuracy: 0.6617 - loss: 0.6169 - val_accuracy: 0.6670 - val_loss: 0.6074\n",
      "Epoch 5/100\n",
      "534/534 - 3s - 6ms/step - accuracy: 0.6372 - loss: 0.6423 - val_accuracy: 0.6144 - val_loss: 0.6566\n",
      "Epoch 6/100\n",
      "534/534 - 3s - 5ms/step - accuracy: 0.6363 - loss: 0.6402 - val_accuracy: 0.6811 - val_loss: 0.6138\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[139], line 4\u001b[0m\n",
      "\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.005\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]:\n",
      "\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m optimizer \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madagrad\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[1;32m----> 4\u001b[0m         train_model(optimizer, \u001b[38;5;241m100\u001b[39m, batch_size, lr)\n",
      "\n",
      "Cell \u001b[1;32mIn[137], line 26\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(optimizer, epochs, batch_size, lr)\u001b[0m\n",
      "\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdagrad(learning_rate\u001b[38;5;241m=\u001b[39mlr)\n",
      "\u001b[0;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;32m---> 26\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n",
      "\u001b[0;32m     27\u001b[0m     X_train, y_train,\n",
      "\u001b[0;32m     28\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n",
      "\u001b[0;32m     29\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n",
      "\u001b[0;32m     30\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n",
      "\u001b[0;32m     31\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[custom_callback, early_stopping],\n",
      "\u001b[0;32m     32\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;32m     33\u001b[0m )\n",
      "\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n",
      "\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n",
      "\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n",
      "\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n",
      "\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n",
      "\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n",
      "\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n",
      "\u001b[0;32m    880\u001b[0m )\n",
      "\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n",
      "\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n",
      "\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n",
      "\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n",
      "\u001b[0;32m    141\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n",
      "\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n",
      "\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n",
      "\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\u001b[0;32m   1324\u001b[0m     args,\n",
      "\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n",
      "\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n",
      "\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n",
      "\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n",
      "\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n",
      "\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n",
      "\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n",
      "\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n",
      "\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n",
      "\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n",
      "\u001b[0;32m    255\u001b[0m     )\n",
      "\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n",
      "\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n",
      "\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n",
      "\u001b[0;32m    261\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n",
      "\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n",
      "\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n",
      "\u001b[0;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n",
      "\u001b[0;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n",
      "\u001b[0;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n",
      "\u001b[0;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n",
      "\u001b[0;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[0;32m   1558\u001b[0m   )\n",
      "\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n",
      "\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n",
      "\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n",
      "\u001b[0;32m   1567\u001b[0m   )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n",
      "\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n",
      "\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_size in [16, 32, 64, 128]:\n",
    "    for lr in [0.005, 0.01, 0.05, 0.1]:\n",
    "        for optimizer in ['adam', 'sgd', 'rmsprop', 'adagrad']:\n",
    "            train_model(optimizer, 100, batch_size, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7016885280609131,\n",
       " 'epoch': 35,\n",
       " 'optimizer': 'adagrad',\n",
       " 'batch_size': 64,\n",
       " 'lr': 0.01}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best model is trained with Optimizer: adagrad, Batch_size: 64, Learning_rate: 0.01 (Final Hidden State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "134/134 - 4s - 28ms/step - accuracy: 0.5043 - loss: 0.7018 - val_accuracy: 0.5403 - val_loss: 0.6903\n",
      "Epoch 2/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.5335 - loss: 0.6892 - val_accuracy: 0.5647 - val_loss: 0.6850\n",
      "Epoch 3/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.5518 - loss: 0.6850 - val_accuracy: 0.5713 - val_loss: 0.6821\n",
      "Epoch 4/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.5612 - loss: 0.6821 - val_accuracy: 0.5713 - val_loss: 0.6798\n",
      "Epoch 5/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.5645 - loss: 0.6796 - val_accuracy: 0.5694 - val_loss: 0.6777\n",
      "Epoch 6/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.5689 - loss: 0.6772 - val_accuracy: 0.5638 - val_loss: 0.6757\n",
      "Epoch 7/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.5755 - loss: 0.6749 - val_accuracy: 0.5666 - val_loss: 0.6738\n",
      "Epoch 8/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.5817 - loss: 0.6725 - val_accuracy: 0.5713 - val_loss: 0.6718\n",
      "Epoch 9/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.5862 - loss: 0.6698 - val_accuracy: 0.5788 - val_loss: 0.6698\n",
      "Epoch 10/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.5913 - loss: 0.6670 - val_accuracy: 0.5872 - val_loss: 0.6676\n",
      "Epoch 11/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.6000 - loss: 0.6636 - val_accuracy: 0.5929 - val_loss: 0.6651\n",
      "Epoch 12/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.6082 - loss: 0.6596 - val_accuracy: 0.5947 - val_loss: 0.6620\n",
      "Epoch 13/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.6157 - loss: 0.6543 - val_accuracy: 0.6088 - val_loss: 0.6574\n",
      "Epoch 14/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.6288 - loss: 0.6468 - val_accuracy: 0.6257 - val_loss: 0.6500\n",
      "Epoch 15/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.6411 - loss: 0.6348 - val_accuracy: 0.6360 - val_loss: 0.6433\n",
      "Epoch 16/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.6615 - loss: 0.6191 - val_accuracy: 0.6473 - val_loss: 0.6300\n",
      "Epoch 17/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.6739 - loss: 0.6071 - val_accuracy: 0.6782 - val_loss: 0.6089\n",
      "Epoch 18/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.6850 - loss: 0.5978 - val_accuracy: 0.6923 - val_loss: 0.5961\n",
      "Epoch 19/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.6947 - loss: 0.5902 - val_accuracy: 0.6970 - val_loss: 0.5878\n",
      "Epoch 20/100\n",
      "134/134 - 1s - 11ms/step - accuracy: 0.7011 - loss: 0.5840 - val_accuracy: 0.6989 - val_loss: 0.5849\n",
      "Epoch 21/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.7096 - loss: 0.5759 - val_accuracy: 0.7073 - val_loss: 0.5729\n",
      "Epoch 22/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.7129 - loss: 0.5706 - val_accuracy: 0.6979 - val_loss: 0.5801\n",
      "Epoch 23/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7120 - loss: 0.5707 - val_accuracy: 0.7008 - val_loss: 0.5920\n",
      "Epoch 24/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7135 - loss: 0.5679 - val_accuracy: 0.7008 - val_loss: 0.5829\n",
      "Epoch 25/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7172 - loss: 0.5642 - val_accuracy: 0.7017 - val_loss: 0.5783\n",
      "Epoch 26/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7184 - loss: 0.5609 - val_accuracy: 0.7120 - val_loss: 0.5714\n",
      "Epoch 27/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7203 - loss: 0.5577 - val_accuracy: 0.7083 - val_loss: 0.5699\n",
      "Epoch 28/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7202 - loss: 0.5554 - val_accuracy: 0.7148 - val_loss: 0.5675\n",
      "Epoch 29/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.7213 - loss: 0.5525 - val_accuracy: 0.7176 - val_loss: 0.5652\n",
      "Epoch 30/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7232 - loss: 0.5499 - val_accuracy: 0.7167 - val_loss: 0.5629\n",
      "Epoch 31/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7243 - loss: 0.5475 - val_accuracy: 0.7186 - val_loss: 0.5606\n",
      "Epoch 32/100\n",
      "134/134 - 1s - 6ms/step - accuracy: 0.7251 - loss: 0.5453 - val_accuracy: 0.7186 - val_loss: 0.5584\n",
      "Epoch 33/100\n",
      "134/134 - 1s - 6ms/step - accuracy: 0.7277 - loss: 0.5433 - val_accuracy: 0.7186 - val_loss: 0.5564\n",
      "Epoch 34/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7299 - loss: 0.5414 - val_accuracy: 0.7167 - val_loss: 0.5547\n",
      "Epoch 35/100\n",
      "134/134 - 1s - 6ms/step - accuracy: 0.7311 - loss: 0.5397 - val_accuracy: 0.7176 - val_loss: 0.5535\n",
      "Epoch 36/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7328 - loss: 0.5382 - val_accuracy: 0.7158 - val_loss: 0.5525\n",
      "Epoch 37/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.7363 - loss: 0.5367 - val_accuracy: 0.7167 - val_loss: 0.5521\n",
      "Epoch 38/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7372 - loss: 0.5353 - val_accuracy: 0.7186 - val_loss: 0.5519\n",
      "Epoch 39/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7393 - loss: 0.5338 - val_accuracy: 0.7205 - val_loss: 0.5515\n",
      "Epoch 40/100\n",
      "134/134 - 1s - 6ms/step - accuracy: 0.7408 - loss: 0.5325 - val_accuracy: 0.7176 - val_loss: 0.5511\n",
      "Epoch 41/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7416 - loss: 0.5313 - val_accuracy: 0.7186 - val_loss: 0.5501\n",
      "Epoch 42/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7421 - loss: 0.5299 - val_accuracy: 0.7186 - val_loss: 0.5489\n",
      "Epoch 43/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7421 - loss: 0.5287 - val_accuracy: 0.7186 - val_loss: 0.5483\n",
      "Epoch 44/100\n",
      "134/134 - 1s - 7ms/step - accuracy: 0.7441 - loss: 0.5275 - val_accuracy: 0.7186 - val_loss: 0.5479\n",
      "Epoch 45/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7449 - loss: 0.5264 - val_accuracy: 0.7167 - val_loss: 0.5477\n",
      "Epoch 46/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.7472 - loss: 0.5253 - val_accuracy: 0.7148 - val_loss: 0.5483\n",
      "Epoch 47/100\n",
      "134/134 - 2s - 13ms/step - accuracy: 0.7483 - loss: 0.5242 - val_accuracy: 0.7186 - val_loss: 0.5479\n",
      "Epoch 48/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7485 - loss: 0.5230 - val_accuracy: 0.7233 - val_loss: 0.5461\n",
      "Epoch 49/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.7495 - loss: 0.5218 - val_accuracy: 0.7233 - val_loss: 0.5453\n",
      "Epoch 50/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7501 - loss: 0.5208 - val_accuracy: 0.7261 - val_loss: 0.5447\n",
      "Epoch 51/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.7511 - loss: 0.5197 - val_accuracy: 0.7233 - val_loss: 0.5441\n",
      "Epoch 52/100\n",
      "134/134 - 1s - 11ms/step - accuracy: 0.7522 - loss: 0.5187 - val_accuracy: 0.7261 - val_loss: 0.5434\n",
      "Epoch 53/100\n",
      "134/134 - 1s - 11ms/step - accuracy: 0.7528 - loss: 0.5177 - val_accuracy: 0.7261 - val_loss: 0.5427\n",
      "Epoch 54/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.7535 - loss: 0.5168 - val_accuracy: 0.7261 - val_loss: 0.5420\n",
      "Epoch 55/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.7544 - loss: 0.5158 - val_accuracy: 0.7251 - val_loss: 0.5413\n",
      "Epoch 56/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.7555 - loss: 0.5147 - val_accuracy: 0.7261 - val_loss: 0.5405\n",
      "Epoch 57/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7567 - loss: 0.5137 - val_accuracy: 0.7270 - val_loss: 0.5409\n",
      "Epoch 58/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.7576 - loss: 0.5130 - val_accuracy: 0.7261 - val_loss: 0.5420\n",
      "Epoch 59/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7577 - loss: 0.5122 - val_accuracy: 0.7280 - val_loss: 0.5402\n",
      "Epoch 60/100\n",
      "134/134 - 1s - 8ms/step - accuracy: 0.7579 - loss: 0.5113 - val_accuracy: 0.7298 - val_loss: 0.5392\n",
      "Epoch 61/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7579 - loss: 0.5104 - val_accuracy: 0.7336 - val_loss: 0.5386\n",
      "Epoch 62/100\n",
      "134/134 - 2s - 12ms/step - accuracy: 0.7585 - loss: 0.5095 - val_accuracy: 0.7383 - val_loss: 0.5380\n",
      "Epoch 63/100\n",
      "134/134 - 2s - 12ms/step - accuracy: 0.7585 - loss: 0.5087 - val_accuracy: 0.7373 - val_loss: 0.5375\n",
      "Epoch 64/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.7591 - loss: 0.5079 - val_accuracy: 0.7364 - val_loss: 0.5371\n",
      "Epoch 65/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.7597 - loss: 0.5071 - val_accuracy: 0.7373 - val_loss: 0.5368\n",
      "Epoch 66/100\n",
      "134/134 - 2s - 11ms/step - accuracy: 0.7613 - loss: 0.5063 - val_accuracy: 0.7364 - val_loss: 0.5365\n",
      "Epoch 67/100\n",
      "134/134 - 2s - 11ms/step - accuracy: 0.7613 - loss: 0.5055 - val_accuracy: 0.7364 - val_loss: 0.5363\n",
      "Epoch 68/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7614 - loss: 0.5047 - val_accuracy: 0.7383 - val_loss: 0.5362\n",
      "Epoch 69/100\n",
      "134/134 - 2s - 13ms/step - accuracy: 0.7613 - loss: 0.5039 - val_accuracy: 0.7383 - val_loss: 0.5362\n",
      "Epoch 70/100\n",
      "134/134 - 2s - 17ms/step - accuracy: 0.7625 - loss: 0.5032 - val_accuracy: 0.7392 - val_loss: 0.5361\n",
      "Epoch 71/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.7628 - loss: 0.5025 - val_accuracy: 0.7364 - val_loss: 0.5361\n",
      "Epoch 72/100\n",
      "134/134 - 2s - 12ms/step - accuracy: 0.7632 - loss: 0.5017 - val_accuracy: 0.7364 - val_loss: 0.5360\n",
      "Epoch 73/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7640 - loss: 0.5010 - val_accuracy: 0.7364 - val_loss: 0.5359\n",
      "Epoch 74/100\n",
      "134/134 - 1s - 9ms/step - accuracy: 0.7640 - loss: 0.5003 - val_accuracy: 0.7345 - val_loss: 0.5358\n",
      "Epoch 75/100\n",
      "134/134 - 2s - 12ms/step - accuracy: 0.7633 - loss: 0.4995 - val_accuracy: 0.7317 - val_loss: 0.5358\n",
      "Epoch 76/100\n",
      "134/134 - 2s - 13ms/step - accuracy: 0.7639 - loss: 0.4988 - val_accuracy: 0.7317 - val_loss: 0.5358\n",
      "Epoch 77/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.7644 - loss: 0.4981 - val_accuracy: 0.7336 - val_loss: 0.5358\n",
      "Epoch 78/100\n",
      "134/134 - 2s - 12ms/step - accuracy: 0.7651 - loss: 0.4974 - val_accuracy: 0.7336 - val_loss: 0.5359\n",
      "Epoch 79/100\n",
      "134/134 - 2s - 12ms/step - accuracy: 0.7657 - loss: 0.4968 - val_accuracy: 0.7345 - val_loss: 0.5359\n",
      "Epoch 80/100\n",
      "134/134 - 1s - 10ms/step - accuracy: 0.7658 - loss: 0.4962 - val_accuracy: 0.7345 - val_loss: 0.5361\n",
      "Run completed on:\n",
      "optimizer: adagrad, batch_size: 64, lr: 0.01\n",
      "Best accuracy for current run: 0.7392120361328125 at epoch 69\n",
      "Training ended\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(best_accuracy['optimizer'], 100, best_accuracy['batch_size'], best_accuracy['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7187 - loss: 0.5703\n",
      "Test accuracy: 73.92%\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_mean.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False),\n",
    "        SimpleRNN(16, return_sequences=True),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4687 - loss: 0.6984\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48593, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4689 - loss: 0.6984 - val_accuracy: 0.4859 - val_loss: 0.6943\n",
      "Epoch 2/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4869 - loss: 0.6949\n",
      "Epoch 2: val_accuracy improved from 0.48593 to 0.49719, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4869 - loss: 0.6949 - val_accuracy: 0.4972 - val_loss: 0.6931\n",
      "Epoch 3/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5029 - loss: 0.6935\n",
      "Epoch 3: val_accuracy improved from 0.49719 to 0.51595, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.5029 - loss: 0.6935 - val_accuracy: 0.5159 - val_loss: 0.6922\n",
      "Epoch 4/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5184 - loss: 0.6924\n",
      "Epoch 4: val_accuracy improved from 0.51595 to 0.53189, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5185 - loss: 0.6924 - val_accuracy: 0.5319 - val_loss: 0.6912\n",
      "Epoch 5/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5278 - loss: 0.6914\n",
      "Epoch 5: val_accuracy improved from 0.53189 to 0.54784, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5284 - loss: 0.6914 - val_accuracy: 0.5478 - val_loss: 0.6904\n",
      "Epoch 6/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5430 - loss: 0.6904\n",
      "Epoch 6: val_accuracy improved from 0.54784 to 0.56004, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5431 - loss: 0.6904 - val_accuracy: 0.5600 - val_loss: 0.6895\n",
      "Epoch 7/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5587 - loss: 0.6894\n",
      "Epoch 7: val_accuracy improved from 0.56004 to 0.56848, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5588 - loss: 0.6894 - val_accuracy: 0.5685 - val_loss: 0.6885\n",
      "Epoch 8/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5712 - loss: 0.6884\n",
      "Epoch 8: val_accuracy improved from 0.56848 to 0.57317, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5714 - loss: 0.6884 - val_accuracy: 0.5732 - val_loss: 0.6875\n",
      "Epoch 9/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5824 - loss: 0.6873\n",
      "Epoch 9: val_accuracy improved from 0.57317 to 0.58068, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5825 - loss: 0.6873 - val_accuracy: 0.5807 - val_loss: 0.6864\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5914 - loss: 0.6860\n",
      "Epoch 10: val_accuracy improved from 0.58068 to 0.59568, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.5914 - loss: 0.6860 - val_accuracy: 0.5957 - val_loss: 0.6852\n",
      "Epoch 11/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6007 - loss: 0.6847\n",
      "Epoch 11: val_accuracy improved from 0.59568 to 0.60319, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6009 - loss: 0.6847 - val_accuracy: 0.6032 - val_loss: 0.6839\n",
      "Epoch 12/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6064 - loss: 0.6831\n",
      "Epoch 12: val_accuracy improved from 0.60319 to 0.61163, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6065 - loss: 0.6831 - val_accuracy: 0.6116 - val_loss: 0.6823\n",
      "Epoch 13/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6164 - loss: 0.6814\n",
      "Epoch 13: val_accuracy did not improve from 0.61163\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6165 - loss: 0.6813 - val_accuracy: 0.6107 - val_loss: 0.6805\n",
      "Epoch 14/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6201 - loss: 0.6792\n",
      "Epoch 14: val_accuracy improved from 0.61163 to 0.62852, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6202 - loss: 0.6792 - val_accuracy: 0.6285 - val_loss: 0.6784\n",
      "Epoch 15/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6313 - loss: 0.6767\n",
      "Epoch 15: val_accuracy improved from 0.62852 to 0.63415, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6314 - loss: 0.6767 - val_accuracy: 0.6341 - val_loss: 0.6758\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6376 - loss: 0.6735\n",
      "Epoch 16: val_accuracy improved from 0.63415 to 0.63696, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6376 - loss: 0.6735 - val_accuracy: 0.6370 - val_loss: 0.6727\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6439 - loss: 0.6696\n",
      "Epoch 17: val_accuracy improved from 0.63696 to 0.63977, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6439 - loss: 0.6696 - val_accuracy: 0.6398 - val_loss: 0.6691\n",
      "Epoch 18/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6497 - loss: 0.6653\n",
      "Epoch 18: val_accuracy improved from 0.63977 to 0.65291, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6496 - loss: 0.6653 - val_accuracy: 0.6529 - val_loss: 0.6652\n",
      "Epoch 19/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6482 - loss: 0.6611\n",
      "Epoch 19: val_accuracy did not improve from 0.65291\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6483 - loss: 0.6610 - val_accuracy: 0.6454 - val_loss: 0.6612\n",
      "Epoch 20/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6465 - loss: 0.6567\n",
      "Epoch 20: val_accuracy did not improve from 0.65291\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6468 - loss: 0.6567 - val_accuracy: 0.6370 - val_loss: 0.6574\n",
      "Epoch 21/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6515 - loss: 0.6523\n",
      "Epoch 21: val_accuracy did not improve from 0.65291\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6517 - loss: 0.6523 - val_accuracy: 0.6398 - val_loss: 0.6537\n",
      "Epoch 22/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6547 - loss: 0.6480\n",
      "Epoch 22: val_accuracy did not improve from 0.65291\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6549 - loss: 0.6480 - val_accuracy: 0.6210 - val_loss: 0.6542\n",
      "Epoch 23/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6538 - loss: 0.6473\n",
      "Epoch 23: val_accuracy did not improve from 0.65291\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6541 - loss: 0.6473 - val_accuracy: 0.6501 - val_loss: 0.6493\n",
      "Epoch 24/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6634 - loss: 0.6419\n",
      "Epoch 24: val_accuracy improved from 0.65291 to 0.65854, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6634 - loss: 0.6419 - val_accuracy: 0.6585 - val_loss: 0.6462\n",
      "Epoch 25/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6671 - loss: 0.6383\n",
      "Epoch 25: val_accuracy improved from 0.65854 to 0.65947, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6671 - loss: 0.6383 - val_accuracy: 0.6595 - val_loss: 0.6434\n",
      "Epoch 26/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6667 - loss: 0.6357\n",
      "Epoch 26: val_accuracy improved from 0.65947 to 0.66510, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6668 - loss: 0.6357 - val_accuracy: 0.6651 - val_loss: 0.6406\n",
      "Epoch 27/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6717 - loss: 0.6330\n",
      "Epoch 27: val_accuracy improved from 0.66510 to 0.67917, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6717 - loss: 0.6330 - val_accuracy: 0.6792 - val_loss: 0.6361\n",
      "Epoch 28/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6793 - loss: 0.6281\n",
      "Epoch 28: val_accuracy did not improve from 0.67917\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6793 - loss: 0.6281 - val_accuracy: 0.6735 - val_loss: 0.6331\n",
      "Epoch 29/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6758 - loss: 0.6259\n",
      "Epoch 29: val_accuracy improved from 0.67917 to 0.68105, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6759 - loss: 0.6259 - val_accuracy: 0.6811 - val_loss: 0.6303\n",
      "Epoch 30/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6862 - loss: 0.6236\n",
      "Epoch 30: val_accuracy did not improve from 0.68105\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6863 - loss: 0.6236 - val_accuracy: 0.6811 - val_loss: 0.6271\n",
      "Epoch 31/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6877 - loss: 0.6188\n",
      "Epoch 31: val_accuracy did not improve from 0.68105\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6877 - loss: 0.6188 - val_accuracy: 0.6811 - val_loss: 0.6256\n",
      "Epoch 32/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6850 - loss: 0.6166\n",
      "Epoch 32: val_accuracy did not improve from 0.68105\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6850 - loss: 0.6166 - val_accuracy: 0.6782 - val_loss: 0.6235\n",
      "Epoch 33/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6922 - loss: 0.6145\n",
      "Epoch 33: val_accuracy did not improve from 0.68105\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6922 - loss: 0.6145 - val_accuracy: 0.6811 - val_loss: 0.6201\n",
      "Epoch 34/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6933 - loss: 0.6114\n",
      "Epoch 34: val_accuracy did not improve from 0.68105\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6934 - loss: 0.6114 - val_accuracy: 0.6792 - val_loss: 0.6186\n",
      "Epoch 35/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6959 - loss: 0.6091\n",
      "Epoch 35: val_accuracy did not improve from 0.68105\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6959 - loss: 0.6091 - val_accuracy: 0.6801 - val_loss: 0.6163\n",
      "Epoch 36/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6963 - loss: 0.6074\n",
      "Epoch 36: val_accuracy did not improve from 0.68105\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6963 - loss: 0.6074 - val_accuracy: 0.6811 - val_loss: 0.6146\n",
      "Epoch 37/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6985 - loss: 0.6053\n",
      "Epoch 37: val_accuracy improved from 0.68105 to 0.68574, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.6986 - loss: 0.6053 - val_accuracy: 0.6857 - val_loss: 0.6124\n",
      "Epoch 38/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7026 - loss: 0.6023\n",
      "Epoch 38: val_accuracy improved from 0.68574 to 0.69043, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7026 - loss: 0.6023 - val_accuracy: 0.6904 - val_loss: 0.6104\n",
      "Epoch 39/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7031 - loss: 0.5999\n",
      "Epoch 39: val_accuracy did not improve from 0.69043\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7031 - loss: 0.6000 - val_accuracy: 0.6839 - val_loss: 0.6086\n",
      "Epoch 40/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7047 - loss: 0.5989\n",
      "Epoch 40: val_accuracy did not improve from 0.69043\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7047 - loss: 0.5989 - val_accuracy: 0.6857 - val_loss: 0.6071\n",
      "Epoch 41/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7075 - loss: 0.5965\n",
      "Epoch 41: val_accuracy improved from 0.69043 to 0.69137, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7074 - loss: 0.5966 - val_accuracy: 0.6914 - val_loss: 0.6058\n",
      "Epoch 42/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7066 - loss: 0.5943\n",
      "Epoch 42: val_accuracy did not improve from 0.69137\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7066 - loss: 0.5944 - val_accuracy: 0.6914 - val_loss: 0.6041\n",
      "Epoch 43/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7104 - loss: 0.5929\n",
      "Epoch 43: val_accuracy improved from 0.69137 to 0.69231, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7103 - loss: 0.5930 - val_accuracy: 0.6923 - val_loss: 0.6024\n",
      "Epoch 44/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6967 - loss: 0.5975\n",
      "Epoch 44: val_accuracy did not improve from 0.69231\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6966 - loss: 0.5975 - val_accuracy: 0.6717 - val_loss: 0.6076\n",
      "Epoch 45/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6986 - loss: 0.5954\n",
      "Epoch 45: val_accuracy did not improve from 0.69231\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6986 - loss: 0.5954 - val_accuracy: 0.6839 - val_loss: 0.6043\n",
      "Epoch 46/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7108 - loss: 0.5924\n",
      "Epoch 46: val_accuracy did not improve from 0.69231\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7108 - loss: 0.5925 - val_accuracy: 0.6904 - val_loss: 0.6004\n",
      "Epoch 47/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7172 - loss: 0.5887\n",
      "Epoch 47: val_accuracy did not improve from 0.69231\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7170 - loss: 0.5888 - val_accuracy: 0.6923 - val_loss: 0.5975\n",
      "Epoch 48/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7174 - loss: 0.5856\n",
      "Epoch 48: val_accuracy improved from 0.69231 to 0.69794, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7172 - loss: 0.5857 - val_accuracy: 0.6979 - val_loss: 0.5961\n",
      "Epoch 49/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7166 - loss: 0.5839\n",
      "Epoch 49: val_accuracy improved from 0.69794 to 0.70075, saving model to model_mean.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7165 - loss: 0.5840 - val_accuracy: 0.7008 - val_loss: 0.5948\n",
      "Epoch 50/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7170 - loss: 0.5824\n",
      "Epoch 50: val_accuracy did not improve from 0.70075\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7169 - loss: 0.5825 - val_accuracy: 0.6989 - val_loss: 0.5936\n",
      "Epoch 51/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7190 - loss: 0.5810\n",
      "Epoch 51: val_accuracy did not improve from 0.70075\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7189 - loss: 0.5810 - val_accuracy: 0.6979 - val_loss: 0.5924\n",
      "Epoch 52/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7207 - loss: 0.5795\n",
      "Epoch 52: val_accuracy did not improve from 0.70075\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7204 - loss: 0.5796 - val_accuracy: 0.6998 - val_loss: 0.5914\n",
      "Epoch 53/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7200 - loss: 0.5781\n",
      "Epoch 53: val_accuracy did not improve from 0.70075\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7198 - loss: 0.5783 - val_accuracy: 0.6989 - val_loss: 0.5904\n",
      "Epoch 54/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7203 - loss: 0.5770\n",
      "Epoch 54: val_accuracy did not improve from 0.70075\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7203 - loss: 0.5770 - val_accuracy: 0.6979 - val_loss: 0.5895\n",
      "Epoch 55/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7213 - loss: 0.5756\n",
      "Epoch 55: val_accuracy did not improve from 0.70075\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7212 - loss: 0.5757 - val_accuracy: 0.6989 - val_loss: 0.5886\n",
      "Epoch 56/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7229 - loss: 0.5744\n",
      "Epoch 56: val_accuracy did not improve from 0.70075\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7228 - loss: 0.5745 - val_accuracy: 0.6998 - val_loss: 0.5877\n",
      "Epoch 57/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7237 - loss: 0.5733\n",
      "Epoch 57: val_accuracy did not improve from 0.70075\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7237 - loss: 0.5734 - val_accuracy: 0.6989 - val_loss: 0.5869\n",
      "Epoch 58/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7252 - loss: 0.5721\n",
      "Epoch 58: val_accuracy did not improve from 0.70075\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7249 - loss: 0.5723 - val_accuracy: 0.6998 - val_loss: 0.5861\n",
      "Epoch 59/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7262 - loss: 0.5710\n",
      "Epoch 59: val_accuracy did not improve from 0.70075\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7260 - loss: 0.5712 - val_accuracy: 0.7008 - val_loss: 0.5853\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6493 - loss: 0.6289\n",
      "Test accuracy: 71.20%\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_mean.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_max.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False), \n",
    "        SimpleRNN(16, return_sequences=True),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5012 - loss: 0.7078\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53189, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5016 - loss: 0.7073 - val_accuracy: 0.5319 - val_loss: 0.6873\n",
      "Epoch 2/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5218 - loss: 0.6920\n",
      "Epoch 2: val_accuracy improved from 0.53189 to 0.55347, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5222 - loss: 0.6919 - val_accuracy: 0.5535 - val_loss: 0.6841\n",
      "Epoch 3/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5456 - loss: 0.6887\n",
      "Epoch 3: val_accuracy improved from 0.55347 to 0.56754, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.5457 - loss: 0.6887 - val_accuracy: 0.5675 - val_loss: 0.6809\n",
      "Epoch 4/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5539 - loss: 0.6849\n",
      "Epoch 4: val_accuracy improved from 0.56754 to 0.58630, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5540 - loss: 0.6849 - val_accuracy: 0.5863 - val_loss: 0.6772\n",
      "Epoch 5/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5696 - loss: 0.6798\n",
      "Epoch 5: val_accuracy improved from 0.58630 to 0.59381, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5697 - loss: 0.6798 - val_accuracy: 0.5938 - val_loss: 0.6732\n",
      "Epoch 6/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5923 - loss: 0.6732\n",
      "Epoch 6: val_accuracy improved from 0.59381 to 0.60413, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5925 - loss: 0.6731 - val_accuracy: 0.6041 - val_loss: 0.6679\n",
      "Epoch 7/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6122 - loss: 0.6657\n",
      "Epoch 7: val_accuracy improved from 0.60413 to 0.62289, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6126 - loss: 0.6656 - val_accuracy: 0.6229 - val_loss: 0.6611\n",
      "Epoch 8/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6257 - loss: 0.6572\n",
      "Epoch 8: val_accuracy improved from 0.62289 to 0.63039, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6259 - loss: 0.6571 - val_accuracy: 0.6304 - val_loss: 0.6533\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6392 - loss: 0.6485\n",
      "Epoch 9: val_accuracy improved from 0.63039 to 0.64353, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6393 - loss: 0.6485 - val_accuracy: 0.6435 - val_loss: 0.6452\n",
      "Epoch 10/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6572 - loss: 0.6397\n",
      "Epoch 10: val_accuracy improved from 0.64353 to 0.65291, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6574 - loss: 0.6395 - val_accuracy: 0.6529 - val_loss: 0.6372\n",
      "Epoch 11/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6706 - loss: 0.6303\n",
      "Epoch 11: val_accuracy improved from 0.65291 to 0.65947, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6708 - loss: 0.6301 - val_accuracy: 0.6595 - val_loss: 0.6294\n",
      "Epoch 12/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6818 - loss: 0.6204\n",
      "Epoch 12: val_accuracy did not improve from 0.65947\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6818 - loss: 0.6204 - val_accuracy: 0.6595 - val_loss: 0.6216\n",
      "Epoch 13/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6930 - loss: 0.6111\n",
      "Epoch 13: val_accuracy improved from 0.65947 to 0.67355, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6930 - loss: 0.6110 - val_accuracy: 0.6735 - val_loss: 0.6134\n",
      "Epoch 14/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7045 - loss: 0.6020\n",
      "Epoch 14: val_accuracy improved from 0.67355 to 0.67730, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7044 - loss: 0.6018 - val_accuracy: 0.6773 - val_loss: 0.6049\n",
      "Epoch 15/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7113 - loss: 0.5933\n",
      "Epoch 15: val_accuracy improved from 0.67730 to 0.68949, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7113 - loss: 0.5932 - val_accuracy: 0.6895 - val_loss: 0.5972\n",
      "Epoch 16/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7143 - loss: 0.5854\n",
      "Epoch 16: val_accuracy improved from 0.68949 to 0.70075, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7142 - loss: 0.5853 - val_accuracy: 0.7008 - val_loss: 0.5895\n",
      "Epoch 17/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7169 - loss: 0.5779\n",
      "Epoch 17: val_accuracy improved from 0.70075 to 0.70544, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7169 - loss: 0.5778 - val_accuracy: 0.7054 - val_loss: 0.5828\n",
      "Epoch 18/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 0.5708\n",
      "Epoch 18: val_accuracy improved from 0.70544 to 0.71576, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7187 - loss: 0.5707 - val_accuracy: 0.7158 - val_loss: 0.5767\n",
      "Epoch 19/100\n",
      "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7228 - loss: 0.5646\n",
      "Epoch 19: val_accuracy improved from 0.71576 to 0.71764, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7228 - loss: 0.5644 - val_accuracy: 0.7176 - val_loss: 0.5712\n",
      "Epoch 20/100\n",
      "\u001b[1m127/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7218 - loss: 0.5589\n",
      "Epoch 20: val_accuracy improved from 0.71764 to 0.72326, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7220 - loss: 0.5587 - val_accuracy: 0.7233 - val_loss: 0.5658\n",
      "Epoch 21/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7260 - loss: 0.5532\n",
      "Epoch 21: val_accuracy improved from 0.72326 to 0.72702, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7260 - loss: 0.5532 - val_accuracy: 0.7270 - val_loss: 0.5611\n",
      "Epoch 22/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7274 - loss: 0.5482\n",
      "Epoch 22: val_accuracy did not improve from 0.72702\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7275 - loss: 0.5481 - val_accuracy: 0.7251 - val_loss: 0.5566\n",
      "Epoch 23/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7301 - loss: 0.5434\n",
      "Epoch 23: val_accuracy did not improve from 0.72702\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7302 - loss: 0.5434 - val_accuracy: 0.7251 - val_loss: 0.5527\n",
      "Epoch 24/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7318 - loss: 0.5391\n",
      "Epoch 24: val_accuracy improved from 0.72702 to 0.73171, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7319 - loss: 0.5390 - val_accuracy: 0.7317 - val_loss: 0.5495\n",
      "Epoch 25/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7319 - loss: 0.5351\n",
      "Epoch 25: val_accuracy did not improve from 0.73171\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7319 - loss: 0.5350 - val_accuracy: 0.7289 - val_loss: 0.5457\n",
      "Epoch 26/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7299 - loss: 0.5370\n",
      "Epoch 26: val_accuracy did not improve from 0.73171\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7300 - loss: 0.5370 - val_accuracy: 0.7242 - val_loss: 0.5468\n",
      "Epoch 27/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7368 - loss: 0.5297\n",
      "Epoch 27: val_accuracy did not improve from 0.73171\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7368 - loss: 0.5296 - val_accuracy: 0.7308 - val_loss: 0.5436\n",
      "Epoch 28/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7397 - loss: 0.5263\n",
      "Epoch 28: val_accuracy improved from 0.73171 to 0.73640, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7397 - loss: 0.5263 - val_accuracy: 0.7364 - val_loss: 0.5415\n",
      "Epoch 29/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7449 - loss: 0.5235\n",
      "Epoch 29: val_accuracy did not improve from 0.73640\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7449 - loss: 0.5235 - val_accuracy: 0.7364 - val_loss: 0.5397\n",
      "Epoch 30/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7461 - loss: 0.5208\n",
      "Epoch 30: val_accuracy improved from 0.73640 to 0.73827, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7461 - loss: 0.5208 - val_accuracy: 0.7383 - val_loss: 0.5379\n",
      "Epoch 31/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7476 - loss: 0.5182\n",
      "Epoch 31: val_accuracy improved from 0.73827 to 0.74296, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7476 - loss: 0.5182 - val_accuracy: 0.7430 - val_loss: 0.5364\n",
      "Epoch 32/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7487 - loss: 0.5159\n",
      "Epoch 32: val_accuracy improved from 0.74296 to 0.74484, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7487 - loss: 0.5159 - val_accuracy: 0.7448 - val_loss: 0.5350\n",
      "Epoch 33/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7501 - loss: 0.5138\n",
      "Epoch 33: val_accuracy improved from 0.74484 to 0.74672, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7501 - loss: 0.5138 - val_accuracy: 0.7467 - val_loss: 0.5334\n",
      "Epoch 34/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7507 - loss: 0.5117\n",
      "Epoch 34: val_accuracy did not improve from 0.74672\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7507 - loss: 0.5117 - val_accuracy: 0.7448 - val_loss: 0.5320\n",
      "Epoch 35/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7518 - loss: 0.5096\n",
      "Epoch 35: val_accuracy did not improve from 0.74672\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7518 - loss: 0.5096 - val_accuracy: 0.7467 - val_loss: 0.5308\n",
      "Epoch 36/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7527 - loss: 0.5085\n",
      "Epoch 36: val_accuracy did not improve from 0.74672\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7522 - loss: 0.5089 - val_accuracy: 0.7308 - val_loss: 0.5446\n",
      "Epoch 37/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7473 - loss: 0.5135\n",
      "Epoch 37: val_accuracy did not improve from 0.74672\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7473 - loss: 0.5134 - val_accuracy: 0.7439 - val_loss: 0.5286\n",
      "Epoch 38/100\n",
      "\u001b[1m130/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7558 - loss: 0.5060\n",
      "Epoch 38: val_accuracy improved from 0.74672 to 0.75047, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7558 - loss: 0.5059 - val_accuracy: 0.7505 - val_loss: 0.5276\n",
      "Epoch 39/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7598 - loss: 0.5039\n",
      "Epoch 39: val_accuracy improved from 0.75047 to 0.75328, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7598 - loss: 0.5038 - val_accuracy: 0.7533 - val_loss: 0.5267\n",
      "Epoch 40/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7616 - loss: 0.5022\n",
      "Epoch 40: val_accuracy did not improve from 0.75328\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7615 - loss: 0.5022 - val_accuracy: 0.7533 - val_loss: 0.5261\n",
      "Epoch 41/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7620 - loss: 0.5007\n",
      "Epoch 41: val_accuracy improved from 0.75328 to 0.75516, saving model to model_max.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7620 - loss: 0.5007 - val_accuracy: 0.7552 - val_loss: 0.5253\n",
      "Epoch 42/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7630 - loss: 0.4993\n",
      "Epoch 42: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7630 - loss: 0.4993 - val_accuracy: 0.7542 - val_loss: 0.5248\n",
      "Epoch 43/100\n",
      "\u001b[1m128/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7637 - loss: 0.4979\n",
      "Epoch 43: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7637 - loss: 0.4979 - val_accuracy: 0.7533 - val_loss: 0.5243\n",
      "Epoch 44/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7655 - loss: 0.4966\n",
      "Epoch 44: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7655 - loss: 0.4966 - val_accuracy: 0.7523 - val_loss: 0.5236\n",
      "Epoch 45/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7664 - loss: 0.4953\n",
      "Epoch 45: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7664 - loss: 0.4953 - val_accuracy: 0.7495 - val_loss: 0.5230\n",
      "Epoch 46/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7674 - loss: 0.4941\n",
      "Epoch 46: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7674 - loss: 0.4941 - val_accuracy: 0.7495 - val_loss: 0.5223\n",
      "Epoch 47/100\n",
      "\u001b[1m133/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7676 - loss: 0.4929\n",
      "Epoch 47: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7676 - loss: 0.4929 - val_accuracy: 0.7505 - val_loss: 0.5217\n",
      "Epoch 48/100\n",
      "\u001b[1m129/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7682 - loss: 0.4918\n",
      "Epoch 48: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7681 - loss: 0.4917 - val_accuracy: 0.7495 - val_loss: 0.5211\n",
      "Epoch 49/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7681 - loss: 0.4906\n",
      "Epoch 49: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7680 - loss: 0.4906 - val_accuracy: 0.7514 - val_loss: 0.5206\n",
      "Epoch 50/100\n",
      "\u001b[1m132/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7682 - loss: 0.4895\n",
      "Epoch 50: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7681 - loss: 0.4895 - val_accuracy: 0.7514 - val_loss: 0.5203\n",
      "Epoch 51/100\n",
      "\u001b[1m131/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7674 - loss: 0.4885\n",
      "Epoch 51: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7674 - loss: 0.4885 - val_accuracy: 0.7505 - val_loss: 0.5198\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7259 - loss: 0.5401\n",
      "Test accuracy: 0.7354596853256226\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_max.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_dense.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False),\n",
    "        SimpleRNN(16, return_sequences=True),\n",
    "        Flatten(),\n",
    "        Dense(62, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.5358 - loss: 0.6983\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58349, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 180ms/step - accuracy: 0.5360 - loss: 0.6983 - val_accuracy: 0.5835 - val_loss: 0.6724\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.6117 - loss: 0.6588\n",
      "Epoch 2: val_accuracy improved from 0.58349 to 0.65009, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 208ms/step - accuracy: 0.6118 - loss: 0.6587 - val_accuracy: 0.6501 - val_loss: 0.6379\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6471 - loss: 0.6261\n",
      "Epoch 3: val_accuracy improved from 0.65009 to 0.66886, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.6472 - loss: 0.6261 - val_accuracy: 0.6689 - val_loss: 0.6154\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.6783 - loss: 0.6012\n",
      "Epoch 4: val_accuracy improved from 0.66886 to 0.68105, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.6784 - loss: 0.6012 - val_accuracy: 0.6811 - val_loss: 0.6013\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6932 - loss: 0.5815\n",
      "Epoch 5: val_accuracy did not improve from 0.68105\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 141ms/step - accuracy: 0.6932 - loss: 0.5815 - val_accuracy: 0.6679 - val_loss: 0.6042\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7085 - loss: 0.5701\n",
      "Epoch 6: val_accuracy improved from 0.68105 to 0.70169, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 146ms/step - accuracy: 0.7085 - loss: 0.5701 - val_accuracy: 0.7017 - val_loss: 0.5795\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7123 - loss: 0.5531\n",
      "Epoch 7: val_accuracy improved from 0.70169 to 0.70356, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.7123 - loss: 0.5531 - val_accuracy: 0.7036 - val_loss: 0.5668\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7223 - loss: 0.5431\n",
      "Epoch 8: val_accuracy improved from 0.70356 to 0.70919, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.7223 - loss: 0.5431 - val_accuracy: 0.7092 - val_loss: 0.5741\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7300 - loss: 0.5374\n",
      "Epoch 9: val_accuracy did not improve from 0.70919\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 159ms/step - accuracy: 0.7301 - loss: 0.5374 - val_accuracy: 0.7092 - val_loss: 0.5589\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7358 - loss: 0.5226\n",
      "Epoch 10: val_accuracy did not improve from 0.70919\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 148ms/step - accuracy: 0.7358 - loss: 0.5226 - val_accuracy: 0.7092 - val_loss: 0.5577\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7415 - loss: 0.5143\n",
      "Epoch 11: val_accuracy did not improve from 0.70919\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 159ms/step - accuracy: 0.7415 - loss: 0.5143 - val_accuracy: 0.6942 - val_loss: 0.5795\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7323 - loss: 0.5266\n",
      "Epoch 12: val_accuracy improved from 0.70919 to 0.71201, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 146ms/step - accuracy: 0.7323 - loss: 0.5265 - val_accuracy: 0.7120 - val_loss: 0.5521\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7517 - loss: 0.5015\n",
      "Epoch 13: val_accuracy improved from 0.71201 to 0.71388, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 166ms/step - accuracy: 0.7517 - loss: 0.5015 - val_accuracy: 0.7139 - val_loss: 0.5438\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7579 - loss: 0.4936\n",
      "Epoch 14: val_accuracy did not improve from 0.71388\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 159ms/step - accuracy: 0.7579 - loss: 0.4936 - val_accuracy: 0.7092 - val_loss: 0.5431\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7597 - loss: 0.4865\n",
      "Epoch 15: val_accuracy did not improve from 0.71388\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 160ms/step - accuracy: 0.7597 - loss: 0.4865 - val_accuracy: 0.7017 - val_loss: 0.5527\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7576 - loss: 0.4870\n",
      "Epoch 16: val_accuracy did not improve from 0.71388\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 154ms/step - accuracy: 0.7577 - loss: 0.4870 - val_accuracy: 0.7120 - val_loss: 0.5484\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7725 - loss: 0.4772\n",
      "Epoch 17: val_accuracy improved from 0.71388 to 0.71670, saving model to model_dense.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 160ms/step - accuracy: 0.7724 - loss: 0.4772 - val_accuracy: 0.7167 - val_loss: 0.5436\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.5282\n",
      "Test accuracy: 0.7373358607292175\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_dense.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy[1] * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
