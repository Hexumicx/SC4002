{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0. Data Prepraration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JJWX\\anaconda3\\envs\\NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset ['train']\n",
    "validation_dataset = dataset ['validation']\n",
    "test_dataset = dataset ['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Enhancement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-100\")\n",
    "vocab_size = len(model.index_to_key) + 1\n",
    "embedding_dim = model.vector_size\n",
    "word_index = {word: index+1 for index, word in enumerate(model.index_to_key)} # index 0 is reserved for padding\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "vocab_size = len(model.index_to_key) + 1\n",
    "embedding_dim = model.vector_size\n",
    "word_index = {word: index+1 for index, word in enumerate(model.index_to_key)} # index 0 is reserved for padding\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, idx in word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[idx] = model[word]\n",
    "\n",
    "def tokenize(text, word_index):\n",
    "    ls = nltk.word_tokenize(text)\n",
    "    return [word_index[word] for word in ls if word in word_index]\n",
    "\n",
    "X_train = [tokenize(text, word_index) for text in train_dataset['text']]\n",
    "X_val = [tokenize(text, word_index) for text in validation_dataset['text']]\n",
    "X_test = [tokenize(text, word_index) for text in test_dataset['text']]\n",
    "max_length = max(len(seq) for seq in X_train)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='pre', truncating='pre')\n",
    "X_val = pad_sequences(X_val, maxlen=max_length, padding='pre', truncating='pre')\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='pre', truncating='pre')\n",
    "\n",
    "y_train = np.array(train_dataset['label'])\n",
    "y_val = np.array(validation_dataset['label'])\n",
    "y_test = np.array(test_dataset['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Instead of keeping the word embeddings fixed, now update the word embeddings (the same way as model parameters) during the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.4895 - loss: 0.7142\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53189, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 165ms/step - accuracy: 0.4896 - loss: 0.7141 - val_accuracy: 0.5319 - val_loss: 0.6920\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5222 - loss: 0.6915\n",
      "Epoch 2: val_accuracy improved from 0.53189 to 0.55629, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 159ms/step - accuracy: 0.5222 - loss: 0.6914 - val_accuracy: 0.5563 - val_loss: 0.6864\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5522 - loss: 0.6864\n",
      "Epoch 3: val_accuracy did not improve from 0.55629\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.5522 - loss: 0.6864 - val_accuracy: 0.5553 - val_loss: 0.6833\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.5603 - loss: 0.6831\n",
      "Epoch 4: val_accuracy improved from 0.55629 to 0.56004, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 163ms/step - accuracy: 0.5603 - loss: 0.6831 - val_accuracy: 0.5600 - val_loss: 0.6810\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.5642 - loss: 0.6804\n",
      "Epoch 5: val_accuracy did not improve from 0.56004\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 155ms/step - accuracy: 0.5642 - loss: 0.6804 - val_accuracy: 0.5600 - val_loss: 0.6788\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.5703 - loss: 0.6779\n",
      "Epoch 6: val_accuracy improved from 0.56004 to 0.56473, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 158ms/step - accuracy: 0.5703 - loss: 0.6779 - val_accuracy: 0.5647 - val_loss: 0.6768\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5727 - loss: 0.6754\n",
      "Epoch 7: val_accuracy improved from 0.56473 to 0.56848, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 207ms/step - accuracy: 0.5727 - loss: 0.6754 - val_accuracy: 0.5685 - val_loss: 0.6747\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.5771 - loss: 0.6728\n",
      "Epoch 8: val_accuracy improved from 0.56848 to 0.57599, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 160ms/step - accuracy: 0.5771 - loss: 0.6728 - val_accuracy: 0.5760 - val_loss: 0.6726\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5836 - loss: 0.6700\n",
      "Epoch 9: val_accuracy improved from 0.57599 to 0.58724, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 161ms/step - accuracy: 0.5837 - loss: 0.6700 - val_accuracy: 0.5872 - val_loss: 0.6703\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5913 - loss: 0.6670\n",
      "Epoch 10: val_accuracy improved from 0.58724 to 0.58912, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 162ms/step - accuracy: 0.5913 - loss: 0.6670 - val_accuracy: 0.5891 - val_loss: 0.6678\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.6026 - loss: 0.6635\n",
      "Epoch 11: val_accuracy improved from 0.58912 to 0.59193, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 169ms/step - accuracy: 0.6026 - loss: 0.6635 - val_accuracy: 0.5919 - val_loss: 0.6649\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6055 - loss: 0.6597\n",
      "Epoch 12: val_accuracy improved from 0.59193 to 0.59850, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 162ms/step - accuracy: 0.6055 - loss: 0.6597 - val_accuracy: 0.5985 - val_loss: 0.6613\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6129 - loss: 0.6551\n",
      "Epoch 13: val_accuracy improved from 0.59850 to 0.60694, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 162ms/step - accuracy: 0.6129 - loss: 0.6551 - val_accuracy: 0.6069 - val_loss: 0.6566\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.6247 - loss: 0.6493\n",
      "Epoch 14: val_accuracy improved from 0.60694 to 0.62101, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 164ms/step - accuracy: 0.6247 - loss: 0.6493 - val_accuracy: 0.6210 - val_loss: 0.6500\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.6379 - loss: 0.6410\n",
      "Epoch 15: val_accuracy improved from 0.62101 to 0.62664, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 167ms/step - accuracy: 0.6379 - loss: 0.6409 - val_accuracy: 0.6266 - val_loss: 0.6419\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.6587 - loss: 0.6276\n",
      "Epoch 16: val_accuracy improved from 0.62664 to 0.63696, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 164ms/step - accuracy: 0.6587 - loss: 0.6275 - val_accuracy: 0.6370 - val_loss: 0.6354\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6709 - loss: 0.6125\n",
      "Epoch 17: val_accuracy improved from 0.63696 to 0.65854, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 164ms/step - accuracy: 0.6709 - loss: 0.6125 - val_accuracy: 0.6585 - val_loss: 0.6196\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6768 - loss: 0.6064\n",
      "Epoch 18: val_accuracy improved from 0.65854 to 0.66886, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 162ms/step - accuracy: 0.6768 - loss: 0.6063 - val_accuracy: 0.6689 - val_loss: 0.6038\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.6942 - loss: 0.5923\n",
      "Epoch 19: val_accuracy improved from 0.66886 to 0.68480, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 167ms/step - accuracy: 0.6941 - loss: 0.5923 - val_accuracy: 0.6848 - val_loss: 0.5918\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7029 - loss: 0.5849\n",
      "Epoch 20: val_accuracy improved from 0.68480 to 0.69137, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 164ms/step - accuracy: 0.7028 - loss: 0.5849 - val_accuracy: 0.6914 - val_loss: 0.5887\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7058 - loss: 0.5808\n",
      "Epoch 21: val_accuracy improved from 0.69137 to 0.69794, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 162ms/step - accuracy: 0.7057 - loss: 0.5809 - val_accuracy: 0.6979 - val_loss: 0.5839\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7104 - loss: 0.5758\n",
      "Epoch 22: val_accuracy did not improve from 0.69794\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.7103 - loss: 0.5758 - val_accuracy: 0.6979 - val_loss: 0.5797\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7157 - loss: 0.5709\n",
      "Epoch 23: val_accuracy improved from 0.69794 to 0.69981, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 160ms/step - accuracy: 0.7157 - loss: 0.5709 - val_accuracy: 0.6998 - val_loss: 0.5759\n",
      "Epoch 24/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7186 - loss: 0.5662\n",
      "Epoch 24: val_accuracy did not improve from 0.69981\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 152ms/step - accuracy: 0.7185 - loss: 0.5663 - val_accuracy: 0.6979 - val_loss: 0.5725\n",
      "Epoch 25/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7236 - loss: 0.5617\n",
      "Epoch 25: val_accuracy improved from 0.69981 to 0.70169, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 161ms/step - accuracy: 0.7236 - loss: 0.5618 - val_accuracy: 0.7017 - val_loss: 0.5694\n",
      "Epoch 26/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7239 - loss: 0.5573\n",
      "Epoch 26: val_accuracy improved from 0.70169 to 0.70450, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 172ms/step - accuracy: 0.7239 - loss: 0.5573 - val_accuracy: 0.7045 - val_loss: 0.5666\n",
      "Epoch 27/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7263 - loss: 0.5530\n",
      "Epoch 27: val_accuracy did not improve from 0.70450\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 169ms/step - accuracy: 0.7263 - loss: 0.5531 - val_accuracy: 0.7045 - val_loss: 0.5646\n",
      "Epoch 28/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7313 - loss: 0.5490\n",
      "Epoch 28: val_accuracy improved from 0.70450 to 0.70826, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 179ms/step - accuracy: 0.7313 - loss: 0.5490 - val_accuracy: 0.7083 - val_loss: 0.5631\n",
      "Epoch 29/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7335 - loss: 0.5452\n",
      "Epoch 29: val_accuracy improved from 0.70826 to 0.70919, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 161ms/step - accuracy: 0.7334 - loss: 0.5452 - val_accuracy: 0.7092 - val_loss: 0.5615\n",
      "Epoch 30/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7363 - loss: 0.5414\n",
      "Epoch 30: val_accuracy improved from 0.70919 to 0.71388, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 158ms/step - accuracy: 0.7362 - loss: 0.5414 - val_accuracy: 0.7139 - val_loss: 0.5601\n",
      "Epoch 31/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7372 - loss: 0.5377\n",
      "Epoch 31: val_accuracy improved from 0.71388 to 0.71764, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 159ms/step - accuracy: 0.7372 - loss: 0.5378 - val_accuracy: 0.7176 - val_loss: 0.5589\n",
      "Epoch 32/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7425 - loss: 0.5344\n",
      "Epoch 32: val_accuracy improved from 0.71764 to 0.71951, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 159ms/step - accuracy: 0.7425 - loss: 0.5345 - val_accuracy: 0.7195 - val_loss: 0.5581\n",
      "Epoch 33/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7455 - loss: 0.5319\n",
      "Epoch 33: val_accuracy improved from 0.71951 to 0.72608, saving model to model_3_1.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 158ms/step - accuracy: 0.7455 - loss: 0.5319 - val_accuracy: 0.7261 - val_loss: 0.5576\n",
      "Epoch 34/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7488 - loss: 0.5281\n",
      "Epoch 34: val_accuracy did not improve from 0.72608\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.7488 - loss: 0.5281 - val_accuracy: 0.7251 - val_loss: 0.5566\n",
      "Epoch 35/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7512 - loss: 0.5249\n",
      "Epoch 35: val_accuracy did not improve from 0.72608\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.7512 - loss: 0.5250 - val_accuracy: 0.7261 - val_loss: 0.5558\n",
      "Epoch 36/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7540 - loss: 0.5218\n",
      "Epoch 36: val_accuracy did not improve from 0.72608\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.7539 - loss: 0.5219 - val_accuracy: 0.7242 - val_loss: 0.5551\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"model_3_1.keras\", \n",
    "    monitor='val_accuracy',            \n",
    "    save_best_only=True,           \n",
    "    mode='max',                 \n",
    "    save_weights_only=False,       \n",
    "    verbose=1\n",
    ")\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size,\n",
    "              output_dim=embedding_dim,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=True),\n",
    "    SimpleRNN(16, return_sequences=False),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[checkpoint_callback, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6270 - loss: 0.6541\n",
      "Test accuracy: 70.54%\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_3_1.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. As discussed in Question 1(c), apply your solution in mitigating the influence of OOV words and train your model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-100\")\n",
    "vocab_size = len(model.index_to_key) + 2 # 0 is reserved for padding, 1 is reserved for OOV\n",
    "embedding_dim = model.vector_size\n",
    "word_index = {word: index+2 for index, word in enumerate(model.index_to_key)} # index 0 is reserved for padding\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in word_index.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[idx] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, word_index):\n",
    "    ls = nltk.word_tokenize(text)\n",
    "    return [word_index[word] if word in word_index else 1 for word in ls]\n",
    "\n",
    "X_train = [tokenize(text, word_index) for text in train_dataset['text']]\n",
    "X_val = [tokenize(text, word_index) for text in validation_dataset['text']]\n",
    "X_test = [tokenize(text, word_index) for text in test_dataset['text']]\n",
    "max_length = max(len(seq) for seq in X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_val = pad_sequences(X_val, maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_dataset['label'])\n",
    "y_val = np.array(validation_dataset['label'])\n",
    "y_test = np.array(test_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_oov.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=True), \n",
    "        SimpleRNN(16, return_sequences=False),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.4908 - loss: 0.7134\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53846, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 162ms/step - accuracy: 0.4909 - loss: 0.7133 - val_accuracy: 0.5385 - val_loss: 0.6900\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.5255 - loss: 0.6912\n",
      "Epoch 2: val_accuracy improved from 0.53846 to 0.56848, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 164ms/step - accuracy: 0.5256 - loss: 0.6912 - val_accuracy: 0.5685 - val_loss: 0.6848\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5528 - loss: 0.6862\n",
      "Epoch 3: val_accuracy improved from 0.56848 to 0.57411, saving model to model_oov.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 159ms/step - accuracy: 0.5528 - loss: 0.6862 - val_accuracy: 0.5741 - val_loss: 0.6819\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5625 - loss: 0.6829\n",
      "Epoch 4: val_accuracy did not improve from 0.57411\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.5625 - loss: 0.6829 - val_accuracy: 0.5694 - val_loss: 0.6796\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5646 - loss: 0.6802\n",
      "Epoch 5: val_accuracy did not improve from 0.57411\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.5646 - loss: 0.6802 - val_accuracy: 0.5694 - val_loss: 0.6775\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5673 - loss: 0.6776\n",
      "Epoch 6: val_accuracy did not improve from 0.57411\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 146ms/step - accuracy: 0.5673 - loss: 0.6776 - val_accuracy: 0.5638 - val_loss: 0.6755\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5742 - loss: 0.6902\n",
      "Test accuracy: 56.10%\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_oov.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Keeping the above two adjustments, replace your simple RNN model in Part 2 with a biLSTM model and a biGRU model, incorporating recurrent computations in both directions and stacking multiple layers if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_bilstm.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=True),\n",
    "        Bidirectional(LSTM(16, return_sequences=True)),\n",
    "        Bidirectional(LSTM(16, return_sequences=True)),\n",
    "        Bidirectional(LSTM(16, return_sequences=False)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.4913 - loss: 0.6940\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53846, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 200ms/step - accuracy: 0.4913 - loss: 0.6940 - val_accuracy: 0.5385 - val_loss: 0.6921\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.5293 - loss: 0.6917\n",
      "Epoch 2: val_accuracy improved from 0.53846 to 0.55722, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 203ms/step - accuracy: 0.5293 - loss: 0.6917 - val_accuracy: 0.5572 - val_loss: 0.6909\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.5537 - loss: 0.6900\n",
      "Epoch 3: val_accuracy improved from 0.55722 to 0.56567, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 203ms/step - accuracy: 0.5537 - loss: 0.6900 - val_accuracy: 0.5657 - val_loss: 0.6891\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.5722 - loss: 0.6874\n",
      "Epoch 4: val_accuracy improved from 0.56567 to 0.58724, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 210ms/step - accuracy: 0.5722 - loss: 0.6874 - val_accuracy: 0.5872 - val_loss: 0.6858\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6012 - loss: 0.6821\n",
      "Epoch 5: val_accuracy improved from 0.58724 to 0.59099, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 196ms/step - accuracy: 0.6012 - loss: 0.6821 - val_accuracy: 0.5910 - val_loss: 0.6781\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6263 - loss: 0.6697\n",
      "Epoch 6: val_accuracy improved from 0.59099 to 0.61257, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 198ms/step - accuracy: 0.6263 - loss: 0.6697 - val_accuracy: 0.6126 - val_loss: 0.6609\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6488 - loss: 0.6440\n",
      "Epoch 7: val_accuracy improved from 0.61257 to 0.66041, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 198ms/step - accuracy: 0.6489 - loss: 0.6440 - val_accuracy: 0.6604 - val_loss: 0.6369\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.6768 - loss: 0.6134\n",
      "Epoch 8: val_accuracy improved from 0.66041 to 0.68668, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 207ms/step - accuracy: 0.6768 - loss: 0.6133 - val_accuracy: 0.6867 - val_loss: 0.6133\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6966 - loss: 0.5883\n",
      "Epoch 9: val_accuracy did not improve from 0.68668\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 187ms/step - accuracy: 0.6966 - loss: 0.5883 - val_accuracy: 0.6857 - val_loss: 0.6031\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7144 - loss: 0.5674\n",
      "Epoch 10: val_accuracy improved from 0.68668 to 0.68856, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 198ms/step - accuracy: 0.7143 - loss: 0.5674 - val_accuracy: 0.6886 - val_loss: 0.6000\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7257 - loss: 0.5506\n",
      "Epoch 11: val_accuracy did not improve from 0.68856\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 184ms/step - accuracy: 0.7257 - loss: 0.5506 - val_accuracy: 0.6811 - val_loss: 0.6019\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7378 - loss: 0.5377\n",
      "Epoch 12: val_accuracy did not improve from 0.68856\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 187ms/step - accuracy: 0.7378 - loss: 0.5377 - val_accuracy: 0.6811 - val_loss: 0.5966\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.7398 - loss: 0.5274\n",
      "Epoch 13: val_accuracy improved from 0.68856 to 0.69137, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 206ms/step - accuracy: 0.7397 - loss: 0.5274 - val_accuracy: 0.6914 - val_loss: 0.5839\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.7448 - loss: 0.5187\n",
      "Epoch 14: val_accuracy improved from 0.69137 to 0.69794, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 217ms/step - accuracy: 0.7448 - loss: 0.5187 - val_accuracy: 0.6979 - val_loss: 0.5757\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7488 - loss: 0.5112\n",
      "Epoch 15: val_accuracy improved from 0.69794 to 0.70544, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 222ms/step - accuracy: 0.7487 - loss: 0.5113 - val_accuracy: 0.7054 - val_loss: 0.5704\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.7542 - loss: 0.5047\n",
      "Epoch 16: val_accuracy improved from 0.70544 to 0.70919, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 201ms/step - accuracy: 0.7541 - loss: 0.5047 - val_accuracy: 0.7092 - val_loss: 0.5662\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.7605 - loss: 0.4987\n",
      "Epoch 17: val_accuracy did not improve from 0.70919\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 195ms/step - accuracy: 0.7605 - loss: 0.4987 - val_accuracy: 0.7092 - val_loss: 0.5632\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.7643 - loss: 0.4932\n",
      "Epoch 18: val_accuracy did not improve from 0.70919\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 192ms/step - accuracy: 0.7643 - loss: 0.4933 - val_accuracy: 0.7092 - val_loss: 0.5615\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.7684 - loss: 0.4883\n",
      "Epoch 19: val_accuracy improved from 0.70919 to 0.71576, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 211ms/step - accuracy: 0.7684 - loss: 0.4883 - val_accuracy: 0.7158 - val_loss: 0.5604\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7676 - loss: 0.4837\n",
      "Epoch 20: val_accuracy improved from 0.71576 to 0.71764, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 223ms/step - accuracy: 0.7676 - loss: 0.4837 - val_accuracy: 0.7176 - val_loss: 0.5592\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.7709 - loss: 0.4795\n",
      "Epoch 21: val_accuracy improved from 0.71764 to 0.72233, saving model to model_bilstm.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 202ms/step - accuracy: 0.7708 - loss: 0.4795 - val_accuracy: 0.7223 - val_loss: 0.5579\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.7753 - loss: 0.4755\n",
      "Epoch 22: val_accuracy did not improve from 0.72233\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 193ms/step - accuracy: 0.7752 - loss: 0.4755 - val_accuracy: 0.7223 - val_loss: 0.5569\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7771 - loss: 0.4718\n",
      "Epoch 23: val_accuracy did not improve from 0.72233\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 208ms/step - accuracy: 0.7770 - loss: 0.4718 - val_accuracy: 0.7223 - val_loss: 0.5568\n",
      "Epoch 24/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.7812 - loss: 0.4683\n",
      "Epoch 24: val_accuracy did not improve from 0.72233\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 204ms/step - accuracy: 0.7812 - loss: 0.4683 - val_accuracy: 0.7167 - val_loss: 0.5582\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5844 - loss: 0.7106\n",
      "Test accuracy: 0.7204502820968628\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_bilstm.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, GRU\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_bigru.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=True), \n",
    "        Bidirectional(GRU(16, return_sequences=False)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.5123 - loss: 0.6944\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51876, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 198ms/step - accuracy: 0.5122 - loss: 0.6944 - val_accuracy: 0.5188 - val_loss: 0.6910\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5373 - loss: 0.6895\n",
      "Epoch 2: val_accuracy improved from 0.51876 to 0.54034, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.5373 - loss: 0.6895 - val_accuracy: 0.5403 - val_loss: 0.6876\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.5605 - loss: 0.6857\n",
      "Epoch 3: val_accuracy improved from 0.54034 to 0.56379, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 176ms/step - accuracy: 0.5605 - loss: 0.6857 - val_accuracy: 0.5638 - val_loss: 0.6842\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.5783 - loss: 0.6818\n",
      "Epoch 4: val_accuracy improved from 0.56379 to 0.58068, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - accuracy: 0.5782 - loss: 0.6818 - val_accuracy: 0.5807 - val_loss: 0.6804\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5937 - loss: 0.6772\n",
      "Epoch 5: val_accuracy improved from 0.58068 to 0.58818, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 188ms/step - accuracy: 0.5937 - loss: 0.6772 - val_accuracy: 0.5882 - val_loss: 0.6760\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6055 - loss: 0.6719\n",
      "Epoch 6: val_accuracy improved from 0.58818 to 0.60600, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 183ms/step - accuracy: 0.6054 - loss: 0.6719 - val_accuracy: 0.6060 - val_loss: 0.6707\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.6193 - loss: 0.6654\n",
      "Epoch 7: val_accuracy improved from 0.60600 to 0.61257, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 191ms/step - accuracy: 0.6193 - loss: 0.6654 - val_accuracy: 0.6126 - val_loss: 0.6644\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6281 - loss: 0.6576\n",
      "Epoch 8: val_accuracy improved from 0.61257 to 0.62008, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 194ms/step - accuracy: 0.6280 - loss: 0.6576 - val_accuracy: 0.6201 - val_loss: 0.6568\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6370 - loss: 0.6482\n",
      "Epoch 9: val_accuracy improved from 0.62008 to 0.63227, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 183ms/step - accuracy: 0.6370 - loss: 0.6482 - val_accuracy: 0.6323 - val_loss: 0.6474\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.6526 - loss: 0.6364\n",
      "Epoch 10: val_accuracy improved from 0.63227 to 0.64540, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 184ms/step - accuracy: 0.6526 - loss: 0.6364 - val_accuracy: 0.6454 - val_loss: 0.6352\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6675 - loss: 0.6211\n",
      "Epoch 11: val_accuracy improved from 0.64540 to 0.66229, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - accuracy: 0.6675 - loss: 0.6211 - val_accuracy: 0.6623 - val_loss: 0.6185\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6846 - loss: 0.6005\n",
      "Epoch 12: val_accuracy improved from 0.66229 to 0.68480, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 184ms/step - accuracy: 0.6846 - loss: 0.6004 - val_accuracy: 0.6848 - val_loss: 0.5974\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7059 - loss: 0.5757\n",
      "Epoch 13: val_accuracy improved from 0.68480 to 0.69606, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 201ms/step - accuracy: 0.7059 - loss: 0.5757 - val_accuracy: 0.6961 - val_loss: 0.5892\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7205 - loss: 0.5586\n",
      "Epoch 14: val_accuracy improved from 0.69606 to 0.69700, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.7205 - loss: 0.5586 - val_accuracy: 0.6970 - val_loss: 0.5872\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7282 - loss: 0.5488\n",
      "Epoch 15: val_accuracy improved from 0.69700 to 0.70169, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 179ms/step - accuracy: 0.7282 - loss: 0.5488 - val_accuracy: 0.7017 - val_loss: 0.5772\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7340 - loss: 0.5406\n",
      "Epoch 16: val_accuracy improved from 0.70169 to 0.71107, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.7340 - loss: 0.5406 - val_accuracy: 0.7111 - val_loss: 0.5666\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7413 - loss: 0.5335\n",
      "Epoch 17: val_accuracy improved from 0.71107 to 0.71764, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 187ms/step - accuracy: 0.7413 - loss: 0.5335 - val_accuracy: 0.7176 - val_loss: 0.5574\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7468 - loss: 0.5273\n",
      "Epoch 18: val_accuracy improved from 0.71764 to 0.73358, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 191ms/step - accuracy: 0.7467 - loss: 0.5273 - val_accuracy: 0.7336 - val_loss: 0.5497\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.7492 - loss: 0.5217\n",
      "Epoch 19: val_accuracy did not improve from 0.73358\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 191ms/step - accuracy: 0.7492 - loss: 0.5217 - val_accuracy: 0.7336 - val_loss: 0.5432\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.7525 - loss: 0.5167\n",
      "Epoch 20: val_accuracy improved from 0.73358 to 0.73640, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 185ms/step - accuracy: 0.7524 - loss: 0.5167 - val_accuracy: 0.7364 - val_loss: 0.5377\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7556 - loss: 0.5120\n",
      "Epoch 21: val_accuracy improved from 0.73640 to 0.73734, saving model to model_bigru.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 184ms/step - accuracy: 0.7555 - loss: 0.5121 - val_accuracy: 0.7373 - val_loss: 0.5329\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7598 - loss: 0.5078\n",
      "Epoch 22: val_accuracy did not improve from 0.73734\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 170ms/step - accuracy: 0.7597 - loss: 0.5078 - val_accuracy: 0.7317 - val_loss: 0.5288\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7610 - loss: 0.5038\n",
      "Epoch 23: val_accuracy did not improve from 0.73734\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 171ms/step - accuracy: 0.7609 - loss: 0.5038 - val_accuracy: 0.7326 - val_loss: 0.5251\n",
      "Epoch 24/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7631 - loss: 0.5000\n",
      "Epoch 24: val_accuracy did not improve from 0.73734\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 171ms/step - accuracy: 0.7630 - loss: 0.5000 - val_accuracy: 0.7317 - val_loss: 0.5218\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6402 - loss: 0.6373\n",
      "Test accuracy: 0.7307692170143127\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_bigru.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Keeping the above two adjustments, replace your simple RNN model in Part 2 with a Convolutional Neural Network (CNN) to produce sentence representations and perform sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Convolution1D, Flatten\n",
    "\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_cnn.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embedding_dim,\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=True), \n",
    "        Convolution1D(16, kernel_size=3, activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.5202 - loss: 0.6951\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57129, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 175ms/step - accuracy: 0.5202 - loss: 0.6951 - val_accuracy: 0.5713 - val_loss: 0.6835\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.5760 - loss: 0.6784\n",
      "Epoch 2: val_accuracy improved from 0.57129 to 0.60882, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 269ms/step - accuracy: 0.5761 - loss: 0.6783 - val_accuracy: 0.6088 - val_loss: 0.6708\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.6335 - loss: 0.6533\n",
      "Epoch 3: val_accuracy improved from 0.60882 to 0.62946, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 160ms/step - accuracy: 0.6335 - loss: 0.6532 - val_accuracy: 0.6295 - val_loss: 0.6594\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.6662 - loss: 0.6247\n",
      "Epoch 4: val_accuracy improved from 0.62946 to 0.64728, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 149ms/step - accuracy: 0.6662 - loss: 0.6247 - val_accuracy: 0.6473 - val_loss: 0.6495\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6940 - loss: 0.6000\n",
      "Epoch 5: val_accuracy improved from 0.64728 to 0.65760, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.6940 - loss: 0.6000 - val_accuracy: 0.6576 - val_loss: 0.6403\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7119 - loss: 0.5801\n",
      "Epoch 6: val_accuracy improved from 0.65760 to 0.66604, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.7119 - loss: 0.5801 - val_accuracy: 0.6660 - val_loss: 0.6297\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7270 - loss: 0.5648\n",
      "Epoch 7: val_accuracy improved from 0.66604 to 0.67917, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.7270 - loss: 0.5648 - val_accuracy: 0.6792 - val_loss: 0.6196\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7345 - loss: 0.5530\n",
      "Epoch 8: val_accuracy improved from 0.67917 to 0.68668, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - accuracy: 0.7345 - loss: 0.5530 - val_accuracy: 0.6867 - val_loss: 0.6113\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7408 - loss: 0.5434\n",
      "Epoch 9: val_accuracy improved from 0.68668 to 0.69325, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - accuracy: 0.7408 - loss: 0.5434 - val_accuracy: 0.6932 - val_loss: 0.6034\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7472 - loss: 0.5355\n",
      "Epoch 10: val_accuracy improved from 0.69325 to 0.70075, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - accuracy: 0.7471 - loss: 0.5355 - val_accuracy: 0.7008 - val_loss: 0.5965\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7512 - loss: 0.5287\n",
      "Epoch 11: val_accuracy improved from 0.70075 to 0.70356, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - accuracy: 0.7511 - loss: 0.5287 - val_accuracy: 0.7036 - val_loss: 0.5906\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7564 - loss: 0.5226\n",
      "Epoch 12: val_accuracy improved from 0.70356 to 0.70638, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - accuracy: 0.7564 - loss: 0.5226 - val_accuracy: 0.7064 - val_loss: 0.5854\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7598 - loss: 0.5172\n",
      "Epoch 13: val_accuracy improved from 0.70638 to 0.71107, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 123ms/step - accuracy: 0.7597 - loss: 0.5173 - val_accuracy: 0.7111 - val_loss: 0.5805\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7621 - loss: 0.5123\n",
      "Epoch 14: val_accuracy improved from 0.71107 to 0.71388, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 123ms/step - accuracy: 0.7620 - loss: 0.5123 - val_accuracy: 0.7139 - val_loss: 0.5763\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7660 - loss: 0.5077\n",
      "Epoch 15: val_accuracy improved from 0.71388 to 0.71951, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.7660 - loss: 0.5077 - val_accuracy: 0.7195 - val_loss: 0.5727\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7719 - loss: 0.5034\n",
      "Epoch 16: val_accuracy did not improve from 0.71951\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - accuracy: 0.7718 - loss: 0.5034 - val_accuracy: 0.7186 - val_loss: 0.5694\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7753 - loss: 0.4994\n",
      "Epoch 17: val_accuracy did not improve from 0.71951\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 117ms/step - accuracy: 0.7752 - loss: 0.4994 - val_accuracy: 0.7195 - val_loss: 0.5665\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7779 - loss: 0.4955\n",
      "Epoch 18: val_accuracy improved from 0.71951 to 0.72233, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 123ms/step - accuracy: 0.7778 - loss: 0.4955 - val_accuracy: 0.7223 - val_loss: 0.5635\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7789 - loss: 0.4918\n",
      "Epoch 19: val_accuracy improved from 0.72233 to 0.72420, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - accuracy: 0.7788 - loss: 0.4918 - val_accuracy: 0.7242 - val_loss: 0.5610\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7809 - loss: 0.4882\n",
      "Epoch 20: val_accuracy improved from 0.72420 to 0.72514, saving model to model_cnn.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - accuracy: 0.7808 - loss: 0.4883 - val_accuracy: 0.7251 - val_loss: 0.5589\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7821 - loss: 0.4848\n",
      "Epoch 21: val_accuracy did not improve from 0.72514\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - accuracy: 0.7820 - loss: 0.4849 - val_accuracy: 0.7251 - val_loss: 0.5566\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7822 - loss: 0.4815\n",
      "Epoch 22: val_accuracy did not improve from 0.72514\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 117ms/step - accuracy: 0.7821 - loss: 0.4815 - val_accuracy: 0.7223 - val_loss: 0.5547\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7849 - loss: 0.4783\n",
      "Epoch 23: val_accuracy did not improve from 0.72514\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 117ms/step - accuracy: 0.7849 - loss: 0.4783 - val_accuracy: 0.7205 - val_loss: 0.5531\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 100, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6685 - loss: 0.6602\n",
      "Test accuracy: 0.7326453924179077\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_cnn.keras\")\n",
    "accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Further improve your model. You are free to use any strategy other than the above mentioned solutions. Changing hyper-parameters or stacking more layers is not counted towards a meaningful improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MultiHeadAttention, Input, Bidirectional, Dropout, Dense, GlobalMaxPooling1D, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def train_model(optimizer, epochs, batch_size, lr):\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    \n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"model_combined.keras\", \n",
    "        monitor='val_accuracy',            \n",
    "        save_best_only=True,           \n",
    "        mode='max',                 \n",
    "        save_weights_only=False,       \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    input_layer = Input(shape=(max_length,))\n",
    "    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=True)(input_layer)\n",
    "    \n",
    "    gru_output = GRU(32, return_sequences=True)(embedding_layer)\n",
    "    gru_output = Dropout(0.5)(gru_output)\n",
    "    attention_output = MultiHeadAttention(num_heads=1, key_dim=16)(gru_output, gru_output)\n",
    "    gru_output = Bidirectional(GRU(16, return_sequences=True))(attention_output)\n",
    "    max_output = GlobalMaxPooling1D()(gru_output)\n",
    "    gru_output = gru_output[:, -1, :]\n",
    "    concat_output = tf.keras.layers.Concatenate(axis=1)([max_output, gru_output])\n",
    "    output_layer = Dense(1, activation='sigmoid')(concat_output) \n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',    \n",
    "        factor=0.75,             \n",
    "        patience=3,            \n",
    "        min_lr=1e-6             \n",
    "    )\n",
    "    # Set optimizer\n",
    "    if optimizer == 'adam': optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd': optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop': optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else: optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpoint_callback, reduce_lr]\n",
    "    )\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4811 - loss: 0.6937\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.4811 - loss: 0.6937 - val_accuracy: 0.5000 - val_loss: 0.6930 - learning_rate: 0.0100\n",
      "Epoch 2/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5062 - loss: 0.6929\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.5062 - loss: 0.6929 - val_accuracy: 0.4981 - val_loss: 0.6928 - learning_rate: 0.0100\n",
      "Epoch 3/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5187 - loss: 0.6926\n",
      "Epoch 3: val_accuracy improved from 0.50000 to 0.51407, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.5186 - loss: 0.6926 - val_accuracy: 0.5141 - val_loss: 0.6925 - learning_rate: 0.0100\n",
      "Epoch 4/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5292 - loss: 0.6923\n",
      "Epoch 4: val_accuracy improved from 0.51407 to 0.53659, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.5291 - loss: 0.6923 - val_accuracy: 0.5366 - val_loss: 0.6922 - learning_rate: 0.0100\n",
      "Epoch 5/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5378 - loss: 0.6918\n",
      "Epoch 5: val_accuracy improved from 0.53659 to 0.56285, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.5378 - loss: 0.6918 - val_accuracy: 0.5629 - val_loss: 0.6919 - learning_rate: 0.0100\n",
      "Epoch 6/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5537 - loss: 0.6910\n",
      "Epoch 6: val_accuracy improved from 0.56285 to 0.56379, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.5536 - loss: 0.6910 - val_accuracy: 0.5638 - val_loss: 0.6913 - learning_rate: 0.0100\n",
      "Epoch 7/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5555 - loss: 0.6906\n",
      "Epoch 7: val_accuracy improved from 0.56379 to 0.59006, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.5555 - loss: 0.6906 - val_accuracy: 0.5901 - val_loss: 0.6907 - learning_rate: 0.0100\n",
      "Epoch 8/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5735 - loss: 0.6895\n",
      "Epoch 8: val_accuracy improved from 0.59006 to 0.59756, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 79ms/step - accuracy: 0.5735 - loss: 0.6895 - val_accuracy: 0.5976 - val_loss: 0.6897 - learning_rate: 0.0100\n",
      "Epoch 9/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5896 - loss: 0.6880\n",
      "Epoch 9: val_accuracy improved from 0.59756 to 0.60600, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.5895 - loss: 0.6880 - val_accuracy: 0.6060 - val_loss: 0.6884 - learning_rate: 0.0100\n",
      "Epoch 10/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5940 - loss: 0.6866\n",
      "Epoch 10: val_accuracy improved from 0.60600 to 0.61820, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.5940 - loss: 0.6866 - val_accuracy: 0.6182 - val_loss: 0.6867 - learning_rate: 0.0100\n",
      "Epoch 11/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6042 - loss: 0.6840\n",
      "Epoch 11: val_accuracy improved from 0.61820 to 0.61914, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.6042 - loss: 0.6840 - val_accuracy: 0.6191 - val_loss: 0.6842 - learning_rate: 0.0100\n",
      "Epoch 12/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6074 - loss: 0.6815\n",
      "Epoch 12: val_accuracy did not improve from 0.61914\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.6074 - loss: 0.6815 - val_accuracy: 0.6173 - val_loss: 0.6805 - learning_rate: 0.0100\n",
      "Epoch 13/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6219 - loss: 0.6757\n",
      "Epoch 13: val_accuracy did not improve from 0.61914\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.6218 - loss: 0.6757 - val_accuracy: 0.6144 - val_loss: 0.6753 - learning_rate: 0.0100\n",
      "Epoch 14/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6230 - loss: 0.6682\n",
      "Epoch 14: val_accuracy did not improve from 0.61914\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.6230 - loss: 0.6682 - val_accuracy: 0.6079 - val_loss: 0.6692 - learning_rate: 0.0100\n",
      "Epoch 15/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6274 - loss: 0.6593\n",
      "Epoch 15: val_accuracy did not improve from 0.61914\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.6274 - loss: 0.6593 - val_accuracy: 0.5947 - val_loss: 0.6677 - learning_rate: 0.0100\n",
      "Epoch 16/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6388 - loss: 0.6471\n",
      "Epoch 16: val_accuracy did not improve from 0.61914\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.6388 - loss: 0.6471 - val_accuracy: 0.5769 - val_loss: 0.6757 - learning_rate: 0.0100\n",
      "Epoch 17/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6457 - loss: 0.6349\n",
      "Epoch 17: val_accuracy did not improve from 0.61914\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.6458 - loss: 0.6348 - val_accuracy: 0.5732 - val_loss: 0.6805 - learning_rate: 0.0100\n",
      "Epoch 18/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6591 - loss: 0.6210\n",
      "Epoch 18: val_accuracy did not improve from 0.61914\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.6591 - loss: 0.6210 - val_accuracy: 0.5685 - val_loss: 0.7097 - learning_rate: 0.0100\n",
      "Epoch 19/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6751 - loss: 0.6076\n",
      "Epoch 19: val_accuracy did not improve from 0.61914\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.6751 - loss: 0.6076 - val_accuracy: 0.5910 - val_loss: 0.6734 - learning_rate: 0.0075\n",
      "Epoch 20/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6871 - loss: 0.5940\n",
      "Epoch 20: val_accuracy did not improve from 0.61914\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.6871 - loss: 0.5940 - val_accuracy: 0.5938 - val_loss: 0.6886 - learning_rate: 0.0075\n",
      "Epoch 21/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7033 - loss: 0.5870\n",
      "Epoch 21: val_accuracy did not improve from 0.61914\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.7033 - loss: 0.5870 - val_accuracy: 0.5994 - val_loss: 0.6869 - learning_rate: 0.0075\n",
      "Epoch 22/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7044 - loss: 0.5764\n",
      "Epoch 22: val_accuracy improved from 0.61914 to 0.63227, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7044 - loss: 0.5764 - val_accuracy: 0.6323 - val_loss: 0.6570 - learning_rate: 0.0056\n",
      "Epoch 23/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7091 - loss: 0.5718\n",
      "Epoch 23: val_accuracy improved from 0.63227 to 0.64728, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7091 - loss: 0.5719 - val_accuracy: 0.6473 - val_loss: 0.6433 - learning_rate: 0.0056\n",
      "Epoch 24/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7170 - loss: 0.5665\n",
      "Epoch 24: val_accuracy improved from 0.64728 to 0.65385, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7170 - loss: 0.5665 - val_accuracy: 0.6538 - val_loss: 0.6425 - learning_rate: 0.0056\n",
      "Epoch 25/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7177 - loss: 0.5631\n",
      "Epoch 25: val_accuracy improved from 0.65385 to 0.66417, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7177 - loss: 0.5631 - val_accuracy: 0.6642 - val_loss: 0.6328 - learning_rate: 0.0056\n",
      "Epoch 26/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7212 - loss: 0.5568\n",
      "Epoch 26: val_accuracy improved from 0.66417 to 0.66604, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7212 - loss: 0.5568 - val_accuracy: 0.6660 - val_loss: 0.6345 - learning_rate: 0.0056\n",
      "Epoch 27/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7218 - loss: 0.5555\n",
      "Epoch 27: val_accuracy improved from 0.66604 to 0.66792, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7218 - loss: 0.5555 - val_accuracy: 0.6679 - val_loss: 0.6335 - learning_rate: 0.0056\n",
      "Epoch 28/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7283 - loss: 0.5507\n",
      "Epoch 28: val_accuracy improved from 0.66792 to 0.67355, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7283 - loss: 0.5508 - val_accuracy: 0.6735 - val_loss: 0.6247 - learning_rate: 0.0056\n",
      "Epoch 29/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7296 - loss: 0.5499\n",
      "Epoch 29: val_accuracy improved from 0.67355 to 0.68574, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7295 - loss: 0.5500 - val_accuracy: 0.6857 - val_loss: 0.6076 - learning_rate: 0.0056\n",
      "Epoch 30/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7312 - loss: 0.5483\n",
      "Epoch 30: val_accuracy improved from 0.68574 to 0.68949, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7311 - loss: 0.5483 - val_accuracy: 0.6895 - val_loss: 0.6081 - learning_rate: 0.0056\n",
      "Epoch 31/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7328 - loss: 0.5449\n",
      "Epoch 31: val_accuracy improved from 0.68949 to 0.69325, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7328 - loss: 0.5450 - val_accuracy: 0.6932 - val_loss: 0.5992 - learning_rate: 0.0056\n",
      "Epoch 32/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7340 - loss: 0.5418\n",
      "Epoch 32: val_accuracy did not improve from 0.69325\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.7339 - loss: 0.5418 - val_accuracy: 0.6932 - val_loss: 0.6039 - learning_rate: 0.0056\n",
      "Epoch 33/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7415 - loss: 0.5415\n",
      "Epoch 33: val_accuracy improved from 0.69325 to 0.69606, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7414 - loss: 0.5416 - val_accuracy: 0.6961 - val_loss: 0.5941 - learning_rate: 0.0056\n",
      "Epoch 34/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7408 - loss: 0.5343\n",
      "Epoch 34: val_accuracy improved from 0.69606 to 0.69794, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7408 - loss: 0.5343 - val_accuracy: 0.6979 - val_loss: 0.5892 - learning_rate: 0.0056\n",
      "Epoch 35/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7410 - loss: 0.5350\n",
      "Epoch 35: val_accuracy improved from 0.69794 to 0.70544, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7410 - loss: 0.5351 - val_accuracy: 0.7054 - val_loss: 0.5834 - learning_rate: 0.0056\n",
      "Epoch 36/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7358 - loss: 0.5363\n",
      "Epoch 36: val_accuracy did not improve from 0.70544\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7358 - loss: 0.5363 - val_accuracy: 0.7036 - val_loss: 0.5843 - learning_rate: 0.0056\n",
      "Epoch 37/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7442 - loss: 0.5317\n",
      "Epoch 37: val_accuracy improved from 0.70544 to 0.71013, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7442 - loss: 0.5317 - val_accuracy: 0.7101 - val_loss: 0.5747 - learning_rate: 0.0056\n",
      "Epoch 38/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7446 - loss: 0.5283\n",
      "Epoch 38: val_accuracy improved from 0.71013 to 0.71388, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7446 - loss: 0.5283 - val_accuracy: 0.7139 - val_loss: 0.5723 - learning_rate: 0.0056\n",
      "Epoch 39/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7419 - loss: 0.5288\n",
      "Epoch 39: val_accuracy improved from 0.71388 to 0.72045, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7419 - loss: 0.5289 - val_accuracy: 0.7205 - val_loss: 0.5631 - learning_rate: 0.0056\n",
      "Epoch 40/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7389 - loss: 0.5286\n",
      "Epoch 40: val_accuracy did not improve from 0.72045\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7389 - loss: 0.5286 - val_accuracy: 0.7158 - val_loss: 0.5675 - learning_rate: 0.0056\n",
      "Epoch 41/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7459 - loss: 0.5263\n",
      "Epoch 41: val_accuracy improved from 0.72045 to 0.72139, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7458 - loss: 0.5264 - val_accuracy: 0.7214 - val_loss: 0.5603 - learning_rate: 0.0056\n",
      "Epoch 42/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 0.5236\n",
      "Epoch 42: val_accuracy did not improve from 0.72139\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7482 - loss: 0.5236 - val_accuracy: 0.7158 - val_loss: 0.5737 - learning_rate: 0.0056\n",
      "Epoch 43/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7467 - loss: 0.5236\n",
      "Epoch 43: val_accuracy improved from 0.72139 to 0.72514, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7466 - loss: 0.5236 - val_accuracy: 0.7251 - val_loss: 0.5583 - learning_rate: 0.0056\n",
      "Epoch 44/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7504 - loss: 0.5239\n",
      "Epoch 44: val_accuracy did not improve from 0.72514\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7504 - loss: 0.5239 - val_accuracy: 0.7176 - val_loss: 0.5648 - learning_rate: 0.0056\n",
      "Epoch 45/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7485 - loss: 0.5180\n",
      "Epoch 45: val_accuracy did not improve from 0.72514\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7485 - loss: 0.5181 - val_accuracy: 0.7223 - val_loss: 0.5536 - learning_rate: 0.0056\n",
      "Epoch 46/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7495 - loss: 0.5198\n",
      "Epoch 46: val_accuracy did not improve from 0.72514\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7495 - loss: 0.5199 - val_accuracy: 0.7242 - val_loss: 0.5520 - learning_rate: 0.0056\n",
      "Epoch 47/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7521 - loss: 0.5185\n",
      "Epoch 47: val_accuracy did not improve from 0.72514\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7520 - loss: 0.5185 - val_accuracy: 0.7223 - val_loss: 0.5596 - learning_rate: 0.0056\n",
      "Epoch 48/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7541 - loss: 0.5194\n",
      "Epoch 48: val_accuracy improved from 0.72514 to 0.72702, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7540 - loss: 0.5195 - val_accuracy: 0.7270 - val_loss: 0.5478 - learning_rate: 0.0056\n",
      "Epoch 49/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7571 - loss: 0.5161\n",
      "Epoch 49: val_accuracy did not improve from 0.72702\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7571 - loss: 0.5161 - val_accuracy: 0.7261 - val_loss: 0.5526 - learning_rate: 0.0056\n",
      "Epoch 50/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7560 - loss: 0.5146\n",
      "Epoch 50: val_accuracy improved from 0.72702 to 0.72795, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7560 - loss: 0.5146 - val_accuracy: 0.7280 - val_loss: 0.5520 - learning_rate: 0.0056\n",
      "Epoch 51/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7484 - loss: 0.5156\n",
      "Epoch 51: val_accuracy did not improve from 0.72795\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7484 - loss: 0.5157 - val_accuracy: 0.7280 - val_loss: 0.5455 - learning_rate: 0.0056\n",
      "Epoch 52/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7566 - loss: 0.5104\n",
      "Epoch 52: val_accuracy improved from 0.72795 to 0.73077, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7565 - loss: 0.5104 - val_accuracy: 0.7308 - val_loss: 0.5415 - learning_rate: 0.0056\n",
      "Epoch 53/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7526 - loss: 0.5100\n",
      "Epoch 53: val_accuracy did not improve from 0.73077\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7526 - loss: 0.5101 - val_accuracy: 0.7289 - val_loss: 0.5432 - learning_rate: 0.0056\n",
      "Epoch 54/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7612 - loss: 0.5076\n",
      "Epoch 54: val_accuracy did not improve from 0.73077\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7612 - loss: 0.5077 - val_accuracy: 0.7280 - val_loss: 0.5467 - learning_rate: 0.0056\n",
      "Epoch 55/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7615 - loss: 0.5084\n",
      "Epoch 55: val_accuracy improved from 0.73077 to 0.73171, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7615 - loss: 0.5085 - val_accuracy: 0.7317 - val_loss: 0.5377 - learning_rate: 0.0056\n",
      "Epoch 56/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7576 - loss: 0.5064\n",
      "Epoch 56: val_accuracy did not improve from 0.73171\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7576 - loss: 0.5064 - val_accuracy: 0.7289 - val_loss: 0.5442 - learning_rate: 0.0056\n",
      "Epoch 57/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7588 - loss: 0.5040\n",
      "Epoch 57: val_accuracy did not improve from 0.73171\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7588 - loss: 0.5040 - val_accuracy: 0.7317 - val_loss: 0.5357 - learning_rate: 0.0056\n",
      "Epoch 58/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7616 - loss: 0.5040\n",
      "Epoch 58: val_accuracy did not improve from 0.73171\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7615 - loss: 0.5041 - val_accuracy: 0.7280 - val_loss: 0.5408 - learning_rate: 0.0056\n",
      "Epoch 59/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7580 - loss: 0.5027\n",
      "Epoch 59: val_accuracy did not improve from 0.73171\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7580 - loss: 0.5027 - val_accuracy: 0.7308 - val_loss: 0.5356 - learning_rate: 0.0056\n",
      "Epoch 60/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7609 - loss: 0.5018\n",
      "Epoch 60: val_accuracy improved from 0.73171 to 0.73358, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7609 - loss: 0.5019 - val_accuracy: 0.7336 - val_loss: 0.5379 - learning_rate: 0.0056\n",
      "Epoch 61/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7613 - loss: 0.5032\n",
      "Epoch 61: val_accuracy did not improve from 0.73358\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7613 - loss: 0.5032 - val_accuracy: 0.7317 - val_loss: 0.5333 - learning_rate: 0.0056\n",
      "Epoch 62/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7594 - loss: 0.5010\n",
      "Epoch 62: val_accuracy did not improve from 0.73358\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7594 - loss: 0.5010 - val_accuracy: 0.7336 - val_loss: 0.5309 - learning_rate: 0.0056\n",
      "Epoch 63/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7688 - loss: 0.4949\n",
      "Epoch 63: val_accuracy did not improve from 0.73358\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.7688 - loss: 0.4950 - val_accuracy: 0.7336 - val_loss: 0.5307 - learning_rate: 0.0056\n",
      "Epoch 64/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7675 - loss: 0.4957\n",
      "Epoch 64: val_accuracy did not improve from 0.73358\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7675 - loss: 0.4957 - val_accuracy: 0.7326 - val_loss: 0.5304 - learning_rate: 0.0056\n",
      "Epoch 65/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7637 - loss: 0.4979\n",
      "Epoch 65: val_accuracy improved from 0.73358 to 0.74109, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7637 - loss: 0.4979 - val_accuracy: 0.7411 - val_loss: 0.5257 - learning_rate: 0.0056\n",
      "Epoch 66/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7636 - loss: 0.4961\n",
      "Epoch 66: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7635 - loss: 0.4961 - val_accuracy: 0.7364 - val_loss: 0.5267 - learning_rate: 0.0056\n",
      "Epoch 67/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7627 - loss: 0.4932\n",
      "Epoch 67: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7626 - loss: 0.4932 - val_accuracy: 0.7392 - val_loss: 0.5251 - learning_rate: 0.0056\n",
      "Epoch 68/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7685 - loss: 0.4898\n",
      "Epoch 68: val_accuracy did not improve from 0.74109\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7684 - loss: 0.4899 - val_accuracy: 0.7364 - val_loss: 0.5256 - learning_rate: 0.0056\n",
      "Epoch 69/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7706 - loss: 0.4925\n",
      "Epoch 69: val_accuracy improved from 0.74109 to 0.74484, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7705 - loss: 0.4925 - val_accuracy: 0.7448 - val_loss: 0.5200 - learning_rate: 0.0056\n",
      "Epoch 70/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7773 - loss: 0.4858\n",
      "Epoch 70: val_accuracy did not improve from 0.74484\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.7772 - loss: 0.4859 - val_accuracy: 0.7430 - val_loss: 0.5217 - learning_rate: 0.0056\n",
      "Epoch 71/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7700 - loss: 0.4872\n",
      "Epoch 71: val_accuracy did not improve from 0.74484\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7700 - loss: 0.4873 - val_accuracy: 0.7430 - val_loss: 0.5223 - learning_rate: 0.0056\n",
      "Epoch 72/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7722 - loss: 0.4882\n",
      "Epoch 72: val_accuracy did not improve from 0.74484\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7721 - loss: 0.4882 - val_accuracy: 0.7439 - val_loss: 0.5187 - learning_rate: 0.0056\n",
      "Epoch 73/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7675 - loss: 0.4877\n",
      "Epoch 73: val_accuracy did not improve from 0.74484\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7675 - loss: 0.4877 - val_accuracy: 0.7411 - val_loss: 0.5191 - learning_rate: 0.0056\n",
      "Epoch 74/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7679 - loss: 0.4844\n",
      "Epoch 74: val_accuracy improved from 0.74484 to 0.74578, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7679 - loss: 0.4844 - val_accuracy: 0.7458 - val_loss: 0.5157 - learning_rate: 0.0056\n",
      "Epoch 75/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7714 - loss: 0.4863\n",
      "Epoch 75: val_accuracy did not improve from 0.74578\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7714 - loss: 0.4863 - val_accuracy: 0.7402 - val_loss: 0.5200 - learning_rate: 0.0056\n",
      "Epoch 76/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7686 - loss: 0.4839\n",
      "Epoch 76: val_accuracy improved from 0.74578 to 0.74672, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7686 - loss: 0.4839 - val_accuracy: 0.7467 - val_loss: 0.5148 - learning_rate: 0.0056\n",
      "Epoch 77/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7727 - loss: 0.4823\n",
      "Epoch 77: val_accuracy improved from 0.74672 to 0.74765, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7727 - loss: 0.4823 - val_accuracy: 0.7477 - val_loss: 0.5136 - learning_rate: 0.0056\n",
      "Epoch 78/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7749 - loss: 0.4814\n",
      "Epoch 78: val_accuracy did not improve from 0.74765\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7749 - loss: 0.4815 - val_accuracy: 0.7458 - val_loss: 0.5118 - learning_rate: 0.0056\n",
      "Epoch 79/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7721 - loss: 0.4782\n",
      "Epoch 79: val_accuracy did not improve from 0.74765\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7721 - loss: 0.4782 - val_accuracy: 0.7477 - val_loss: 0.5144 - learning_rate: 0.0056\n",
      "Epoch 80/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7726 - loss: 0.4777\n",
      "Epoch 80: val_accuracy improved from 0.74765 to 0.74859, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7726 - loss: 0.4777 - val_accuracy: 0.7486 - val_loss: 0.5104 - learning_rate: 0.0056\n",
      "Epoch 81/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7729 - loss: 0.4787\n",
      "Epoch 81: val_accuracy did not improve from 0.74859\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7729 - loss: 0.4787 - val_accuracy: 0.7458 - val_loss: 0.5097 - learning_rate: 0.0056\n",
      "Epoch 82/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7748 - loss: 0.4738\n",
      "Epoch 82: val_accuracy did not improve from 0.74859\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.7747 - loss: 0.4738 - val_accuracy: 0.7448 - val_loss: 0.5106 - learning_rate: 0.0056\n",
      "Epoch 83/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7732 - loss: 0.4767\n",
      "Epoch 83: val_accuracy did not improve from 0.74859\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7732 - loss: 0.4767 - val_accuracy: 0.7448 - val_loss: 0.5123 - learning_rate: 0.0056\n",
      "Epoch 84/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7732 - loss: 0.4766\n",
      "Epoch 84: val_accuracy did not improve from 0.74859\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7732 - loss: 0.4767 - val_accuracy: 0.7467 - val_loss: 0.5096 - learning_rate: 0.0056\n",
      "Epoch 85/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7745 - loss: 0.4740\n",
      "Epoch 85: val_accuracy did not improve from 0.74859\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7744 - loss: 0.4741 - val_accuracy: 0.7486 - val_loss: 0.5084 - learning_rate: 0.0056\n",
      "Epoch 86/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7809 - loss: 0.4713\n",
      "Epoch 86: val_accuracy improved from 0.74859 to 0.75235, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7809 - loss: 0.4713 - val_accuracy: 0.7523 - val_loss: 0.5062 - learning_rate: 0.0056\n",
      "Epoch 87/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7828 - loss: 0.4704\n",
      "Epoch 87: val_accuracy did not improve from 0.75235\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7828 - loss: 0.4704 - val_accuracy: 0.7467 - val_loss: 0.5082 - learning_rate: 0.0056\n",
      "Epoch 88/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7795 - loss: 0.4697\n",
      "Epoch 88: val_accuracy did not improve from 0.75235\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7795 - loss: 0.4697 - val_accuracy: 0.7523 - val_loss: 0.5051 - learning_rate: 0.0056\n",
      "Epoch 89/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7739 - loss: 0.4709\n",
      "Epoch 89: val_accuracy improved from 0.75235 to 0.75422, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7739 - loss: 0.4710 - val_accuracy: 0.7542 - val_loss: 0.5058 - learning_rate: 0.0056\n",
      "Epoch 90/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7791 - loss: 0.4723\n",
      "Epoch 90: val_accuracy did not improve from 0.75422\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7791 - loss: 0.4723 - val_accuracy: 0.7486 - val_loss: 0.5033 - learning_rate: 0.0056\n",
      "Epoch 91/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7818 - loss: 0.4679\n",
      "Epoch 91: val_accuracy did not improve from 0.75422\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7817 - loss: 0.4679 - val_accuracy: 0.7523 - val_loss: 0.5031 - learning_rate: 0.0056\n",
      "Epoch 92/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7834 - loss: 0.4666\n",
      "Epoch 92: val_accuracy did not improve from 0.75422\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7834 - loss: 0.4666 - val_accuracy: 0.7514 - val_loss: 0.5023 - learning_rate: 0.0056\n",
      "Epoch 93/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7822 - loss: 0.4682\n",
      "Epoch 93: val_accuracy did not improve from 0.75422\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7822 - loss: 0.4682 - val_accuracy: 0.7514 - val_loss: 0.5024 - learning_rate: 0.0056\n",
      "Epoch 94/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7815 - loss: 0.4672\n",
      "Epoch 94: val_accuracy did not improve from 0.75422\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7815 - loss: 0.4672 - val_accuracy: 0.7505 - val_loss: 0.5007 - learning_rate: 0.0056\n",
      "Epoch 95/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7836 - loss: 0.4623\n",
      "Epoch 95: val_accuracy did not improve from 0.75422\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7836 - loss: 0.4623 - val_accuracy: 0.7514 - val_loss: 0.5023 - learning_rate: 0.0056\n",
      "Epoch 96/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7815 - loss: 0.4624\n",
      "Epoch 96: val_accuracy did not improve from 0.75422\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7815 - loss: 0.4625 - val_accuracy: 0.7523 - val_loss: 0.5002 - learning_rate: 0.0056\n",
      "Epoch 97/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7865 - loss: 0.4633\n",
      "Epoch 97: val_accuracy did not improve from 0.75422\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7865 - loss: 0.4633 - val_accuracy: 0.7505 - val_loss: 0.5003 - learning_rate: 0.0056\n",
      "Epoch 98/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7882 - loss: 0.4618\n",
      "Epoch 98: val_accuracy improved from 0.75422 to 0.75516, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.7882 - loss: 0.4618 - val_accuracy: 0.7552 - val_loss: 0.4996 - learning_rate: 0.0056\n",
      "Epoch 99/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7836 - loss: 0.4625\n",
      "Epoch 99: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7836 - loss: 0.4625 - val_accuracy: 0.7552 - val_loss: 0.4990 - learning_rate: 0.0056\n",
      "Epoch 100/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7848 - loss: 0.4611\n",
      "Epoch 100: val_accuracy did not improve from 0.75516\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7848 - loss: 0.4612 - val_accuracy: 0.7552 - val_loss: 0.4984 - learning_rate: 0.0056\n",
      "Epoch 101/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7829 - loss: 0.4559\n",
      "Epoch 101: val_accuracy improved from 0.75516 to 0.75891, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7829 - loss: 0.4559 - val_accuracy: 0.7589 - val_loss: 0.4974 - learning_rate: 0.0056\n",
      "Epoch 102/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7894 - loss: 0.4528\n",
      "Epoch 102: val_accuracy did not improve from 0.75891\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7893 - loss: 0.4528 - val_accuracy: 0.7523 - val_loss: 0.4986 - learning_rate: 0.0056\n",
      "Epoch 103/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7890 - loss: 0.4536\n",
      "Epoch 103: val_accuracy did not improve from 0.75891\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7890 - loss: 0.4536 - val_accuracy: 0.7552 - val_loss: 0.4972 - learning_rate: 0.0056\n",
      "Epoch 104/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7878 - loss: 0.4578\n",
      "Epoch 104: val_accuracy did not improve from 0.75891\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7878 - loss: 0.4578 - val_accuracy: 0.7552 - val_loss: 0.4974 - learning_rate: 0.0056\n",
      "Epoch 105/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7889 - loss: 0.4542\n",
      "Epoch 105: val_accuracy did not improve from 0.75891\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7889 - loss: 0.4543 - val_accuracy: 0.7533 - val_loss: 0.4973 - learning_rate: 0.0056\n",
      "Epoch 106/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7877 - loss: 0.4531\n",
      "Epoch 106: val_accuracy did not improve from 0.75891\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7877 - loss: 0.4532 - val_accuracy: 0.7552 - val_loss: 0.4976 - learning_rate: 0.0056\n",
      "Epoch 107/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7921 - loss: 0.4516\n",
      "Epoch 107: val_accuracy did not improve from 0.75891\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7920 - loss: 0.4517 - val_accuracy: 0.7542 - val_loss: 0.4949 - learning_rate: 0.0042\n",
      "Epoch 108/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7894 - loss: 0.4549\n",
      "Epoch 108: val_accuracy did not improve from 0.75891\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7894 - loss: 0.4549 - val_accuracy: 0.7570 - val_loss: 0.4942 - learning_rate: 0.0042\n",
      "Epoch 109/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7936 - loss: 0.4503\n",
      "Epoch 109: val_accuracy did not improve from 0.75891\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7936 - loss: 0.4503 - val_accuracy: 0.7542 - val_loss: 0.4956 - learning_rate: 0.0042\n",
      "Epoch 110/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7892 - loss: 0.4538\n",
      "Epoch 110: val_accuracy did not improve from 0.75891\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7892 - loss: 0.4538 - val_accuracy: 0.7552 - val_loss: 0.4943 - learning_rate: 0.0042\n",
      "Epoch 111/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7953 - loss: 0.4467\n",
      "Epoch 111: val_accuracy did not improve from 0.75891\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7953 - loss: 0.4467 - val_accuracy: 0.7580 - val_loss: 0.4940 - learning_rate: 0.0042\n",
      "Epoch 112/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7927 - loss: 0.4488\n",
      "Epoch 112: val_accuracy improved from 0.75891 to 0.75985, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step - accuracy: 0.7926 - loss: 0.4488 - val_accuracy: 0.7598 - val_loss: 0.4935 - learning_rate: 0.0042\n",
      "Epoch 113/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7916 - loss: 0.4492\n",
      "Epoch 113: val_accuracy did not improve from 0.75985\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7916 - loss: 0.4492 - val_accuracy: 0.7570 - val_loss: 0.4935 - learning_rate: 0.0042\n",
      "Epoch 114/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7964 - loss: 0.4488\n",
      "Epoch 114: val_accuracy did not improve from 0.75985\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7963 - loss: 0.4488 - val_accuracy: 0.7580 - val_loss: 0.4926 - learning_rate: 0.0042\n",
      "Epoch 115/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7935 - loss: 0.4460\n",
      "Epoch 115: val_accuracy improved from 0.75985 to 0.76173, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.7935 - loss: 0.4461 - val_accuracy: 0.7617 - val_loss: 0.4928 - learning_rate: 0.0042\n",
      "Epoch 116/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7909 - loss: 0.4467\n",
      "Epoch 116: val_accuracy did not improve from 0.76173\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7909 - loss: 0.4467 - val_accuracy: 0.7561 - val_loss: 0.4929 - learning_rate: 0.0042\n",
      "Epoch 117/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7967 - loss: 0.4458\n",
      "Epoch 117: val_accuracy did not improve from 0.76173\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7967 - loss: 0.4458 - val_accuracy: 0.7589 - val_loss: 0.4917 - learning_rate: 0.0042\n",
      "Epoch 118/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7911 - loss: 0.4475\n",
      "Epoch 118: val_accuracy improved from 0.76173 to 0.76266, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7911 - loss: 0.4475 - val_accuracy: 0.7627 - val_loss: 0.4919 - learning_rate: 0.0042\n",
      "Epoch 119/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7968 - loss: 0.4430\n",
      "Epoch 119: val_accuracy did not improve from 0.76266\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7967 - loss: 0.4430 - val_accuracy: 0.7617 - val_loss: 0.4910 - learning_rate: 0.0042\n",
      "Epoch 120/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7957 - loss: 0.4422\n",
      "Epoch 120: val_accuracy did not improve from 0.76266\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7957 - loss: 0.4422 - val_accuracy: 0.7617 - val_loss: 0.4918 - learning_rate: 0.0042\n",
      "Epoch 121/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7960 - loss: 0.4442\n",
      "Epoch 121: val_accuracy did not improve from 0.76266\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7960 - loss: 0.4442 - val_accuracy: 0.7580 - val_loss: 0.4913 - learning_rate: 0.0042\n",
      "Epoch 122/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8002 - loss: 0.4452\n",
      "Epoch 122: val_accuracy did not improve from 0.76266\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.8002 - loss: 0.4452 - val_accuracy: 0.7580 - val_loss: 0.4909 - learning_rate: 0.0042\n",
      "Epoch 123/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7973 - loss: 0.4413\n",
      "Epoch 123: val_accuracy improved from 0.76266 to 0.76454, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.7973 - loss: 0.4413 - val_accuracy: 0.7645 - val_loss: 0.4908 - learning_rate: 0.0032\n",
      "Epoch 124/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7932 - loss: 0.4439\n",
      "Epoch 124: val_accuracy did not improve from 0.76454\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7932 - loss: 0.4439 - val_accuracy: 0.7598 - val_loss: 0.4907 - learning_rate: 0.0032\n",
      "Epoch 125/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8014 - loss: 0.4422\n",
      "Epoch 125: val_accuracy did not improve from 0.76454\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8014 - loss: 0.4422 - val_accuracy: 0.7627 - val_loss: 0.4901 - learning_rate: 0.0032\n",
      "Epoch 126/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7991 - loss: 0.4398\n",
      "Epoch 126: val_accuracy did not improve from 0.76454\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.7990 - loss: 0.4398 - val_accuracy: 0.7617 - val_loss: 0.4902 - learning_rate: 0.0032\n",
      "Epoch 127/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8012 - loss: 0.4423\n",
      "Epoch 127: val_accuracy did not improve from 0.76454\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8012 - loss: 0.4423 - val_accuracy: 0.7627 - val_loss: 0.4898 - learning_rate: 0.0032\n",
      "Epoch 128/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7999 - loss: 0.4416\n",
      "Epoch 128: val_accuracy did not improve from 0.76454\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.7999 - loss: 0.4416 - val_accuracy: 0.7645 - val_loss: 0.4896 - learning_rate: 0.0032\n",
      "Epoch 129/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7964 - loss: 0.4386\n",
      "Epoch 129: val_accuracy improved from 0.76454 to 0.76642, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7964 - loss: 0.4386 - val_accuracy: 0.7664 - val_loss: 0.4895 - learning_rate: 0.0032\n",
      "Epoch 130/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7942 - loss: 0.4401\n",
      "Epoch 130: val_accuracy did not improve from 0.76642\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.7942 - loss: 0.4401 - val_accuracy: 0.7664 - val_loss: 0.4894 - learning_rate: 0.0032\n",
      "Epoch 131/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7962 - loss: 0.4403\n",
      "Epoch 131: val_accuracy did not improve from 0.76642\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7962 - loss: 0.4403 - val_accuracy: 0.7608 - val_loss: 0.4895 - learning_rate: 0.0032\n",
      "Epoch 132/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7993 - loss: 0.4394\n",
      "Epoch 132: val_accuracy did not improve from 0.76642\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7992 - loss: 0.4394 - val_accuracy: 0.7617 - val_loss: 0.4896 - learning_rate: 0.0032\n",
      "Epoch 133/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8020 - loss: 0.4342\n",
      "Epoch 133: val_accuracy did not improve from 0.76642\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.8020 - loss: 0.4342 - val_accuracy: 0.7617 - val_loss: 0.4888 - learning_rate: 0.0032\n",
      "Epoch 134/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8002 - loss: 0.4388\n",
      "Epoch 134: val_accuracy did not improve from 0.76642\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8002 - loss: 0.4388 - val_accuracy: 0.7655 - val_loss: 0.4889 - learning_rate: 0.0032\n",
      "Epoch 135/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7956 - loss: 0.4405\n",
      "Epoch 135: val_accuracy improved from 0.76642 to 0.76735, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 72ms/step - accuracy: 0.7956 - loss: 0.4405 - val_accuracy: 0.7674 - val_loss: 0.4884 - learning_rate: 0.0032\n",
      "Epoch 136/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8067 - loss: 0.4343\n",
      "Epoch 136: val_accuracy did not improve from 0.76735\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8067 - loss: 0.4343 - val_accuracy: 0.7674 - val_loss: 0.4882 - learning_rate: 0.0032\n",
      "Epoch 137/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7974 - loss: 0.4402\n",
      "Epoch 137: val_accuracy did not improve from 0.76735\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7973 - loss: 0.4402 - val_accuracy: 0.7645 - val_loss: 0.4881 - learning_rate: 0.0032\n",
      "Epoch 138/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8005 - loss: 0.4404\n",
      "Epoch 138: val_accuracy improved from 0.76735 to 0.76829, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.8005 - loss: 0.4403 - val_accuracy: 0.7683 - val_loss: 0.4887 - learning_rate: 0.0032\n",
      "Epoch 139/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8016 - loss: 0.4344\n",
      "Epoch 139: val_accuracy did not improve from 0.76829\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8016 - loss: 0.4344 - val_accuracy: 0.7655 - val_loss: 0.4879 - learning_rate: 0.0032\n",
      "Epoch 140/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8049 - loss: 0.4293\n",
      "Epoch 140: val_accuracy did not improve from 0.76829\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.8049 - loss: 0.4294 - val_accuracy: 0.7627 - val_loss: 0.4877 - learning_rate: 0.0032\n",
      "Epoch 141/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7990 - loss: 0.4339\n",
      "Epoch 141: val_accuracy did not improve from 0.76829\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.7990 - loss: 0.4339 - val_accuracy: 0.7636 - val_loss: 0.4883 - learning_rate: 0.0032\n",
      "Epoch 142/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8035 - loss: 0.4341\n",
      "Epoch 142: val_accuracy improved from 0.76829 to 0.76923, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.8035 - loss: 0.4341 - val_accuracy: 0.7692 - val_loss: 0.4878 - learning_rate: 0.0032\n",
      "Epoch 143/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7996 - loss: 0.4338\n",
      "Epoch 143: val_accuracy did not improve from 0.76923\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.7995 - loss: 0.4338 - val_accuracy: 0.7692 - val_loss: 0.4869 - learning_rate: 0.0032\n",
      "Epoch 144/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8002 - loss: 0.4324\n",
      "Epoch 144: val_accuracy did not improve from 0.76923\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8002 - loss: 0.4324 - val_accuracy: 0.7683 - val_loss: 0.4871 - learning_rate: 0.0032\n",
      "Epoch 145/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8020 - loss: 0.4313\n",
      "Epoch 145: val_accuracy did not improve from 0.76923\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8019 - loss: 0.4313 - val_accuracy: 0.7627 - val_loss: 0.4870 - learning_rate: 0.0032\n",
      "Epoch 146/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8015 - loss: 0.4333\n",
      "Epoch 146: val_accuracy did not improve from 0.76923\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.8014 - loss: 0.4333 - val_accuracy: 0.7617 - val_loss: 0.4873 - learning_rate: 0.0032\n",
      "Epoch 147/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8011 - loss: 0.4323\n",
      "Epoch 147: val_accuracy did not improve from 0.76923\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8011 - loss: 0.4323 - val_accuracy: 0.7674 - val_loss: 0.4867 - learning_rate: 0.0024\n",
      "Epoch 148/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8018 - loss: 0.4289\n",
      "Epoch 148: val_accuracy did not improve from 0.76923\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.8018 - loss: 0.4290 - val_accuracy: 0.7645 - val_loss: 0.4868 - learning_rate: 0.0024\n",
      "Epoch 149/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8065 - loss: 0.4310\n",
      "Epoch 149: val_accuracy did not improve from 0.76923\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8065 - loss: 0.4310 - val_accuracy: 0.7683 - val_loss: 0.4868 - learning_rate: 0.0024\n",
      "Epoch 150/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8032 - loss: 0.4342\n",
      "Epoch 150: val_accuracy did not improve from 0.76923\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8032 - loss: 0.4342 - val_accuracy: 0.7674 - val_loss: 0.4865 - learning_rate: 0.0024\n",
      "Epoch 151/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8042 - loss: 0.4305\n",
      "Epoch 151: val_accuracy did not improve from 0.76923\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8042 - loss: 0.4305 - val_accuracy: 0.7683 - val_loss: 0.4863 - learning_rate: 0.0024\n",
      "Epoch 152/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8040 - loss: 0.4267\n",
      "Epoch 152: val_accuracy improved from 0.76923 to 0.77205, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8039 - loss: 0.4267 - val_accuracy: 0.7720 - val_loss: 0.4867 - learning_rate: 0.0024\n",
      "Epoch 153/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8063 - loss: 0.4287\n",
      "Epoch 153: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.8063 - loss: 0.4287 - val_accuracy: 0.7711 - val_loss: 0.4869 - learning_rate: 0.0024\n",
      "Epoch 154/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8001 - loss: 0.4317\n",
      "Epoch 154: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8001 - loss: 0.4317 - val_accuracy: 0.7720 - val_loss: 0.4863 - learning_rate: 0.0024\n",
      "Epoch 155/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8053 - loss: 0.4304\n",
      "Epoch 155: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.8052 - loss: 0.4304 - val_accuracy: 0.7711 - val_loss: 0.4862 - learning_rate: 0.0018\n",
      "Epoch 156/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8068 - loss: 0.4305\n",
      "Epoch 156: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.8068 - loss: 0.4305 - val_accuracy: 0.7674 - val_loss: 0.4858 - learning_rate: 0.0018\n",
      "Epoch 157/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8082 - loss: 0.4262\n",
      "Epoch 157: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.8082 - loss: 0.4262 - val_accuracy: 0.7711 - val_loss: 0.4860 - learning_rate: 0.0018\n",
      "Epoch 158/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8079 - loss: 0.4280\n",
      "Epoch 158: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8079 - loss: 0.4281 - val_accuracy: 0.7692 - val_loss: 0.4859 - learning_rate: 0.0018\n",
      "Epoch 159/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8036 - loss: 0.4260\n",
      "Epoch 159: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8036 - loss: 0.4261 - val_accuracy: 0.7711 - val_loss: 0.4858 - learning_rate: 0.0018\n",
      "Epoch 160/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8046 - loss: 0.4258\n",
      "Epoch 160: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.8046 - loss: 0.4258 - val_accuracy: 0.7702 - val_loss: 0.4859 - learning_rate: 0.0013\n",
      "Epoch 161/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8039 - loss: 0.4280\n",
      "Epoch 161: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.8038 - loss: 0.4280 - val_accuracy: 0.7711 - val_loss: 0.4859 - learning_rate: 0.0013\n",
      "Epoch 162/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8032 - loss: 0.4221\n",
      "Epoch 162: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8032 - loss: 0.4221 - val_accuracy: 0.7711 - val_loss: 0.4857 - learning_rate: 0.0013\n",
      "Epoch 163/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8103 - loss: 0.4255\n",
      "Epoch 163: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8103 - loss: 0.4255 - val_accuracy: 0.7702 - val_loss: 0.4860 - learning_rate: 0.0013\n",
      "Epoch 164/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8090 - loss: 0.4300\n",
      "Epoch 164: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8089 - loss: 0.4300 - val_accuracy: 0.7702 - val_loss: 0.4857 - learning_rate: 0.0013\n",
      "Epoch 165/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8058 - loss: 0.4284\n",
      "Epoch 165: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8057 - loss: 0.4284 - val_accuracy: 0.7702 - val_loss: 0.4856 - learning_rate: 0.0013\n",
      "Epoch 166/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8062 - loss: 0.4264\n",
      "Epoch 166: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.8062 - loss: 0.4264 - val_accuracy: 0.7720 - val_loss: 0.4853 - learning_rate: 0.0010\n",
      "Epoch 167/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8076 - loss: 0.4257\n",
      "Epoch 167: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8076 - loss: 0.4257 - val_accuracy: 0.7711 - val_loss: 0.4853 - learning_rate: 0.0010\n",
      "Epoch 168/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8090 - loss: 0.4239\n",
      "Epoch 168: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.8090 - loss: 0.4239 - val_accuracy: 0.7702 - val_loss: 0.4852 - learning_rate: 0.0010\n",
      "Epoch 169/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8029 - loss: 0.4273\n",
      "Epoch 169: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8029 - loss: 0.4273 - val_accuracy: 0.7692 - val_loss: 0.4858 - learning_rate: 0.0010\n",
      "Epoch 170/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8110 - loss: 0.4211\n",
      "Epoch 170: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8110 - loss: 0.4211 - val_accuracy: 0.7720 - val_loss: 0.4855 - learning_rate: 7.5085e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8034 - loss: 0.4249\n",
      "Epoch 171: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8034 - loss: 0.4249 - val_accuracy: 0.7720 - val_loss: 0.4856 - learning_rate: 7.5085e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8067 - loss: 0.4207\n",
      "Epoch 172: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8067 - loss: 0.4207 - val_accuracy: 0.7702 - val_loss: 0.4853 - learning_rate: 7.5085e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8067 - loss: 0.4254\n",
      "Epoch 173: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8067 - loss: 0.4254 - val_accuracy: 0.7720 - val_loss: 0.4853 - learning_rate: 5.6314e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8072 - loss: 0.4250\n",
      "Epoch 174: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8071 - loss: 0.4250 - val_accuracy: 0.7711 - val_loss: 0.4853 - learning_rate: 5.6314e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8071 - loss: 0.4219\n",
      "Epoch 175: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8071 - loss: 0.4219 - val_accuracy: 0.7720 - val_loss: 0.4854 - learning_rate: 5.6314e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8061 - loss: 0.4239\n",
      "Epoch 176: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8061 - loss: 0.4239 - val_accuracy: 0.7720 - val_loss: 0.4854 - learning_rate: 4.2235e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8084 - loss: 0.4239\n",
      "Epoch 177: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.8084 - loss: 0.4239 - val_accuracy: 0.7720 - val_loss: 0.4854 - learning_rate: 4.2235e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8088 - loss: 0.4229\n",
      "Epoch 178: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.8087 - loss: 0.4229 - val_accuracy: 0.7720 - val_loss: 0.4854 - learning_rate: 4.2235e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8087 - loss: 0.4266\n",
      "Epoch 179: val_accuracy did not improve from 0.77205\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.8087 - loss: 0.4266 - val_accuracy: 0.7720 - val_loss: 0.4854 - learning_rate: 3.1676e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8064 - loss: 0.4299\n",
      "Epoch 180: val_accuracy improved from 0.77205 to 0.77298, saving model to model_combined.keras\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step - accuracy: 0.8064 - loss: 0.4299 - val_accuracy: 0.7730 - val_loss: 0.4853 - learning_rate: 3.1676e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8042 - loss: 0.4204\n",
      "Epoch 181: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8042 - loss: 0.4205 - val_accuracy: 0.7720 - val_loss: 0.4853 - learning_rate: 3.1676e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8088 - loss: 0.4243\n",
      "Epoch 182: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.8088 - loss: 0.4244 - val_accuracy: 0.7720 - val_loss: 0.4852 - learning_rate: 2.3757e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8096 - loss: 0.4280\n",
      "Epoch 183: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8096 - loss: 0.4280 - val_accuracy: 0.7720 - val_loss: 0.4852 - learning_rate: 2.3757e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8061 - loss: 0.4245\n",
      "Epoch 184: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8060 - loss: 0.4245 - val_accuracy: 0.7720 - val_loss: 0.4852 - learning_rate: 2.3757e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8076 - loss: 0.4241\n",
      "Epoch 185: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8076 - loss: 0.4241 - val_accuracy: 0.7730 - val_loss: 0.4852 - learning_rate: 2.3757e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8028 - loss: 0.4311\n",
      "Epoch 186: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8028 - loss: 0.4311 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 1.7818e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8064 - loss: 0.4255\n",
      "Epoch 187: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8064 - loss: 0.4255 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 1.7818e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8121 - loss: 0.4250\n",
      "Epoch 188: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.8120 - loss: 0.4250 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 1.7818e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8051 - loss: 0.4263\n",
      "Epoch 189: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8050 - loss: 0.4263 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 1.3363e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8038 - loss: 0.4287\n",
      "Epoch 190: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 0.8037 - loss: 0.4287 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 1.3363e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8073 - loss: 0.4206\n",
      "Epoch 191: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8073 - loss: 0.4206 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 1.3363e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8107 - loss: 0.4215\n",
      "Epoch 192: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8107 - loss: 0.4215 - val_accuracy: 0.7730 - val_loss: 0.4850 - learning_rate: 1.3363e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8079 - loss: 0.4261\n",
      "Epoch 193: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.8078 - loss: 0.4261 - val_accuracy: 0.7720 - val_loss: 0.4850 - learning_rate: 1.3363e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8093 - loss: 0.4184\n",
      "Epoch 194: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8092 - loss: 0.4184 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 1.3363e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8065 - loss: 0.4249\n",
      "Epoch 195: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8065 - loss: 0.4249 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 1.0023e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8038 - loss: 0.4227\n",
      "Epoch 196: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8038 - loss: 0.4227 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 1.0023e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8055 - loss: 0.4229\n",
      "Epoch 197: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.8055 - loss: 0.4229 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 1.0023e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8073 - loss: 0.4255\n",
      "Epoch 198: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.8073 - loss: 0.4255 - val_accuracy: 0.7730 - val_loss: 0.4851 - learning_rate: 7.5169e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8070 - loss: 0.4235\n",
      "Epoch 199: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.8070 - loss: 0.4235 - val_accuracy: 0.7730 - val_loss: 0.4850 - learning_rate: 7.5169e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8056 - loss: 0.4243\n",
      "Epoch 200: val_accuracy did not improve from 0.77298\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.8056 - loss: 0.4243 - val_accuracy: 0.7720 - val_loss: 0.4850 - learning_rate: 7.5169e-05\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\"adagrad\", 200, 64, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.4918\n",
      "Test accuracy: 0.7729831337928772\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"model_combined.keras\")\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
